@INBOOK{7090259, 
author={Nelson L. S. da Fonseca and Raouf Boutaba}, 
booktitle={Cloud Services, Networking, and Management}, 
title={Virtualization in the Cloud}, 
year={2015}, 
volume={}, 
number={}, 
pages={432-}, 
abstract={This chapter covers the management of virtualization in the cloud. It reviews some basic concepts of virtualization in cloud computing environments. First, the chapter describes the main elements of a virtualized cloud environment. It also reviews some of the most important efforts towards the definition of open standard interfaces to support virtualization and interoperability in the cloud. Next, the chapter lists some of the most important efforts currently targeted to build tools and systems for virtualization and cloud resource management. It also lists key challenges that can guide future developments in the virtualization management and also mentions some ongoing research in the field. The Open Cloud Computing Interface (OCCI) introduces a set of open, community-driven specifications to deal with cloud service resource management. The Cloud Data Management Interface (CDMI) is a standard specifically targeted to define an interface to access cloud storage and to manage data objects.}, 
keywords={}, 
doi={10.1002/9781119042655.ch2}, 
ISSN={}, 
publisher={Wiley-IEEE Press}, 
isbn={9781119042655}, 
url={http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7090259},}
@INPROCEEDINGS{5358085, 
author={Zehua Zhang and Xuejie Zhang}, 
booktitle={2009 IEEE International Conference on Intelligent Computing and Intelligent Systems}, 
title={Realization of open cloud computing federation based on mobile agent}, 
year={2009}, 
volume={3}, 
number={}, 
pages={642-646}, 
abstract={Although cloud computing is generally recognized as a technology which will has a significant impact on IT in the future. However, Cloud computing is still in its infancy, currently, there is not a standard available for it, portability and interoperability is also impossible between different Cloud Computing Service Providers, therefore, handicaps the widely deploy and quick development of cloud computing, there is still a long distance to the fine scenery which theoretically depicted by cloud computing. We analyze the problems in the current state of the art, put forward that Open Cloud Computing Federation is an inevitable approach for the widely use of cloud computing and to realize the greatest value of it. Accordingly, we proposal the MABOCCF (Mobile Agent Based Open Cloud Computing Federation) mechanism in this paper, it combines the advantages of Mobile Agent and cloud computing to provide a realization for the Open Cloud Computing Federation, MABOCCF can span over multiple heterogeneous Cloud Computing platforms and realizes portability and interoperability, it can be a beginning of open cloud computing federation and a future part of cloud computing. We also present in this paper the rationalities and the motivations for the combination of Mobile Agent and Cloud Computing, finally, a prototype is given with a performance analysis.}, 
keywords={Internet;mobile agents;cloud computing service providers;mobile agent;open cloud computing federation;Availability;Cloud computing;Computer industry;Computer networks;Distributed computing;Electric breakdown;Information science;Mobile agents;Scalability;Standards development;cloud computing;federation;interoperablility;mobile agent;portability}, 
doi={10.1109/ICICISYS.2009.5358085}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{5778905, 
author={X. M. Zhang and N. Zhang}, 
booktitle={2011 International Conference on Computer and Management (CAMAN)}, 
title={An Open, Secure and Flexible Platform Based on Internet of Things and Cloud Computing for Ambient Aiding Living and Telemedicine}, 
year={2011}, 
volume={}, 
number={}, 
pages={1-4}, 
abstract={Currently Internet of Things (IoT) and multimedia technologies have entered the healthcare field through ambient aiding living and telemedicine. However there are still several obstacles blocking in the way, the toughest ones among which are IoT interoperability, system security, streaming Quality of Service (QoS) and dynamic increasing storage. The major contribution of this paper is proposing an open, secure and flexible platform based on IoT and Cloud computing, on which several mainstream short distant ambient communication protocols for medical purpose are discussed to address interoperability; Secure Sockets Layer (SSL), authentication and auditing are taken into consideration to solve the security issue; an adaptive streaming QoS model is utilized to improve streaming quality in dynamic environment; and an open Cloud computing infrastructure is adopted to support elastic Electronic Health Record (EHR) archiving in the backend. Finally an integrated reference implementation is introduced to demonstrate feasibility.}, 
keywords={Internet;cloud computing;cryptographic protocols;medical information systems;open systems;telemedicine;Internet of things;IoT interoperability;ambient aiding living;ambient communication protocols;cloud computing;electronic health record;multimedia technologies;secure sockets layer;service quality;system security;telemedicine;Internet;Logic gates;Multimedia communication;Quality of service;Security;Streaming media;Telemedicine}, 
doi={10.1109/CAMAN.2011.5778905}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{7776594, 
author={V. C. Emeakaroha and M. Bullman and J. P. Morrison}, 
booktitle={2016 5th IEEE International Conference on Cloud Networking (Cloudnet)}, 
title={Towards Automated Cost-Efficient Data Management for Federated Cloud Services}, 
year={2016}, 
volume={}, 
number={}, 
pages={158-163}, 
abstract={Cloud computing has transformed the accessibility and usage of information technology resources, by offering them as services via the Internet. Cloud service provisioning spans across infrastructure, platform and software levels. The management of the services at these levels is based on monitoring. The analysis of monitoring data provides insight into Cloud operations in order to make informed decisions. Due to the emergence of numerous heterogenous Cloud platforms with proprietary APIs, service and monitoring data are being formatted using diverse and mostly incompatible data interchange formats. This results to interoperability issues and makes the analysis of monitoring data from multi-Cloud service deployments difficult to handle. The existing research efforts on data interchange formats have been mainly focused on general performance analyses. Little or no effort has been channelled towards a combination of multiple data interchange formats based on data type to achieve efficient serialisation that can facilitate interoperability in federated Clouds, and also reduce the size of data and bandwidth utilisation cost. This paper addresses these issues by presenting automated framework that is capable of automatically selecting the most suitable data interchange formats for achieving an efficient formatting and serialisation outcome. The goal of the framework is to enable robust and transparent communication within and between multiple Cloud deployments. Based on three use case scenarios, we evaluate the proposed framework to demonstrate its efficacy in formatting and serialising data.}, 
keywords={application program interfaces;cloud computing;data analysis;electronic data interchange;monitoring;open systems;Internet;bandwidth utilisation cost;cloud computing;cloud services;cost-efficiency data management;data analysis monitoring;data interchange formats;data size reduction;information technology resource usage;interoperability;proprietary APIs;Arrays;Bandwidth;Cloud computing;Interoperability;Monitoring;XML;Cloud Federation;Cloud Interoperability;Data Interchange Format;Data Management}, 
doi={10.1109/CloudNet.2016.37}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6614137, 
author={M. Schnjakin and C. Meinel}, 
booktitle={2013 22nd International Conference on Computer Communication and Networks (ICCCN)}, 
title={Evaluation of Cloud-RAID: A Secure and Reliable Storage above the Clouds}, 
year={2013}, 
volume={}, 
number={}, 
pages={1-9}, 
abstract={Cloud Computing as a service-on-demand architecture has grown in importance over the previous few years. One driver of its growth is the ever increasing amount of data which is supposed to outpace the growth of storage capacity. The usage of cloud technology enables organizations to manage their data with low operational expenses. However, the benefits of cloud computing come along with challenges and open issues such as security, reliability and the risk to become dependent on a provider for its service. In general, a switch of a storage provider is associated with high costs of adapting new APIs and additional charges for inbound and outbound bandwidth and requests. In this paper, we present a system that improves availability, confidentiality and reliability of data stored in the cloud. To achieve this objective, we encrypt user's data and make use of the RAID-technology principle to manage data distribution across cloud storage providers. We conduct a proof-of-concept testbed experiment for our application to evaluate the performance and cost effectiveness of our approach. We deployed our application using eight commercial cloud storage repositories in different countries. Our approach allows users to avoid vendor lock-in, and reduces significantly the cost of switching providers. We also observed that our implementation improved the perceived availability and, in most cases, the overall performance when compared with individual cloud providers. Moreover, we estimated the monetary costs to be competitive to the cost of using a single cloud provider.}, 
keywords={RAID;cloud computing;cryptography;storage management;API;RAID-technology principle;cloud computing;cloud storage providers;cloud storage repository;cloud technology;cloud-RAID evaluation;cost effectiveness evaluation;data confidentiality;data distribution management;data reliability;monetary cost;performance evaluation;reliable storage;secure storage;security;service-on-demand architecture;storage capacity;user data encryption;vendor lock-in;Availability;Cloud computing;Cryptography;Encoding;Google;Throughput}, 
doi={10.1109/ICCCN.2013.6614137}, 
ISSN={1095-2055}, 
month={July},}
@INPROCEEDINGS{6058962, 
author={J. Altmann and M. Hovestadt and O. Kao}, 
booktitle={7th International Conference on Networked Computing}, 
title={Business support service platform for providers in open cloud computing markets}, 
year={2011}, 
volume={}, 
number={}, 
pages={149-154}, 
abstract={Cloud computing faces two business-related issues. First, the management of clouds requires not only technical skills but also the understanding of the business side of these systems. Traditional distributed systems research did not require this understanding, simply assuming that all components involved are willing to cooperate according to the resource allocation algorithm prescribed. This cooperation assumption is not valid anymore if clouds are commercial. Secondly, the demand of cloud customers can cause demand spikes at any time, raising the questions on how to allocate the limited resources. Consequently, a real-time view of the provider's business with respect to revenue streams and costs becomes essential for cloud providers. Such a system helps them to respond in an economically efficient way. From the user perspective, the understanding of the different offerings of clouds is also becoming none-trivial, requiring a support in selecting the best-fitting cloud service. A solution to these two issues is the use of business economics. The objective of this work is to lay out a concept and design of a business support service platform, which is called Cloud Management Cockpit (CMC), which uses business economics for giving decision support to providers for managing clouds and for using clouds. The applications of the CMC are laid out in three scenarios. They highlight the usefulness of the CMC business support models and demonstrate how CMC enables platform interoperability, service composition, and reduces complexity of clouds.}, 
keywords={business data processing;cloud computing;decision support systems;marketing;CMC business support model;business economics;business support service platform;cloud management cockpit;open cloud computing markets;revenue streams;Biological system modeling;Cloud computing;Computational modeling;Decision making;Economics}, 
doi={}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{7557398, 
author={H. Witti and C. Ghedira-Guegan and E. Disson and K. Boukadi}, 
booktitle={2016 IEEE World Congress on Services (SERVICES)}, 
title={Security Governance in Multi-cloud Environment: A Systematic Mapping Study}, 
year={2016}, 
volume={}, 
number={}, 
pages={81-86}, 
abstract={Cloud computing has revolutionized delivery of IT solutions increasing economic advantages, robustness, scalability, elasticity and security. Nowadays to achieve their cloud goals, organizations are increasingly move towards enabling multi-cloud environments which promised to support very large-scale, worldwide, distributed applications using multiple and independent cloud environments. However, given their complexity and distribution, multi-cloud has to face several key challenges around security and governance such as interoperability, portability, provisioning, elasticity, high availability and security. Therefore, these challenges increase the needs of security governance in such environments. Although some researches have been realized in the multi-cloud security domain, it becomes imperative to asses the current state of research and practice of its security governance. This paper aims to categorize the existing works related to security governance in multi-cloud environments by applying a systematic mapping study methodology in order toidentify trends and future directions. Our results prove that multi-clouds security governance seems to be a promising areain multi-cloud research and evaluation.}, 
keywords={cloud computing;security of data;cloud computing;multicloud environment;security governance;systematic mapping study methodology;Cloud computing;Complexity theory;Market research;Risk management;Security;Systematics;Multi-cloud;mapping study;security;security governance}, 
doi={10.1109/SERVICES.2016.17}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{6753866, 
author={G. C. Silva and L. M. Rose and R. Calinescu}, 
booktitle={2013 IEEE 5th International Conference on Cloud Computing Technology and Science}, 
title={Towards a Model-Driven Solution to the Vendor Lock-In Problem in Cloud Computing}, 
year={2013}, 
volume={1}, 
number={}, 
pages={711-716}, 
abstract={Due to the heterogeneity of today's cloud providers, migrating applications between providers is extremely challenging. This lack of portability is caused, in part, by vendor lock-in: the strong dependency created between a cloud user and a cloud provider since the cloud user deploys their software on a specific cloud platform. This paper outlines our plans to address vendor lock-in by applying techniques from the area of model-driven engineering (MDE), a contemporary and principled approach to software engineering that has sometimes been used to achieve greater portability of software. This paper presents preliminary models of two widely used IaaS services and an analysis of literature reporting real cases of software migration, and introduces a research question and method for our future work on using MDE to address vendor lock-in for cloud computing.}, 
keywords={cloud computing;software portability;IaaS services;MDE;cloud computing;cloud providers;model-driven engineering;software engineering;software migration;software portability;vendor lock-in problem;Analytical models;Business;Cloud computing;Computational modeling;Operating systems;Unified modeling language;application migration;cloud computing;portability}, 
doi={10.1109/CloudCom.2013.131}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6996769, 
author={J. Ma and C. Peng and Q. Chen}, 
booktitle={2014 5th International Conference on Digital Home}, 
title={Health Information Exchange for Home-Based Chronic Disease Self-Management -- A Hybrid Cloud Approach}, 
year={2014}, 
volume={}, 
number={}, 
pages={246-251}, 
abstract={The exchange of health information between patients and multiple stakeholders empowers digital home based self-care, which can deal with the challenge of increasing chronic disease prevalence. Cloud computing has the potential to provide a more imaginative long-term solution. However, concerns over pattern of data sharing, confidentiality of sensitive health data, and service integration need to be addressed. This paper aims to identify a promising and achievable cloud based solution which enables patients to share the health information when multiple stakeholders are involved for different purposes. A prototype on the case of type 2 diabetes is implemented as a proof of concept for the proposed hybrid cloud based solution. The hybrid cloud environment is composed of Open Stack and Amazon Web Services with open source libs. And the exchanging health data contains in HL7 CCD format. According to the simulation, it shows that the health data sharing between patients and multiple stakeholders has been achieved. And the problems of interoperability and privacy have been partly solved within the proposed solution.}, 
keywords={Web services;cloud computing;data privacy;diseases;electronic data interchange;health care;medical information systems;open systems;patient care;telemedicine;Amazon Web services;HL7 CCD format;chronic disease prevalence;cloud computing;data privacy;digital home based self-care;health data exchange;health data sharing;health information exchange;home-based chronic disease self-management;hybrid cloud approach;hybrid cloud based solution;hybrid cloud environment;interoperability;open source libs;open stack;sensitive health data confidentiality;service integration;type 2 diabetes;Cloud computing;Data models;Diseases;Hospitals;Monitoring;Prototypes;Health data exchange;chronic disease home care;cloud computing;digital home}, 
doi={10.1109/ICDH.2014.54}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{6405657, 
author={Z. Yu}, 
booktitle={2012 Fourth International Conference on Multimedia Information Networking and Security}, 
title={Cloud Computing-Conversion Technology for Interoperability}, 
year={2012}, 
volume={}, 
number={}, 
pages={179-182}, 
abstract={Though the current cloud computing is in its initial stage of development, some established players, such as Amazon, Google, Salesforce.com, have captured market shares with their own strategies and standards. However, for a further development for this immature market, it has been proposed a general standard (like TCP/IP for internet) among cloud participants. There are some standards under drafting, but it seems impractical for established players to agree on a general one, for they already have their own standards. What's more, the ongoing creation in the industry undermines standardization, On the other hand, each cloud provider is taking an active role in making its own API, for instance VMware's vCloud, an open standard, but the cost is consumers' lock-in. Thus, conversion technology seems to have a brighter future than standardization towards achieving interoperability. This study discusses various issues concerning the realization of interoperability by conversion technology. Primarily, an economic model is used for reference to analyze the market's incentive to adopt such technology, especially in such a market with network effects. Then a sequence of issues regarding technique, economy, management, security and politics are put forward and discussed, ending with an outlook for the industry. These discussions have important implications for realization of interoperability under the current condition where standardization is somewhat costly and impractical.}, 
keywords={cloud computing;open systems;API;Amazon;Google;Internet;Salesforce.com;VMware;cloud computing conversion technology;cloud provider;economic model;interoperability;market incentive;market shares;vCloud;Cloud computing;Clouds;Industries;Security;Standards;cloud computing;conversion technology;interoperability;network effects;standardization}, 
doi={10.1109/MINES.2012.85}, 
ISSN={2162-8998}, 
month={Nov},}
@INPROCEEDINGS{5767969, 
author={}, 
booktitle={2011 IEEE 27th International Conference on Data Engineering}, 
title={Table of contents}, 
year={2011}, 
volume={}, 
number={}, 
pages={1-35}, 
abstract={The following topics are dealt with: social network; personal information; cloud computing; streams and sensor networks; data warehousing; OLAP; data grids; data mining; knowledge discovery; distributed and mobile systems; query processing and optimization; data integration; metadata management; interoperability; privacy and security; distributed systems; semi structured data; XML; Web data management; database user interfaces; information visualization; query processing; Web information management; and business intelligence.}, 
keywords={XML;cloud computing;competitive intelligence;data mining;grid computing;personal information systems;query processing;social networking (online);user interfaces;warehousing;OLAP;Web data management;XML;business intelligence;cloud computing;data grid;data integration;data mining;data warehousing;database user interface;distributed system;information visualization;knowledge discovery;metadata management;optimization;personal information;privacy;query processing;social network}, 
doi={10.1109/ICDE.2011.5767969}, 
ISSN={1063-6382}, 
month={April},}
@INPROCEEDINGS{7557522, 
author={H. Brabra and A. Mtibaa and L. Sliman and W. Gaaloul and F. Gargouri}, 
booktitle={2016 IEEE International Conference on Services Computing (SCC)}, 
title={Semantic Web Technologies in Cloud Computing: A Systematic Literature Review}, 
year={2016}, 
volume={}, 
number={}, 
pages={744-751}, 
abstract={During the last years we have seen a dramatic increase of new Cloud providers, applications, services, management platforms, data, etc. reaching a level of complexity that implies the necessity of new solutions to deal with such vast, shared and heterogeneous services and resources. Consequently, challenges often related to interoperability, portability, security, discovery, selection, negotiation and description of cloud service and resource may take place. In this sense, Semantic Web Technologies, holding a great potential to cloud computing, have been proven as an efficient means to relive these challenges. This paper examines and explores the role of Semantic Web Technologies in the cloud from a wide variety of literatures. Various approaches, architectures, and frameworks are screened and evaluated based on eight prime research questions. At the end of the review, research opportunities in the form of a roadmap are discussed.}, 
keywords={semantic Web;Semantic Web technologies;cloud computing;cloud providers;cloud service;discovery;interoperability;negotiation;portability;security;selection;systematic literature review;Cloud computing;Computational modeling;Electronic mail;OWL;Ontologies;Semantics;Cloud Computing;Ontologies;Semantic Web Technologies}, 
doi={10.1109/SCC.2016.102}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{6424301, 
author={K. Bilal and S. Mohsin}, 
booktitle={2012 10th International Conference on Frontiers of Information Technology}, 
title={Muhadith: A Cloud Based Distributed Expert System for Classification of Ahadith}, 
year={2012}, 
volume={}, 
number={}, 
pages={73-78}, 
abstract={This paper presents a novel approach for the classification of the religious scriptures, the Hadith (sayings of Prophet Muhammad (plural Ahadith)). Muhadith is a distributed, Cloud based expert system that uses the Hadith science to classify Ahadith among 24 types from seven broad categories. Classification of the Hadith is a complex and sensitive task, and can only be performed by an expert of the Hadith sciences. Muhadith expert system is designed to imitate the Hadith experts for Hadith classification, and to enable a computer to behave like a Hadith expert to discriminate the authentic Ahadith from unauthentic ones. This paper presents the relationship and mapping of the expert system technology onto Hadith sciences, and technicalities involved in designing of the Muhadith expert system. We also propose solutions for the communicational and interoperability problems faced by the legacy web based distributed expert systems. We employ service oriented architecture to overcome the communicational problem and a candidature for the Software as a Service (SaaS) for the Cloud computing. The expert system also provides a reasoning facility that enables the user to look into the classification details. Muhadith expert system has been designed by merging the ideas from the domains of expert systems, Web technologies, and distributed computing systems. This type of an effort on the topic is rare and applying them in the domain of Hadith is our humble contribution.}, 
keywords={cloud computing;expert systems;inference mechanisms;pattern classification;service-oriented architecture;Ahadith classification;Hadith science;Muhadith;Muhadith expert system;Prophet Muhammad;SaaS;Web technologies;cloud based distributed expert system;cloud computing;communicational problems;distributed computing systems;interoperability problems;legacy Web based distributed expert systems;reasoning facility;religious scriptures classification;service oriented architecture;software as a service;Cognition;Data mining;Databases;Engines;Expert systems;Service oriented architecture;Software as a service;Cloud computing;Expert system;Hadith;Islam}, 
doi={10.1109/FIT.2012.22}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6849160, 
author={A. Rafique and S. Walraven and B. Lagaisse and T. Desair and W. Joosen}, 
booktitle={2014 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, 
title={Towards portability and interoperability support in middleware for hybrid clouds}, 
year={2014}, 
volume={}, 
number={}, 
pages={7-12}, 
abstract={The cloud computing paradigm promises increased flexibility and scalability for consumers and providers of software services. Service providers that exploit private cloud environments offer restricted flexibility and scalability because of the limited capacity. However, such organizations are often reluctant to migrate to public clouds because of business continuity threats and vendor lock-in. Hybrid clouds potentially combine the benefits of private and public (external) clouds. Vendor lock-in can be avoided when multiple external clouds are supported and effectively exploited. This paper presents a middleware platform for hybrid cloud applications. The middleware enables organizations to control the execution of their applications in hybrid cloud environments. Driven by policies, the middleware can dynamically decide which requests and tasks are executed on a particular part of the hybrid cloud. The core of the middleware, and the focus of this paper, is an abstraction layer. The abstraction layer enables portability over multiple services including data storage, blob storage, and asynchronous task execution of various PaaS platforms as well as interoperability between the PaaS platforms. We have validated the core concept by building a prototype implementation that runs on top of specific PaaS platforms as well as on a cloud-enabling middleware. A document processing SaaS application has been instantiated on the middleware. Performance results have been collected for JBoss AS cluster, Google App Engine, and Red Hat OpenShift.}, 
keywords={business continuity;cloud computing;middleware;open systems;software portability;Google App Engine;JBoss AS cluster;PaaS platforms;Red Hat OpenShift;abstraction layer;asynchronous task execution;blob storage;business continuity threats;cloud computing paradigm;cloud-enabling middleware;document processing SaaS application;hybrid cloud environments;interoperability support;middleware platform;portability support;private cloud environments;public clouds;software service consumers;software service providers;vendor lock-in;Cloud computing;Conferences;Engines;Google;Interoperability;Software as a service;Hybrid Cloud;Interoperability;Middleware;PaaS;Portability}, 
doi={10.1109/INFCOMW.2014.6849160}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{7289571, 
author={F. Fatemi Moghaddam and M. Ahmadi and S. Sarvari and M. Eslami and A. Golkar}, 
booktitle={2015 1st International Conference on Telematics and Future Generation Networks (TAFGEN)}, 
title={Cloud computing challenges and opportunities: A survey}, 
year={2015}, 
volume={}, 
number={}, 
pages={34-38}, 
abstract={The approval rating of cloud computing as an emerging technology has been enhanced significantly and these days, there are many cloud storage and computing providers who offer their services regarding IaaS, PaaS, and SaaS. Despite these considerable benefits, there are serious concerns and challenges about this new technology. The most important issue is related to security and privacy subjects in cloud-based environments. Furthermore, resource allocation, load balancing, data management, data availability, scalability, compatibility and interoperability are the other challenges in cloud-based environments that decrease efficiency and reliability of this technology. In this paper, challenges and concerns related to cloud-based environments have been identified and most appropriate current solutions for each challenge have been described.}, 
keywords={cloud computing;open systems;resource allocation;security of data;IaaS;PaaS;SaaS;approval rating;cloud computing;cloud storage;cloud-based environment;computing provider;data availability;data compatibility;data interoperability;data management;data scalability;load balancing;resource allocation;Authentication;Cloud computing;Interoperability;Load management;Reliability;Resource management;availability;cloud computing;data management;load balancing;resource allocation;security}, 
doi={10.1109/TAFGEN.2015.7289571}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{7792452, 
author={M. Msahli and A. Serhrouchni and M. Badra}, 
booktitle={2016 8th IFIP International Conference on New Technologies, Mobility and Security (NTMS)}, 
title={Extending TLS with KMIP Protocol for Cloud Computing}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Any information system using encryption tends to have its own key management infrastructure. In practice, we find a separate key management systems dedicated to application encryption, or database encryption, or file encryption etc. This emergent needs to several key management systems and multiple cryptographic algorithms are resolved by the new Key Management Interoperability Protocol (KMIP). This work specifies how the Key Management Interoperability Protocol (KMIP) can be included in Transport Layer Security (TLS) protocol in order to provide additional security features, flexibility, interoperability and authentication specially in distributed systems like Cloud Computing. Till now, authentication in TLS is limited to digital certificate and Kerberos. In this paper, we use the Key Management Interoperability Protocol to make an additional authentication option for TLS and we reduce handshake latency to 0-RTT for repeated handshakes and 1-RTT for full handshakes. We specify also the KMIP-TLS extension and its formal validation with AVISPA tool.}, 
keywords={cloud computing;cryptographic protocols;information systems;open systems;AVISPA tool;KMIP protocol;TLS protocol;authentication;cloud computing;database encryption;file encryption;information system;key management infrastructure;key management interoperability protocol;multiple cryptographic algorithms;transport layer security protocol;Authentication;Cloud computing;Encryption;Protocols;Servers}, 
doi={10.1109/NTMS.2016.7792452}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{7780321, 
author={S. Khalil and V. Fernandez and V. Fautrero}, 
booktitle={2016 IEEE 18th Conference on Business Informatics (CBI)}, 
title={Cloud Impact on IT Governance}, 
year={2016}, 
volume={01}, 
number={}, 
pages={255-261}, 
abstract={Today's competitive environment pushes technology into changing quickly, hence triggering organizations to be ready for such changes. Cloud computing is one of the popular evolving information technologies that seems to affect organizations in different ways, and on different levels. The academic as well as the professional literature focused on identifying the several promoters and inhibitors for adopting cloud solutions. However, the related work does not clearly identify how adopting such solutions affects the organization's IT governance, where implementing effective IT governance is required in order to survive in a competitive market. Therefore, the aim of this research paper is to study the effect of cloud solutions on organizations' IT governance. We first built this paper through an exhaustive literature review describing the various cloud computing promoters and inhibitors, along with the organizational transformations cited by several researchers. Then, in order to validate these transformations and the effects brought by the cloud, we conducted a set of twenty interviews with professionals (CIOs, CEOs, and project managers) from large organizations in France. Our findings endorse the most common elements found in the literature regarding the important considerations when adopting the cloud (security, reversibility, interoperability, etc.) New findings have also been highlighted in our data analysis, cloud computing seems to affect the technological and strategical aspects of IT governance, as well as the business transformation.}, 
keywords={cloud computing;organisational aspects;France;business transformation;cloud computing inhibitors;cloud computing promoters;cloud solutions;organization IT governance;organizational transformations;Bibliographies;Cloud computing;Companies;Inhibitors;Interviews;Adoption;Business Transformation;Cloud Computing;IT Governance}, 
doi={10.1109/CBI.2016.36}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{6391954, 
author={P. Hu and J. Shen and S. Fang}, 
booktitle={2012 IEEE 12th International Conference on Computer and Information Technology}, 
title={Application of Mobile Cloud Computing in Operational Command Training Simulation System}, 
year={2012}, 
volume={}, 
number={}, 
pages={532-535}, 
abstract={Combining cloud computing and mobile computing, a frame of Operational Command Training Simulation System based on mobile cloud computing was proposed, which includes infrastructure, platform, support, application and middleware layer. And the detail design of middleware layer was described. Some key technologies of the layer were settled as: cloud service access adapter, cache management and consistency maintenance strategy, data blocking and parallel processing. The bottleneck of the mobile terminal with limited resources had been solved, and the distribution and interoperability of simulation systems were enhanced.}, 
keywords={cloud computing;computer based training;digital simulation;middleware;military computing;mobile computing;open systems;parallel processing;application layer;cache management;cloud service access adapter;consistency maintenance strategy;data blocking;infrastructure layer;middleware layer;mobile cloud computing;mobile terminal;operational command training simulation system;parallel processing;platform layer;simulation system distribution;simulation system interoperability;support layer;Cloud computing;Computational modeling;Mobile communication;Mobile computing;Servers;Training;adapter;middleware;mobile cloud computing;operational command training;simulation system}, 
doi={10.1109/CIT.2012.116}, 
ISSN={}, 
month={Oct},}
@ARTICLE{7742225, 
author={M. Lacoste and M. Miettinen and N. Neves and F. M. V. Ramos and M. Vukolic and F. Charmet and R. Yaich and K. Oborzynski and G. Vernekar and P. Sousa}, 
journal={IEEE Cloud Computing}, 
title={User-Centric Security and Dependability in the Clouds-of-Clouds}, 
year={2016}, 
volume={3}, 
number={5}, 
pages={64-75}, 
abstract={A promising vision of distributed cloud computing is a unified world of multiple clouds, with business benefits at hand. In practice, lack of interoperability among clouds and management complexity raise many security and dependability concerns. The authors propose secure Supercloud computing as a new paradigm for security and dependability management of distributed clouds. Supercloud follows a user-centric and self-managed approach to avoid technology and vendor lock-ins. In Supercloud, users define U-Clouds, which are isolated sets of computation, data, and networking services run over both private and public clouds operated by multiple providers, with customized security requirements as well as self-management for reducing administration complexity. The article presents the Supercloud architecture with a focus on its security infrastructure. The authors illustrate through several use cases the practical applicability of the Supercloud paradigm.}, 
keywords={cloud computing;reliability;security of data;Supercloud architecture;U-Clouds;clouds-of-clouds;dependability management;distributed cloud computing;private clouds;public clouds;security infrastructure;user-centric security;Cloud computing;Computer architecture;Interoperability;Security management;Virtual machine monitors;Virtualization;cloud computing;multicloud security;security;security self-management;user-centric security management}, 
doi={10.1109/MCC.2016.110}, 
ISSN={2325-6095}, 
month={Sept},}
@INPROCEEDINGS{6414474, 
author={Z. Guo and C. Liu and Y. Feng and F. Hong}, 
booktitle={2012 International Conference on Cloud and Service Computing}, 
title={CCSA: A Cloud Computing Service Architecture for Sensor Networks}, 
year={2012}, 
volume={}, 
number={}, 
pages={25-31}, 
abstract={Sensor network systems have received amounts of attention and become a common practice in many fields. These systems are commonly developed by non-standard technologies, which bring lots of difficulties in system integration and interoperability. To figure out this problem, an integrated sensor network system architecture based on Cloud computing is proposed, which offers anytime service to access different kinds of systems. By abstracting the general model of sensor network system, we present a new architecture and describe the detail model design. In order to confirm the feasibility of the architecture, a Cloud computing service system has been developed to integrate two existing systems. The result shows that the proposed architecture is effective and feasible.}, 
keywords={cloud computing;distributed sensors;open systems;service-oriented architecture;CCSA;any-time service;cloud computing service architecture;cloud computing-based integrated sensor network system architecture;interoperability;model design;nonstandard technologies;two existing systems;Cloud computing;Computational modeling;Data models;Data structures;Instruments;Monitoring;Cloud computing;architecture;sensor network;system integration}, 
doi={10.1109/CSC.2012.12}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{7301415, 
author={C. Alexakos and A. P. Kalogeras}, 
booktitle={2015 IEEE 20th Conference on Emerging Technologies Factory Automation (ETFA)}, 
title={Internet of Things integration to a Multi Agent System based manufacturing environment}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={The Internet of Things (IoT) and its infrastructures for ubiquitous, grid and cloud computing map well with the manufacturing environment and its needs to decentralize and distribute in order to increase its levels of flexibility, agility and dependability. Multi Agent Systems (MAS) make it possible to increase the autonomy and flexibility in the industrial environment allowing for an increase in the level of integration and interoperability of manufacturing applications and systems. Different applications mandate the integration of IoT devices and knowledge in manufacturing processes. The present work presents an approach that makes it possible to integrate IoT devices to a MAS based manufacturing environment.}, 
keywords={Internet of Things;cloud computing;grid computing;manufacturing systems;multi-agent systems;open systems;production engineering computing;Internet of Things integration;IoT;MAS based manufacturing environment;cloud computing;grid computing;interoperability;manufacturing processes;multiagent system based manufacturing environment;ubiquitous computing;Internet of things;Manufacturing;Ontologies;Production;Protocols;Semantics;Sensors;Internet of Things;Manufacturing Systems;Meta-Model;Multi Agent Systems;Ontologies}, 
doi={10.1109/ETFA.2015.7301415}, 
ISSN={1946-0740}, 
month={Sept},}
@INPROCEEDINGS{6529265, 
author={D. Bermbach and T. Kurze and S. Tai}, 
booktitle={2013 IEEE International Conference on Cloud Engineering (IC2E)}, 
title={Cloud Federation: Effects of Federated Compute Resources on Quality of Service and Cost*}, 
year={2013}, 
volume={}, 
number={}, 
pages={31-37}, 
abstract={Cloud Federation is one concept to confront challenges that still persist in Cloud Computing, such as vendor lock-in or compliance requirements. The lack of a standardized meaning for the term Cloud Federation has led to multiple conflicting definitions and an unclear prospect of its possible benefits. Taking a client-side perspective on federated compute services, we analyse how choosing a certain federation strategy affects Quality of Service and cost of the resulting service or application. Based on a use case, we experimentally prove our analysis to be correct and describe the different trade-offs that exist within each of the strategies.}, 
keywords={cloud computing;costing;quality of service;resource allocation;cloud computing;cloud federation;cost;federated compute resources;federated compute services;quality of service;Availability;Benchmark testing;Data models;Delays;Quality of service;Security;Servers}, 
doi={10.1109/IC2E.2013.24}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{6676742, 
author={J. Miranda and J. Guillén and J. M. Murillo and C. Canal}, 
booktitle={2013 IEEE Sixth International Conference on Cloud Computing}, 
title={Assisting Cloud Service Migration Using Software Adaptation Techniques}, 
year={2013}, 
volume={}, 
number={}, 
pages={573-580}, 
abstract={The different implementations of cloud computing services developed by each cloud vendor have resulted in a heterogeneity of APIs and libraries which most developers of cloud-based applications must fight to understand. This so called vendor lock-in effect leads to a substantial increment on the development effort required to switch the initially selected cloud service used by an application to a different one. Different initiatives have emerged to solve this problem, such as standardization attempts, and intermediate systems or middlewares. Instead, our approach makes use software adaptation techniques for tackling the vendor lock-in problem and facilitating the development of cloud applications that are not coupled to any specific platform. In this paper, a case study application is presented in order to illustrate how the vendor lock-in effect appears and to make an estimation of the effort required for its migration to a different platform. This way we show the benefits of our approach for reducing the cloud service migration efforts. Such solution is sketched briefly, and the main steps of the adaptation process are described.}, 
keywords={application program interfaces;cloud computing;libraries;API;case study application;cloud computing services;cloud service migration;cloud-based applications;intermediate systems;libraries;middlewares;software adaptation techniques;standardization attempts;vendor lock-in effect;Adaptation models;Cloud computing;Estimation;Libraries;Protocols;adaptation;cloud;component;computing;migration}, 
doi={10.1109/CLOUD.2013.35}, 
ISSN={2159-6182}, 
month={June},}
@INPROCEEDINGS{7328120, 
author={P. Scandurra and G. Psaila and R. Capilla and R. Mirandola}, 
booktitle={2015 IEEE 9th International Symposium on the Maintenance and Evolution of Service-Oriented and Cloud-Based Environments (MESOCA)}, 
title={Challenges and assessment in migrating IT legacy applications to the cloud}, 
year={2015}, 
volume={}, 
number={}, 
pages={7-14}, 
abstract={The incessant trend where software engineers need to redesign legacy systems adopting a service-centric engineering approach brings new challenges for software architects and developers. Today, engineering and deploying software as a service requires specific Internet protocols, middleware and languages that often complicate the interoperability of software at all levels. Moreover, cloud computing demands stringent quality requirements, such as security, scalability, and interoperability among others, to provide services and data across networks more efficiently. As software engineers must face the problem to redesign and redeploy systems as services, we explore in this paper the challenges found during the migration of an existing system to a cloud solution and based on a set of quality requirements that includes the vendor Lock-in factor. We also present a set of assessment activities and guidelines to support migration to the Cloud by adopting SOA and Cloud modeling standards and tools.}, 
keywords={cloud computing;open systems;service-oriented architecture;software maintenance;IT legacy applications;Internet protocols;SOA;cloud computing;cloud modeling standards;middleware;service-centric engineering approach;software as a service;software interoperability;vendor lock-in factor;Business;Cloud computing;Interoperability;Scalability;Service-oriented architecture;Software as a service;Cloud computing;cloud migration;cloud modeling;interoperability;portability;service-centric engineering;service-oriented architecture;service-oriented computing;vendor Lock-in}, 
doi={10.1109/MESOCA.2015.7328120}, 
ISSN={2326-6910}, 
month={Oct},}
@INPROCEEDINGS{6079471, 
author={R. Lee and B. Jeng}, 
booktitle={2011 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery}, 
title={Load-Balancing Tactics in Cloud}, 
year={2011}, 
volume={}, 
number={}, 
pages={447-454}, 
abstract={Cloud computing enables shared servers to provide resources, software and data for collaborative services on demand with high interoperability and scalability. However, there are a number of technical challenges that need to be tackled before these benefits can be fully realized, which include system reliability, resource provisioning, and efficient resources consuming, etc. Among them, load-balancing is a necessary mechanism to increase the service level agreement (SLA) and better uses of the resources. Unfortunately, servers' capability varies much in practice and is not easy to record in ordered positions in a server farm, which will causes non resource-aware load-balancing algorithms to distribute workloads evenly. We discuss this issue and show why such algorithms don't fit the cloud computing environment and then present a feasible resource-aware load balancing mechanism by using existing proven technologies to meet higher SLA and the return of investment as well.}, 
keywords={cloud computing;groupware;resource allocation;cloud computing;collaborative service;investment;load-balancing tactics;nonresource-aware load-balancing algorithm;resource provisioning;resource-aware load balancing mechanism;server farm;service level agreement;shared server;system reliability;workload distribution;Cloud computing;Computational modeling;Computer architecture;Delay;Load modeling;Servers}, 
doi={10.1109/CyberC.2011.79}, 
ISSN={}, 
month={Oct},}
@ARTICLE{7030248, 
author={Z. Jin and Y. Chen}, 
journal={IEEE Pervasive Computing}, 
title={Telemedicine in the Cloud Era: Prospects and Challenges}, 
year={2015}, 
volume={14}, 
number={1}, 
pages={54-61}, 
abstract={The combination of cloud computing and telemedicine introduces new opportunities for transforming healthcare delivery in a more effective and sustainable manner. A number of telemedicine applications have been investigated and developed on the cloud, such as telemonitoring and teleconsultation, all of which fully demonstrate the potential of telemedicine in promoting more affordable and higher quality healthcare through the adoption of emerging cloud and mobile technologies. The need to deploy cloud-based telemedicine has also presented numerous challenges, including how to achieve high assurance, interoperability, security and privacy, and storage adaptability. This article discusses these challenges and several open research issues, with the goal of inspiring research and development in this rising area.}, 
keywords={cloud computing;telemedicine;cloud computing;cloud-based telemedicine;healthcare delivery;Cloud computing;Medical diagnostic imaging;Medical services;Mobile communication;Mobile handsets;Telemedicine;cloud computing;healthcare;interoperability;mobile;pervasive computing;privacy;security;telemedicine}, 
doi={10.1109/MPRV.2015.19}, 
ISSN={1536-1268}, 
month={Jan},}
@INPROCEEDINGS{7819681, 
author={D. Sitaram and S. Harwalkar and K. V. S. Kumar}, 
booktitle={2016 IEEE International Conference on Cloud Computing in Emerging Markets (CCEM)}, 
title={Standards Based Integration of Intercloud for Federation with OpenStack}, 
year={2016}, 
volume={}, 
number={}, 
pages={113-118}, 
abstract={Cloud computing model has been among the main stream popular new technologies by providing services such as software, platform and infrastructure. In the process of providing better services for customers, cloud service providers have developed proprietary standards on how cloud application interacts with their cloud. This has been limiting the cloud adoption because of the vendor lock-in and portability issues. The need for the business application on clouds to be interoperable is increasing. The cloud federation would be the solution in providing on demand resources and better scalability. The IEEE cloud computing working standard groups have certain standards to build interoperable cloud environment. The paper explores the approach for cloud federation by using standard protocols by implementing IEEE standards as a proof of concept using multiple OpenStack environment, which can be easily extended to other clouds (AWS, Azure, VMware) and finally conclude with benefits of using standards based federation.}, 
keywords={IEEE standards;cloud computing;open systems;public domain software;resource allocation;software portability;IEEE cloud computing working standard groups;IEEE standards;OpenStack environment;business application;cloud adoption;cloud application;cloud computing model;cloud federation;cloud service providers;customer services;intercloud integration;interoperable cloud environment;on demand resources;portability issues;standards based Integration;vendor lock-in issues;Cloud computing;Interoperability;Logic gates;Protocols;Servers;Standards;Cloud Computing;Cost Efficiency;Intercloud;Interoperability;XMPP;federation OpenStack}, 
doi={10.1109/CCEM.2016.028}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{7507161, 
author={M. A. Macedo and D. A. S. Carvalho and M. A. Musicante and A. Pardo and U. S. Costa}, 
booktitle={2015 IEEE/ACS 12th International Conference of Computer Systems and Applications (AICCSA)}, 
title={An abstract machine for integrating heterogeneous web applications}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={The adoption of Cloud Computing technologies by the organizations has profound consequences on the way software applications are developed and used. The migration to the Cloud may be accompanied by the revision of the business process, to integrate tasks over big data. In this way, existing workflow implementations may be extended with calls to operations in Hadoop or other tools. In this work, we define a framework to implement business process over heterogeneous technologies. Our framework is based on a novel workflow engine, called μBP-AM. Workflow execution in μBP-AM is performed by successively transforming the graph obtained from a workflow definition. μBP-AM has a formal semantics, which gives a precise definition of how the workflow is implemented. μBP-AM is at the core of an extensible framework capable of supporting not only Web service operations but also Hadoop operation calls (among others). The tool described here was conceived to increase reliability and to promote interoperability. We describe a prototype implementation of our framework, as well as some experimental results. Experiments using this prototype show that compositions run in μBP-AM using about the same resources as those run by using other tools.}, 
keywords={Web services;business data processing;cloud computing;open systems;parallel processing;program compilers;μBP-AM;Big Data;Hadoop operation;Web service operations;abstract machine;business process;cloud computing technologies;formal semantics;heterogeneous Web applications;heterogeneous technologies;interoperability;reliability;software application development;workflow engine;workflow execution;workflow implementations;Big data;Engines;Organizations;Reliability;Runtime;Web services;Abstract Machine;Big Data;Integration;Interoperability;Operational Semantics}, 
doi={10.1109/AICCSA.2015.7507161}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{7337000, 
author={M. Thabet and M. Boufaida}, 
booktitle={2015 International Conference on Cloud Technologies and Applications (CloudTech)}, 
title={A SCA based model for resolving syntactic heterogeneity among clouds}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Nowadays, companies are increasingly adopting the technology of cloud computing. This technology allows them to innovate and to improve their business. Plus, the presence of numerous cloud providers would be beneficial for providers and companies if some collaboration among clouds will be achieved. This collaboration lets companies to choose and to move their applications and data among clouds without being tied to any provider. We have embedded the Service Component Architecture in the cloud computing domain. The proposed model aims at facilitating the data sharing between multiple cloud service providers regardless their infrastructure, tools and platforms. Indeed, we have opted for SCA standard to promote the interoperability mechanism by moving and converting data formats exchanged among clouds. Our model allows many providers to interact among each other by overcoming the syntactic heterogeneity in order to satisfy companies' needs.}, 
keywords={business data processing;cloud computing;data handling;open systems;SCA based model;SCA standard;cloud application;cloud collaboration;cloud computing domain;cloud computing technology;cloud data;cloud service providers;cloud syntactic heterogeneity resolution;data format;data sharing;interoperability mechanism;service component architecture;Adaptation models;Cloud computing;Companies;Data mining;Data models;Interoperability;Load modeling;Cloud computing;SCA;adaptation;heterogeneity;interoperability;service component;syntactic}, 
doi={10.1109/CloudTech.2015.7337000}, 
ISSN={}, 
month={June},}
@ARTICLE{6200250, 
author={A. Edmonds and T. Metsch and A. Papaspyrou and A. Richardson}, 
journal={IEEE Internet Computing}, 
title={Toward an Open Cloud Standard}, 
year={2012}, 
volume={16}, 
number={4}, 
pages={15-25}, 
abstract={Today's cloud ecosystem features several increasingly divergent management interfaces. Numerous bridging efforts attempt to ameliorate the resulting vendor lock-in for customers. However, as the number of providers continues to grow, the drawback of this approach becomes apparent: the need to maintain adapter implementations. The Open Cloud Computing Interface builds on the fundamentals of modern Web-based services to define a standardized interface for cloud environments while enabling service providers to differentiate their service offerings at the same time.}, 
keywords={Web services;cloud computing;customer relationship management;open systems;user interfaces;Web-based services;adapter implementations;cloud ecosystem;cloud environments;divergent management interfaces;open cloud computing interface;open cloud standard;service providers;standardized interface;Cloud computing;Computational modeling;Ecosystems;Rendering (computer graphics);Standards;Cloud computing;Computational modeling;Ecosystems;OCCI;Rendering (computer graphics);Standards;cloud computing;open cloud computing interface;standardization}, 
doi={10.1109/MIC.2012.65}, 
ISSN={1089-7801}, 
month={July},}
@ARTICLE{7828007, 
author={P. Zhang and Y. Liu and M. Qiu}, 
journal={IEEE Transactions on Cloud Computing}, 
title={SNC: A Cloud Service Platform for Symbolic-Numeric Computation using Just-In-Time Compilation}, 
year={2017}, 
volume={PP}, 
number={99}, 
pages={1-1}, 
abstract={Cloud services have been widely employed in IT industry and scientific research. By using Cloud services users can move computing tasks and data away from local computers to remote datacenters. By accessing Internet-based services over lightweight and mobile devices, users deploy diversified Cloud applications on powerful machines. The key drivers towards this paradigm for the scientific computing field include the substantial computing capacity, on-demand provisioning and cross-platform interoperability. To fully harness the Cloud services for scientific computing, however, we need to design an application-specific platform to help the users efficiently migrate their applications. In this, we propose a Cloud service platform for symbolic-numeric computation– SNC. SNC allows the Cloud users to describe tasks as symbolic expressions through C/C++, Python, Java APIs and SNC script. Just-In-Time (JIT) compilation through using LLVM/JVM is used to compile the user code to the machine code. We implemented the SNC design and tested a wide range of symbolic-numeric computation applications (including nonlinear minimization, Monte Carlo integration, finite element assembly and multibody dynamics) on several popular cloud platforms (including the Google Compute Engine, Amazon EC2, Microsoft Azure, Rackspace, HP Helion and VMWare vCloud). These results demonstrate that our approach can work across multiple cloud platforms, support different languages and significantly improve the performance of symbolic-numeric computation using cloud platforms. This offered a way to stimulate the need for using the cloud computing for the symbolic-numeric computation in the field of scientific research.}, 
keywords={Cloud computing;Java;MATLAB;Runtime;Scientific computing;Virtual machining;Cloud computing;JVM;LLVM;just-in-time compilation;symbolic-numeric computation}, 
doi={10.1109/TCC.2017.2656088}, 
ISSN={2168-7161}, 
month={},}
@INPROCEEDINGS{7391401, 
author={D. R. Posircaru and L. Dan Serbanati}, 
booktitle={2015 E-Health and Bioengineering Conference (EHB)}, 
title={Integrating legacy medical applications in a standardized Electronic Health Record platform}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-4}, 
abstract={An architecture for integrating legacy applications into the Romanian Health Information System platform is proposed. Such an integration is needed because a lack of interoperability between legacy medical applications and the Health Information Platform continues to exist. To solve the integration problem and create a true Unique Integrated Health Information System able to support all healthcare activities in the Romanian Health System the proposed architecture introduces a HL7-standardized Electronic Health Record (EHR) that uses cloud computing technologies and a HL7 Adapter. The Adapter integrates the legacy medical applications that generate electronic prescriptions in-house format as they are currently reported to the National Health Insurance House into the Electronic Health Record platform by converting their messages into HL7 Messages.}, 
keywords={cloud computing;electronic health records;health care;HL7 adapter;National Health Insurance House;Romanian health information system platform;cloud computing technology;electronic health record platform;electronic prescription in-house format;healthcare activity;legacy medical application;Adaptation models;Cloud computing;Computer architecture;Information systems;Medical services;Standards;XML;Cloud Computing;Electronic Health Record platform;HL7 Adapter;electronic prescription;legacy medical applications}, 
doi={10.1109/EHB.2015.7391401}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{5439441, 
author={A. K. Talukder and H. A. Prahalad}, 
booktitle={2009 IEEE International Conference on Internet Multimedia Services Architecture and Applications (IMSAA)}, 
title={Security #x00026; scalability architecture for next generation internet services}, 
year={2009}, 
volume={}, 
number={}, 
pages={1-4}, 
abstract={Next Generation Internet Applications will experience many paradigm shifts from what we have seen so far. Through various technologies like applications mash-up, content aggregations, grid computing, cloud computing, Web 2.0, Web 3.0, applications will have to adopt novel software engineering techniques for development and deployment. Scalability, Interoperability, Availability (tolerance to failure), Accounting (journaling, billing), and Security (confidentiality, integrity, authentication, authorization), and Anonymity are some of the important quality and usability features that will determine the success of new Internet applications. This position paper proposes how these complex challenges can be managed.}, 
keywords={Internet;grid computing;innovation management;open systems;security of data;software engineering;Web 2.0;Web 3.0;accounting;anonymity;applications mash up;availability;cloud computing;content aggregations;grid computing;interoperability;next generation Internet services;scalability architecture;security architecture;software engineering techniques;Application software;Authentication;Authorization;Cloud computing;Computer architecture;Grid computing;Scalability;Security;Software engineering;Web and internet services;Cloud Computing;Next Generation Internet;Scalability and Security aware Software Development Life Cycle, SaSDLC;Security-aware}, 
doi={10.1109/IMSAA.2009.5439441}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{7382217, 
author={M. Bobák and L. Hluchý and V. Tran}, 
booktitle={2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)}, 
title={Methodology for intercloud multicriteria optimization}, 
year={2015}, 
volume={}, 
number={}, 
pages={1786-1791}, 
abstract={The idea of offering computing resources over the network is very popular nowadays. This concept is called cloud computing and it is one of the computer science buzzword. We are interested in interoperability. We are attracted by cloud collaboration and multicriteria optimization in the multicloud environment. This thoughts we model by multicloud computing architecture and multicriteria optimization problem.}, 
keywords={cloud computing;groupware;open systems;operations research;optimisation;software architecture;cloud collaboration;cloud computing;computer science;computing resources;intercloud multicriteria optimization;interoperability;multicloud computing architecture;Cloud computing;Collaboration;Elasticity;Optimization;Scalability;Virtual machining;architecture;cloud computing;collaboration;methodology;optimization;scalability}, 
doi={10.1109/FSKD.2015.7382217}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{6316656, 
author={B. M. Nguyen and V. Tran and L. Hluchy}, 
booktitle={2011 6th International Conference on Computer Sciences and Convergence Information Technology (ICCIT)}, 
title={A high-level abstraction layer for cloud computing}, 
year={2011}, 
volume={}, 
number={}, 
pages={446-449}, 
abstract={In this paper, we will present a high-level abstraction layer for development and deployment of cloud services. The abstraction layer will abstract and control cloud resources via reference object, simultaneously allows users to simplify the process of porting applications to different clouds. This approach could improve the flexibility of Cloud computing, enable interoperability and simplify the creation of more complex systems in the Cloud.}, 
keywords={cloud computing;object-oriented programming;open systems;resource allocation;application porting;cloud computing;cloud resource abstraction;cloud resource control;cloud service deployment;cloud service development;high-level abstraction layer;interoperability;object-oriented programming;reference object;Abstracts;Cloud computing;Home appliances;IP networks;Optimization;Virtual machining;cloud computing;high-level abstraction;object-oriented programming;service deployment;service development}, 
doi={}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{6382904, 
author={J. Chen and X. Wu and S. Zhang and W. Zhang and Y. Niu}, 
booktitle={2012 Second International Conference on Cloud and Green Computing}, 
title={A Decentralized Approach for Implementing Identity Management in Cloud Computing}, 
year={2012}, 
volume={}, 
number={}, 
pages={770-776}, 
abstract={Cloud computing is the next generation of computing paradigm. Along with cloud computing, many related problems come up. And these problems in turn slow the speed of the development of cloud computing down. Among these problems, e.g. interoperability and privacy, identity management and security are strong concerned. Many researchers and enterprises have already done a lot to optimize the identity management and strengthen the security in cloud computing. Most of these studies focus on the usability of identity management and various kinds of method to help improve security. But in this paper, we do some research from a new angle. While the federated solution of identity management helps relieve many problems, it's adopted by many platforms and enterprises. The general approach for deploying identity management is a centralized component processing authentication and authorization requests. But with the cloud growing in scale and the increasing number of users, this centralized solution will be the bottleneck of the cloud. In this paper, we propose a decentralized approach for implementing identity management in service oriented architecture in cloud computing and a grouping algorithm as the deploy strategy. Security is another problem involved in this paper. Since many researchers have done many detailed and fruitful studies in security, the security solution illustrated in this paper is specific in the proposed architecture.}, 
keywords={cloud computing;data privacy;open systems;service-oriented architecture;SOA;centralized component processing authentication requests;centralized component processing authorization requests;cloud computing;decentralized approach;federated solution;grouping algorithm;identity management deploying strategy;identity management optimization;identity management usability;interoperability problems;privacy problems;security improvement;service-oriented architecture;Authentication;Authorization;Cloud computing;Computer architecture;Intrusion detection;Service oriented architecture;cloud computing;grouping algorithm;identity management (IdM);security;service oriented architecture (SOA)}, 
doi={10.1109/CGC.2012.118}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{7226670, 
author={H. Wu and D. Huang and M. Chen}, 
booktitle={2015 IEEE International Conference on Mobile Services}, 
title={POEM: On Establishing a Personal On-Demand Execution Environment for Mobile Cloud Applications}, 
year={2015}, 
volume={}, 
number={}, 
pages={41-48}, 
abstract={A distributed mobile cloud service model called "POEM" is presented to manage the mobile cloud resource and compose mobile cloud applications. POEM provides the following salient features: (a) it considers resource management not only between mobile devices and clouds, but also among mobile devices, (b) it utilizes the entire mobile cloud system as the mobile application running platform, and as a result, the mobile cloud application development is significantly simplified and enriched, and (c) it addresses the interoperability issues among mobile devices and cloud resource providers to allow mobile cloud applications running cross various cloud virtual machines and mobile devices. The proposed POEM solution is demonstrated by using OSGi and XMPP techniques. Our performance evaluations demonstrate that POEM provides a true elastic application running environment for mobile cloud computing.}, 
keywords={cloud computing;mobile computing;virtual machines;POEM;cloud resource providers;distributed mobile cloud service model;mobile cloud resource;mobile devices;personal on-demand execution environment;virtual machines;Cloud computing;Java;Mobile communication;Mobile handsets;Runtime;Virtual machining;OSGi;XMPP;mobile cloud computing;offloading;service oriented architecture}, 
doi={10.1109/MobServ.2015.16}, 
ISSN={2329-6429}, 
month={June},}
@INPROCEEDINGS{7471190, 
author={A. Longo and M. Zappatore and M. A. Bochicchio and B. Livieri and N. Guarino and D. Napoleone}, 
booktitle={2016 30th International Conference on Advanced Information Networking and Applications Workshops (WAINA)}, 
title={Cloud for Europe: The Experience of a Tenderer}, 
year={2016}, 
volume={}, 
number={}, 
pages={153-158}, 
abstract={In 2013, in the context of the Seventh Framework Programme (FP7), the European Commission promoted a major initiative addressing cloud computing and the public sector, named Cloud-for-Europe (C4E), for the creation of a digital single market of IT services in the cloud. That initiative pushes public sector organizations from Member States for preparing themselves in procuring secure, cost-effective, reliable and trustworthy cloud services. C4E has adopted the Pre-Commercial Procurement (PCP) instrument for involving not only public sector entities but also IT, Telcos, and SMEs in providing innovative cloud-based solutions that best fit public sector's needs. In this paper, after presenting a brief overview of C4E initiative and the current European scenario for public cloud services and cloud projects, we discuss the lessons learned on the relevance of achieving cross-border interoperability between public cloud computing services, deriving from our successful participation at the first PCP phase as tenderers.}, 
keywords={cloud computing;open systems;procurement;C4E tenderers;Cloud-for-Europe;European Commission;FP7;IT services;PCP phase;SME;Seventh Framework Programme;Telcos;cloud computing;cloud projects;cross-border interoperability;member states;precommercial procurement;public cloud computing services;public sector organizations;secure-cost-effective-reliable trustworthy cloud services;Certification;Cloud computing;Europe;Industries;Procurement;Security;Cloud Computing Service Interoperability;Cloud Computing Services;Cloud for Europe (C4E);Pre-Commercial Procurement (PCP)}, 
doi={10.1109/WAINA.2016.66}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{6588163, 
author={}, 
booktitle={2013 1st International Conference Exhibition on the Applications of Information Technology to Renewable Energy Processes and Systems}, 
title={Track B-3: Smart systems for renewable energy}, 
year={2013}, 
volume={}, 
number={}, 
pages={113-113}, 
abstract={This track explores the many areas of Information Technology necessary for the development of Smart Grids and Smart Cities. It focuses on achieving social sustainability as well as environmental sustainability for smart cities. The track considers issues related to Infrastructure, communications, networking, sensors, monitoring, measurement, smart meters, Smart control, scheduling, Fault tolerance, security and interoperability of smart grids. Information Technology topics covered in this track includes: Pervasive computing; Intelligent & Expert systems; Embedded systems; Smart scheduling systems; Control/Remote control systems; Data acquisition systems; Internet and Web applications; Cloud computing; Grid computing; Mobile computing; Parallel and distributed systems; Wireless data communication systems; Mobile Ad Hoc networks; Wireless sensor networks; Green cellular networks; Green communication devices; Green networks.}, 
keywords={}, 
doi={10.1109/IT-DREPS.2013.6588163}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{6206764, 
author={T. S. Somasundaram and K. Govindarajan and m. r. Rajagopalan and S. M. Rao}, 
booktitle={2012 International Conference on Recent Trends in Information Technology}, 
title={An architectural framework to solve the interoperability issue between private clouds using semantic technology}, 
year={2012}, 
volume={}, 
number={}, 
pages={162-167}, 
abstract={Cloud Computing is the blending technology of parallel and distributing computing paradigm, and its main aim is providing Everything as a Service (XaaS) to the consumers. The Infrastructure as a Service (IaaS) is one type of service models in Cloud Computing to provide infrastructure to the customers. The private cloud is one of the deployment models in cloud computing, and it offers resources to the consumers in an on-demand manner within or inside the organization. It is managed by different type of cloud middleware's and each them have their own mechanism and protocols. So there is an interoperability issue between these different type of private clouds, to solve this issue it is essential to describe a common mechanism. In this paper, we have devised a a broker based architectural framework to solve the interoperability issue between the Eucalyptus and OpenNebula based private clouds. The proposed work has incorporated with semantic based resource description and discovery, capacity based resource selection and resource provisioning mechanism. The proposed framework solves the interoperability between private clouds, enhances the efficiency of cloud resources, increases the scheduling success rate resulting in increase of throughput of application requests submitted to the resource broker in a better manner.}, 
keywords={cloud computing;middleware;open systems;Eucalyptus based private clouds;IaaS;OpenNebula based private clouds;XaaS;architectural framework;broker based architectural framework;capacity based resource selection;cloud computing;cloud middleware;cloud resources;distributed computing paradigm;everything as a service;infrastructure as a service;interoperability issue;parallel computing paradigm;resource provisioning mechanism;semantic based resource description;semantic based resource discovery;semantic technology;Cloud computing;Computational modeling;Knowledge based systems;Ontologies;Semantics;Eucalyptus;Interoperability;Open Nebula;RESTful webservice;Resource Management;Semantic}, 
doi={10.1109/ICRTIT.2012.6206764}, 
ISSN={}, 
month={April},}
@ARTICLE{8010408, 
author={Y. Sahni and J. Cao and S. Zhang and L. Yang}, 
journal={IEEE Access}, 
title={Edge Mesh: A New Paradigm to Enable Distributed Intelligence in Internet of Things}, 
year={2017}, 
volume={5}, 
number={}, 
pages={16441-16458}, 
abstract={In recent years, there has been a paradigm shift in Internet of Things (IoT) from centralized cloud computing to edge computing (or fog computing). Developments in ICT have resulted in the significant increment of communication and computation capabilities of embedded devices and this will continue to increase in coming years. However, existing paradigms do not utilize low-level devices for any decision-making process. In fact, gateway devices are also utilized mostly for communication interoperability and some low-level processing. In this paper, we have proposed a new computing paradigm, named Edge Mesh, which distributes the decision-making tasks among edge devices within the network instead of sending all the data to a centralized server. All the computation tasks and data are shared using a mesh network of edge devices and routers. Edge Mesh provides many benefits, including distributed processing, low latency, fault tolerance, better scalability, better security, and privacy. These benefits are useful for critical applications, which require higher reliability, real-time processing, mobility support, and context awareness. We first give an overview of existing computing paradigms to establish the motivation behind Edge Mesh. Then, we describe in detail about the Edge Mesh computing paradigm, including the proposed software framework, research challenges, and benefits of Edge Mesh. We have also described the task management framework and done a preliminary study on task allocation problem in Edge Mesh. Different application scenarios, including smart home, intelligent transportation system, and healthcare, are presented to illustrate the significance of Edge Mesh computing paradigm.}, 
keywords={Internet of Things;cloud computing;embedded systems;internetworking;mobility management (mobile radio);network servers;open systems;software fault tolerance;ICT;Internet-of-Things;IoT;centralized cloud computing;centralized server;communication capabilities;communication interoperability;computation capabilities;context awareness;decision-making tasks;distributed intelligence;distributed processing;edge computing;edge mesh computing paradigm;embedded devices;fault tolerance;fog computing;gateway devices;healthcare;intelligent transportation system;mobility support;real-time processing;smart home;software framework;task allocation problem;task management framework;Cloud computing;Decision making;Edge computing;Resource management;Security;Sensors;Servers;Edge devices;Internet of Things;distributed computing;distributed intelligence;mesh network}, 
doi={10.1109/ACCESS.2017.2739804}, 
ISSN={}, 
month={},}
@INPROCEEDINGS{6354585, 
author={N. R. Challa}, 
booktitle={2012 IEEE International Conference on Cloud Computing in Emerging Markets (CCEM)}, 
title={A CIM (Common Information Model) Based Management Model for Clouds}, 
year={2012}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={The recently emerged Cloud Computing paradigm poses new management challenges because of its complex, heterogeneous infrastructure. A cloud contains infrastructure (Servers, Storage, Networks), applications (web apps, database, backup etc.) from various vendors. Generally, different vendor products are managed (discovery, provisioning, monitoring etc.) by their own proprietary management software. Today, in clouds there is no standard way to manage infrastructure and applications using a single management framework. This will cause cloud management a complex task and creates interoperability issues. The Cloud infrastructure cannot be easily replaced due to dependency on the management software. In this paper we will present various independent CIM (Common Information Model) based Management models available as today, their applicability to cloud infrastructure, advantages etc.}, 
keywords={cloud computing;information management;open systems;CIM based management model;cloud computing paradigm;cloud management;common information model;heterogeneous infrastructure;interoperability issues;management framework;proprietary management software;vendor products;Computational modeling;Computer integrated manufacturing;Object oriented modeling;Servers;Software;Standards}, 
doi={10.1109/CCEM.2012.6354585}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6123444, 
author={V. Bernardo and M. Curado and T. Staub and T. Braun}, 
booktitle={2011 First International Symposium on Network Cloud Computing and Applications}, 
title={Towards Energy Consumption Measurement in a Cloud Computing Wireless Testbed}, 
year={2011}, 
volume={}, 
number={}, 
pages={91-98}, 
abstract={The evolution of the Next Generation Networks, especially the wireless broadband access technologies such as Long Term Evolution (LTE) and Worldwide Interoperability for Microwave Access (WiMAX), have increased the number of "all-IP" networks across the world. The enhanced capabilities of these access networks has spearheaded the cloud computing paradigm, where the end-users aim at having the services accessible anytime and anywhere. The services availability is also related with the end-user device, where one of the major constraints is the battery lifetime. Therefore, it is necessary to assess and minimize the energy consumed by the end-user devices, given its significance for the user perceived quality of the cloud computing services. In this paper, an empirical methodology to measure network interfaces energy consumption is proposed. By employing this methodology, an experimental evaluation of energy consumption in three different cloud computing access scenarios (including WiMAX) were performed. The empirical results obtained show the impact of accurate network interface states management and application network level design in the energy consumption. Additionally, the achieved outcomes can be used in further software-based models to optimized energy consumption, and increase the Quality of Experience (QoE) perceived by the end-users.}, 
keywords={IP networks;Long Term Evolution;WiMax;cloud computing;energy consumption;network interfaces;next generation networks;LTE;Long Term Evolution;WiMAX;access network;all-IP network;application network level design;battery lifetime;cloud computing wireless testbed;energy consumption measurement;network interface;next generation network;quality of experience;services availability;wireless broadband access technology;worldwide interoperability for microwave access;Cloud computing;Energy consumption;Energy measurement;IEEE 802.11 Standards;Network interfaces;Universal Serial Bus;WiMAX;4G networks;Cloud Computing;Energy;Measurement;Testbed;Wireless}, 
doi={10.1109/NCCA.2011.22}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{6481063, 
author={D. Tovarnák and T. Pitner}, 
booktitle={2012 14th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing}, 
title={Towards multi-tenant and interoperable monitoring of virtual machines in cloud}, 
year={2012}, 
volume={}, 
number={}, 
pages={436-442}, 
abstract={The advent of Cloud Computing introduced new challenges in various computer science fields and disciplines, monitoring being one of them. Due to the multi-tenant nature of Cloud environment, its size and use of massive virtualization, the current monitoring solutions are approaching their limits. Unlike some other approaches, focusing on data integration, aggregation, and abstraction, our work focuses on a virtual machine representing the primary source of monitoring information. In this paper, we propose requirements for the producer of monitoring information addressing existing issues related to monitoring data representation, storage, processing and distribution. As a proof-of-concept, conforming to these requirements, prototype of event-based monitoring daemon is presented in detail. The resulting solution allows multiple users to consume monitoring information in an extensible data format without impairing interoperability.}, 
keywords={cloud computing;data handling;data structures;open systems;system monitoring;virtual machines;virtualisation;cloud computing;cloud environment;event-based monitoring daemon prototype;interoperable monitoring;monitoring data distribution;monitoring data processing;monitoring data representation;monitoring data storage;multitenant monitoring;primary monitoring information source;virtual machines;virtualization;Cloud computing;Data models;Hardware;Monitoring;Protocols;Security;Virtual machining;cloud;management;monitoring;multi-tenancy}, 
doi={10.1109/SYNASC.2012.55}, 
ISSN={}, 
month={Sept},}
@INBOOK{7827475, 
author={Tyson T. Brooks}, 
booktitle={Cyber-Assurance for the Internet of Things}, 
title={A Steady???State Framework for Assessing Security Mechanisms in a Cloud???of???Things Architecture}, 
year={2017}, 
volume={}, 
number={}, 
pages={520-}, 
abstract={The ability to process large amounts of data with the integration of the Internet of Things (IoT) and cloud computing environments means organizations can trade sophisticated security estimation techniques for more accurate and simple models. By determining tactical and technical parameters of Cloud???of???Things (CoT) wireless equipment and systems, discovering irregularities of electronic tags and their threat levels and analyzing tags/readers strong and weak APs provide the interoperability for organizing and carrying out CoT defense. The basic task of the steady???state model for the CoT will be to support the defense for the CoT network through detecting technical loopholes and topographic structures from the various CoT networks and the data/information stored inside the system. The CoT system will possess a function of automatic identity recognition and needs a steady???state framework for measuring security components and mechanisms of computing devices, communication networks, and sensing devices.}, 
keywords={}, 
doi={10.1002/9781119193784.ch9}, 
ISSN={}, 
publisher={Wiley-IEEE Press}, 
isbn={9781119193784}, 
url={http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7827475},}
@INPROCEEDINGS{6405458, 
author={R. Matos and J. Araujo and V. Alves and P. Maciel}, 
booktitle={2012 IEEE 23rd International Symposium on Software Reliability Engineering Workshops}, 
title={Characterization of Software Aging Effects in Elastic Storage Mechanisms for Private Clouds}, 
year={2012}, 
volume={}, 
number={}, 
pages={293-298}, 
abstract={Cloud computing systems fundamentally provide access to large pools of data and computational resources. Eucalyptus is a software framework used to implement private and hybrid-style Infrastructure as a Service clouds. It implements the Amazon Web Service (AWS) API, allowing interoperability with other AWS-based services. Elastic block storage (EBS) is a technology which provides flexible allocation of remote storage volumes to the virtual machines running in a cloud computing environment. Eucalyptus interacts with many software components to provide EBS features to the virtual machines: KVM hypervisor and Eucalyptus Node Controller (NC) are among those components. This work investigates the software aging effects in a Eucalyptus environment, considering workloads composed of intensive requests for attaching remote storage volumes to virtual machines. The results evidenced that memory leaks in Node Controller and the high CPU utilization by the KVM process are strongly correlated. The experimental analysis also show how much the aging effects are related to the performance degradation of a virtualized web server running on this infrastructure.}, 
keywords={Web services;application program interfaces;cloud computing;information storage;resource allocation;software reliability;virtual machines;AWS API;AWS-based services;Amazon Web Service API;CPU utilization;EBS features;Eucalyptus node controller;KVM hypervisor;KVM process;NC;cloud computing environment;cloud computing systems;computational resources;elastic block storage;elastic storage mechanisms;hybrid-style infrastructure;memory leakage;private clouds;remote storage volumes;service clouds;software aging effect characterization;software components;software framework;virtual machines;virtualized Web server;Aging;Correlation;Process control;Random access memory;Software;Time factors;Virtual machining;Cloud computing;KVM hypervisor;performance evaluation;software aging}, 
doi={10.1109/ISSREW.2012.82}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{6968495, 
author={F. Dudouet and P. Harsh and S. Ruiz and A. Gomes and T. M. Bohnert}, 
booktitle={2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)}, 
title={A case for CDN-as-a-service in the cloud: A Mobile Cloud Networking argument}, 
year={2014}, 
volume={}, 
number={}, 
pages={651-657}, 
abstract={Content Distribution Networks are mandatory components of modern web architectures, with plenty of vendors offering their services. Despite its maturity, new paradigms and architecture models are still being developed in this area. Cloud Computing, on the other hand, is a more recent concept which has expanded extremely quickly, with new services being regularly added to cloud management software suites such as OpenStack. The main contribution of this paper is the architecture and the development of an open source CDN that can be provisioned in an on-demand, pay-as-you-go model thereby enabling the CDN as a Service paradigm. We describe our experience with integration of CDNaaS framework in a cloud environment, as a service for enterprise users. We emphasize the flexibility and elasticity of such a model, with each CDN instance being delivered on-demand and associated to personalized caching policies as well as an optimized choice of Points of Presence based on exact requirements of an enterprise customer. Our development is based on the framework developed in the Mobile Cloud Networking (MCN) EU FP7 project, which offers its enterprise users a common framework to instantiate and control services. CDNaaS is one of the core support components in this project as is tasked to deliver different type of multimedia content to several thousands of users geographically distributed. It integrates seamlessly in the MCN service life-cycle and as such enjoys all benefits of a common design environment, allowing for an improved interoperability with the rest of the services within the MCN ecosystem.}, 
keywords={cloud computing;mobile computing;software architecture;CDN-as-a-service;CDNaaS framework;MCN EU FP7 project;MCN ecosystem;MCN service life-cycle;OpenStack;Web architectures;architecture models;cloud computing;cloud environment;cloud management software;content distribution networks;enterprise customer;enterprise users;mobile cloud networking;multimedia content;on-demand pay-as-you-go model;open source CDN;personalized caching policies;points of presence;Cloud computing;Computer architecture;Containers;Monitoring;Real-time systems;Servers}, 
doi={10.1109/ICACCI.2014.6968495}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6197463, 
author={F. Karatas and M. Bourimi and T. Barth and D. Kesdogan and R. Giménez and W. Schwittek and M. Planagumà}, 
booktitle={2012 IEEE International Conference on Pervasive Computing and Communications Workshops}, 
title={Towards secure and at-runtime tailorable customer-driven public cloud deployment}, 
year={2012}, 
volume={}, 
number={}, 
pages={124-130}, 
abstract={Cloud computing as a facility for outsourcing IT related tasks is a growing trend. Customer-driven application deployment in public clouds has to be secure and flexible by means of easing security configuration as well as by avoiding the vendor lock-in problem. In this paper we present an approach intending to meet these needs by (1) easing security configuration(s), (2) automating the consideration of security best practices and adding/enabling anonymity components at-runtime, and (3) by using Open Virtualization Format (OVF) in order to overcome the vendor lock-in problem. The requirements gathering is based on the needs of three projects from different business domains, the EU FP7 digital.me project, the multidisciplinary iFishWatcher/iAngle combined project and the joint german-french research and development project ReSCUe IT. All projects require empowering lay as well as experienced customers to (re-)deploy their own applications and migrate them easily by considering security thereby. Supporting tailorability of the deployed environment by adding anonymity components at-runtime without downtimes is a specific requirement in these projects. We present first results and discuss experiences and future work directions.}, 
keywords={cloud computing;security of data;virtualisation;EU FP7 digital.me project;German-French research and development project;anonymity component;cloud computing;customer-driven application deployment;customer-driven public cloud deployment;iFishWatcher-iAngle combined project;open virtualization format;security best practice;security configuration;vendor lock-in problem;Authentication;Best practices;Cloud computing;Runtime;Servers;Supply chains;Cloud deployment;cloud security;di.me;security best practices;user-controlled deployment;vendor lock-in prevention}, 
doi={10.1109/PerComW.2012.6197463}, 
ISSN={}, 
month={March},}
@ARTICLE{5233607, 
author={M. D. Dikaiakos and D. Katsaros and P. Mehra and G. Pallis and A. Vakali}, 
journal={IEEE Internet Computing}, 
title={Cloud Computing: Distributed Internet Computing for IT and Scientific Research}, 
year={2009}, 
volume={13}, 
number={5}, 
pages={10-13}, 
abstract={Cloud computing is a disruptive technology with profound implications not only for Internet services but also for the IT sector as a whole. Its emergence promises to streamline the on-demand provisioning of software, hardware, and data as a service, achieving economies of scale in IT solutions' deployment and operation. This issue's articles tackle topics including architecture and management of cloud computing infrastructures, SaaS and IaaS applications, discovery of services and data in cloud computing infrastructures, and cross-platform interoperability. Still, several outstanding issues exist, particularly related to SLAs, security and privacy, and power efficiency. Other open issues include ownership, data transfer bottlenecks, performance unpredictability, reliability, and software licensing issues. Finally, hosted applications' business models must show a clear pathway to monetizing cloud computing. Several companies have already built Internet consumer services such as search, social networking, Web email, and online commerce that use cloud computing infrastructure. Above all, cloud computing's still unknown "killer application" will determine many of the challenges and the solutions we must develop to make this technology work in practice.}, 
keywords={Internet;electronic commerce;open systems;IT sector;Web email;business model;cloud computing;consumer services;cross-platform interoperability;data transfer;distributed Internet computing;online commerce;social networking;software licensing;software reliability;Application software;Business;Cloud computing;Computer architecture;Data security;Disaster management;Distributed computing;Economies of scale;Hardware;Web and internet services;Internet data centers;cloud computing;distributed systems;utility computing}, 
doi={10.1109/MIC.2009.103}, 
ISSN={1089-7801}, 
month={Sept},}
@INPROCEEDINGS{6391816, 
author={G. D. Modica and G. Petralia and O. Tomarchio}, 
booktitle={2012 Eighth International Conference on Semantics, Knowledge and Grids}, 
title={A Business Ontology to Enable Semantic Matchmaking in Open Cloud Markets}, 
year={2012}, 
volume={}, 
number={}, 
pages={96-103}, 
abstract={Over the past few years, an increasing number of organizations have been considering the use of some form of cloud computing for their business purpose. However, the market of cloud resources is still in its infancy due to, among other reasons, the lack of interoperability among existing cloud platforms. In this paper we argue that a successful open cloud market needs a flexible and powerful way to express actors' requirements. In order to address this issue, we developed a set of ontologies to capture and express the business aspects of providers' offerings and customers' requests. To the best of our knowledge this is one of the first attempt to build a cloud ontology focused on business related concepts rather than on technical aspects. The ontology discussed here is just the first step of our work: the final aim is to define an exhaustive set of business-oriented requirements to support the implementation of a semantic cloud resource publish/discovery mechanism.}, 
keywords={business data processing;cloud computing;customer services;ontologies (artificial intelligence);open systems;business ontology;business-oriented requirements;cloud computing;cloud platforms;customer requests;interoperability;open cloud markets;providers offering;semantic cloud resource publish-discovery mechanism;semantic matchmaking;Business;Cloud computing;Context;Ontologies;Semantics;Taxonomy;cloud market;ontology;price model;semantic discovery}, 
doi={10.1109/SKG.2012.1}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{8024513, 
author={C. Lubamba and A. Bagula}, 
booktitle={2017 IEEE Symposium on Computers and Communications (ISCC)}, 
title={Cyber-healthcare cloud computing interoperability using the HL7-CDA standard}, 
year={2017}, 
volume={}, 
number={}, 
pages={105-110}, 
abstract={The HL7 standard was initially designed to enable interoperability of healthcare information within large hospitals. HL7's focus has recently been extended to regional healthcare cloud infrastructures but not yet reached the lightweight fog infrastructures emerging from niche healthcare areas such as body area networks (BANs) and the massive flow of personal medical records resulting from off-the-shelf e-health devices and networks. This paper addresses the issue of interoperability between fog and cloud computing platforms by i) proposing a framework for a standardized exchange of information between healthcare entities ii) designing and implementing a software tool to be integrated into medical data dissemination protocols to ensure interoperability and iii) evaluating the impact of the software tool on the transport of data when exchanging healthcare information using “in-band” and “out-band” transport over the IEEE802.15.4/ZigBee and WiFi protocols. Our results reveal that, for the lightweight devices used by fog infrastructures, “out-band” transport over WiFi with edge data translation into HL7 records is a better option than “in-band” transport.}, 
keywords={cloud computing;health care;hospitals;open systems;BAN;HL7 records;HL7-CDA standard;IEEE802.15.4/ZigBee;WiFi protocols;body area networks;cloud computing platforms;cyber-healthcare cloud computing interoperability;edge data translation;healthcare information;hospitals;in-band transport;lightweight fog infrastructures;medical data dissemination protocols;out-band transport;personal medical records;regional healthcare cloud infrastructures;software tool;standardized exchange;Cloud computing;Interoperability;Medical services;Organizations;Standards organizations;XML;Cyber-Healthcare;Fog Computing;HL7-CDA;Interoperability}, 
doi={10.1109/ISCC.2017.8024513}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{7027503, 
author={N. Ferry and H. Song and A. Rossini and F. Chauvel and A. Solberg}, 
booktitle={2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing}, 
title={CloudMF: Applying MDE to Tame the Complexity of Managing Multi-cloud Applications}, 
year={2014}, 
volume={}, 
number={}, 
pages={269-277}, 
abstract={The market of cloud computing encompasses an ever-growing number of cloud providers offering a multitude of infrastructure-as-a-service (IaaS) and platform-as-a-service (PaaS) solutions. The heterogeneity of these solutions hinders the proper exploitation of cloud computing since it prevents interoperability and promotes vendor lock-in, which increases the complexity of executing and managing multi-cloud applications (i.e., Applications that can be deployed across multiple cloud infrastructures and platforms). Providers of multi-cloud applications seek to exploit the peculiarities of each cloud solution and to combine the delivery models of IaaS and PaaS in order to optimise performance, availability, and cost. In this paper, we show how the Cloud Modelling Framework leverages upon model-driven engineering to tame this complexity by providing: (i) a tool-supported domain-specific language for specifying the provisioning and deployment of multi-cloud applications, and (ii) a models@run-time environment for enacting the provisioning, deployment, and adaptation of these applications.}, 
keywords={cloud computing;open systems;IaaS;MDE;PaaS;cloud MF;cloud computing;cloud modelling framework;infrastructure-as-a-service;interoperability;model-driven engineering;multicloud applications;platform-as-a-service;tool-supported domain-specific language;Adaptation models;Biological system modeling;Cloud computing;Containers;Engines;Sensors;Syntactics;Cloud ML;Cloud computing;Model-driven engineering;multi-cloud}, 
doi={10.1109/UCC.2014.36}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6488579, 
author={E. Hendrick and B. Schooley and Chunming Gao}, 
booktitle={2013 IEEE 10th Consumer Communications and Networking Conference (CCNC)}, 
title={CloudHealth: Developing a reliable cloud platform for healthcare applications}, 
year={2013}, 
volume={}, 
number={}, 
pages={887-891}, 
abstract={Electronic medical systems have become a popular and necessary instrument to the healthcare community in the recent years. These systems however lack a key component: interoperability. The basis of this project was to create a cloud computing platform for the healthcare community that would be able to support the medical records of an entire country. After copious amounts of research, a prototype of such a system was created. Through this process we've learned about the complexities of creating a cloud solution for the healthcare community.}, 
keywords={biomedical communication;biomedical equipment;cloud computing;health care;medical computing;CloudHealth platform;cloud computing platform reliability;cloud would medical record;electronic medical system;healthcare community application;interoperability;Cloud computing;Communities;Databases;Medical services;Monitoring;Servers;Virtual machining;EHR;EMR;cloud computing;eHealth systems;healthcare}, 
doi={10.1109/CCNC.2013.6488579}, 
ISSN={2331-9852}, 
month={Jan},}
@INPROCEEDINGS{6245776, 
author={T. F. Fortis and V. I. Munteanu and V. Negru}, 
booktitle={2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems}, 
title={Towards an Ontology for Cloud Services}, 
year={2012}, 
volume={}, 
number={}, 
pages={787-792}, 
abstract={The emergence of cloud computing has created a shift in the service lifecycle, a shift meant to meet the requirements of cloud environments. Anticipating this, cloud governance, a step forward from SOA governance, tries to consolidate an environment where collaboration between various enterprises can be easily achieved. Cloud governance lays the groundwork for enabling easy application development and deployment by providing critical services that range from service management to security, monitoring and audit. As means of support for cloud computing, several ontologies have tried to bridge gaps and provide interoperability. None, however, have taken the time to analyze and define aspects that relate to service lifecycle and cloud governance. In this regard, our article proposes an ontology that is meant to complement existing ones.}, 
keywords={auditing;cloud computing;groupware;monitoring;ontologies (artificial intelligence);security;service-oriented architecture;SOA governance;audit;cloud computing;cloud services;collaboration;monitoring;ontology;security;service lifecycle;service management;service-oriented architecture;Cloud computing;Monitoring;Ontologies;Security;Semantics;Service oriented architecture;cloud brokerage;cloud computing;cloud governance;cloud management;semantic cloud}, 
doi={10.1109/CISIS.2012.138}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{7194328, 
author={F. Messina and R. Mikkilineni and G. Morana}, 
booktitle={2015 IEEE 24th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises}, 
title={CDCGM 2015 Track Report: Convergence of Distributed Clouds, Grids and their Management}, 
year={2015}, 
volume={}, 
number={}, 
pages={47-50}, 
abstract={This track started with the first Cloud Computing session in WETICE2009 with the observation that the cloud computing evolution depends on research efforts from the infrastructure providers creating next generation hardware that is service friendly, service developers that embed business service intelligence in the network to create distributed business workflow execution, assure service delivery on a massive scale with global interoperability while dealing with non-functional requirements such as security, availability, performance, compliance, cost and fluctuations both in resources and workloads. It was pointed out that the architecture and evolution of the cloud is increasing data enter complexity by piling up new layers of management over the many layers that already exist. Current session proves the epigram by Jean-Baptiste (1849) "plus ça change, plus c'est la mêeme chose." Literally "The more it changes, the more it's the same thing". In this conference, one paper presents the result of the discussions started in these sessions in 2009 that led to a policy based dynamic workflow orchestration independent of the infrastructure orchestration which eliminates the need for moving Virtual Machine images and interfaces to myriad infrastructure management systems at runtime. The architecture is derived from the well-understood and time-tested distributed systems such as cellular organisms, human organizational structures and telecommunication networks. In addition, eight full papers and three short papers continue to make progress on current state of the art. Based on the papers presented in these sessions over the last six years, we boldly predict that we are on the verge of a synthesis of the thesis of current state of the art and the anti-thesis of increasing complexity to address scaling and fluctuations in distributed systems.}, 
keywords={Business;Cloud computing;Complexity theory;Computer architecture;Quality of service;Security;Cloud Computing;Distributed Intelligent Managed Element Networks;Distributed Services Management;Parallel Computing;Services Virtualization;grid computing}, 
doi={10.1109/WETICE.2015.40}, 
ISSN={1524-4547}, 
month={June},}
@INPROCEEDINGS{6135872, 
author={J. Yang and R. Anand and S. Hobson and J. Lee and Y. Wang and J. M. Xu}, 
booktitle={2011 8th International Conference Expo on Emerging Technologies for a Smarter World}, 
title={Data Service Portal for application integration in cloud computing}, 
year={2011}, 
volume={}, 
number={}, 
pages={1-3}, 
abstract={Cloud computing offers both an opportunity and a challenge to the application interoperability. In a cloud computing environment, it may be easier to integrate software applications than in the traditional enterprise computing environment, if they all run on the same cloud platform, especially, on a SaaS (Software-as-a-Service) platform, following a common programming model. However, making multiple applications running on different computing clouds would make it more difficult to deal with multiple cloud platforms and their differences. This paper presents a novel service and data management platform called DSP (Data Service Portal) in the cloud computing environment that facilitates the integration of applications by sharing their information in a loosely coupled manner. DSP enables applications to collectively exchange data through a platform in a fine-grained access control environment. The applications can work cooperatively, through the data sharing mechanism provided by the platform playing the role of a data broker, without being aware of each other's presence. An individual application can maintain its own data and run independently of the other applications in the platform. The data sharing mechanism enables the applications to offer (or subscribe to) a set of data to be consumed by (or produced by) the other applications in the platform. The platform publishes the data model along with APIs and guidelines for applications to adapt to the DSP platform and get to on-board to the platform for the subscriptions.}, 
keywords={application program interfaces;authorisation;cloud computing;open systems;portals;signal processing;API;DSP platform;SaaS platform;application interoperability;application program interface;cloud computing;data broker;data management platform;data service portal;data sharing mechanism;digital signal processing;enterprise computing environment;fine-grained access control environment;service management platform;software application;software-as-a-service;Cloud computing;Data models;Digital signal processing;Government;Portals;Software-as-a-Service;application integration;data sharing;data trades}, 
doi={10.1109/CEWIT.2011.6135872}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{7015492, 
author={S. Sahni and V. Varma}, 
booktitle={2014 IEEE International Conference on Cloud Computing in Emerging Markets (CCEM)}, 
title={MultiPaaS - PaaS on Multiple Clouds}, 
year={2014}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Current PaaS solutions use an underlying IaaS provider and restrict themselves to a few geographical regions. They operate in one/two zones only and use others for failover or disaster recovery. In this paper, we present the design of MultiPaaS, a PaaS solution which runs on multiple cloud/IaaS providers and leverages the combined global span. Unlike traditional scaling techniques where app servers are scaled up or down in a specific region or data center, we present a design to perform it on a global scale. Origin of the request burst is identified and instances are booted in a data center closest to it. It ensures database persistence and cross-region scalability via a combination of replication techniques. We identify common features available across all IaaS providers and use that as a provider interface to ensure interoperability, but use provider specific extensions to leverage unique offerings and benefits.}, 
keywords={IP networks;cloud computing;open systems;MultiPaaS;cross-region scalability;data center;database persistence;disaster recovery;failover;geographical regions;global scale;global span;instance booting;interoperability;multiple IaaS providers;multiple cloud providers;multiple clouds;provider specific extensions;replication techniques;request burst origin identification;Containers;Databases;IP networks;Load management;Routing;Servers;Web services}, 
doi={10.1109/CCEM.2014.7015492}, 
ISSN={}, 
month={Oct},}
@ARTICLE{6497434, 
author={A. Ranabahu and E. M. Maximilien and A. Sheth and K. Thirunarayan}, 
journal={IEEE Transactions on Services Computing}, 
title={Application Portability in Cloud Computing: An Abstraction-Driven Perspective}, 
year={2015}, 
volume={8}, 
number={6}, 
pages={945-957}, 
abstract={Cloud computing has changed the way organizations create, manage, and evolve their applications. While the abundance of computing resources at low cost opens up many possibilities for migrating applications to the cloud, this migration also comes at a price. Cloud applications, in many cases, depend on certain provider specific features or services. In moving applications to the cloud, application developers face the challenge of balancing these dependencies to avoid vendor lock-in. We present an abstraction-driven approach to address the application portability issues and focus on the application development process. We also present our theoretical basis and experience in two practical projects where we have applied the abstraction-driven approach.}, 
keywords={cloud computing;abstraction-driven perspective;application development process;application portability;cloud computing;computing resources;Cloud computing;DSL;Domain specific languages;Mathematical model;Semantics;Unified modeling language;Cloud computing;application generation;domain specific languages}, 
doi={10.1109/TSC.2013.25}, 
ISSN={1939-1374}, 
month={Nov},}
@INPROCEEDINGS{6480040, 
author={G. A. Lewis}, 
booktitle={2013 46th Hawaii International Conference on System Sciences}, 
title={Role of Standards in Cloud-Computing Interoperability}, 
year={2013}, 
volume={}, 
number={}, 
pages={1652-1661}, 
abstract={In cloud computing, interoperability typically refers to the ability to easily move workloads and data from one cloud provider to another or between private and public clouds. A common tactic for enabling interoperability is the use of open standards, so there is currently a large amount of active work in standards development for the Cloud. This paper explores the role of standards in cloud-computing interoperability. It covers standard-related efforts, discusses several cloud interoperability use cases, and provides some recommendations for moving forward with cloud-computing adoption regardless of the maturity of standards for the cloud.}, 
keywords={cloud computing;open systems;cloud computing adoption;cloud computing interoperability;cloud provider;cloud standard development;cloud standards;open standards;private clouds;public clouds;Authentication;Cloud computing;Interoperability;Standards organizations;cloud computing;interoperability;portability;standards}, 
doi={10.1109/HICSS.2013.470}, 
ISSN={1530-1605}, 
month={Jan},}
@INPROCEEDINGS{6615730, 
author={T. Teixeira and B. Malheiro}, 
booktitle={2013 8th Iberian Conference on Information Systems and Technologies (CISTI)}, 
title={Support system for rational use of electric energy}, 
year={2013}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={This paper presents the system developed to promote the rational use of electric energy among consumers and, thus, increase the energy efficiency. The goal is to provide energy consumers with an application that displays the energy consumption/production profiles, sets up consuming ceilings, defines automatic alerts and alarms, compares anonymously consumers with identical energy usage profiles by region and predicts, in the case of non-residential installations, the expected consumption/production values. The resulting distributed system is organized in two main blocks: front-end and back-end. The front-end includes user interface applications for Android mobile devices and Web browsers. The back-end provides data storage and processing functionalities and is installed in a cloud computing platform - the Google App Engine - which provides a standard Web service interface. This option ensures interoperability, scalability and robustness to the system.}, 
keywords={Web services;cloud computing;energy conservation;power consumption;power engineering computing;user interfaces;Android mobile devices;Google App engine;Web browsers;Web service interface;back-end;cloud computing platform;data storage;distributed system;energy efficiency;front-end;identical energy usage profiles;production profiles;rational electric energy usage;support system;user interface applications;Energy consumption;Google;Libraries;Mobile communication;Production;User interfaces;Web services;Android;Cloud computing;Efficiency;Electricity;Rationalization}, 
doi={}, 
ISSN={2166-0727}, 
month={June},}
@INPROCEEDINGS{7389065, 
author={A. Sharma and T. Goyal and E. S. Pilli and A. P. Mazumdar and M. C. Govil and R. C. Joshi}, 
booktitle={2015 IEEE 2nd World Forum on Internet of Things (WF-IoT)}, 
title={A Secure Hybrid Cloud Enabled architecture for Internet of Things}, 
year={2015}, 
volume={}, 
number={}, 
pages={274-279}, 
abstract={Rapid advances in digitalization, Internet and world wide web enable the communication between two computing hosts across any location in the globe. Pervasive or ubiquitous computing enhanced this to a level that any two intelligent physical objects can communicate with each other, anytime and anywhere. Internet of Things (IoT) is a novel paradigm emerging from ubiquitous computing that facilitates communication between many real world objects by collaboration of various technologies. Integrating IoT with Cloud Computing derives manifold advantages to store and process enormous data generated by heterogeneous devices. Though both the technologies together have profound effect in many application areas like smart home, smart agriculture, healthcare etc., their integration involves many challenges. Security is one of the most important issues confronted by IoT-Cloud architecture. In this paper, we propose a Secure, Hybrid, Cloud Enabled architecture for IoT (SHCEI), which uses hybrid cloud (both public and private cloud). This architecture ensures security of intradomain data and will also address issues of scalability and interoperability. Further, we highlight some of the research challenges in implementing the combined architecture of Cloud and IoT.}, 
keywords={Internet of Things;cloud computing;open systems;Internet of Things;IoT-cloud architecture;SHCEI;World Wide Web;cloud computing;digitalization;healthcare;heterogeneous device;intelligent physical object;interoperability;pervasive computing;private cloud;public cloud;secure hybrid cloud enabled architecture for IoT;smart agriculture;smart home;ubiquitous computing;Cloud computing;Computer architecture;Intelligent sensors;Protocols;Security;Wireless sensor networks;Hybrid Cloud;Interoperability;IoT;Scalability;Security;Social IoT}, 
doi={10.1109/WF-IoT.2015.7389065}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6949250, 
author={A. O. Akande and J. P. Van Belle}, 
booktitle={2014 5th International Conference - Confluence The Next Generation Information Technology Summit (Confluence)}, 
title={A proposed framework to assess and increase the cloud computing readiness of financial institutions in South Africa}, 
year={2014}, 
volume={}, 
number={}, 
pages={46-52}, 
abstract={Among the various industry sectors, the financial industry in South Africa (SA) has been one of the early adopters of cloud computing (CC) but they have not fully implemented it because of barriers such as security and privacy, governance issues, inadequate cloud service level agreements (SLAs), vendor lock in, poor vendor transparency, inability to assess risks, confidentiality, integrity and availability. Few guidelines exist to help organizations improve their CC readiness level. This is particularly risky for financial institutions that deal with sensitive customer information as the safety of that information is not guaranteed if a desired readiness level is not attained before implementation. In order to assist financial institutions with this hurdle, this paper proposes a framework that will serve as a tool by which financial institutions can determine and improve their CC readiness. The framework is called “Becoming Cloud Computing Ready” (BCCR) and it would help financial institutions to determine which stage they are with their CC readiness. It will also provide guidelines that will assist financial institutions to improve their level of readiness in order to ensure successful CC adoption. The proposed framework is grounded in both the literature as well as empirical data obtained from interviews with the largest financial institutions in SA.}, 
keywords={cloud computing;contracts;data integrity;data privacy;financial management;BCCR;CC readiness level;SLA;South Africa;becoming cloud computing ready;cloud computing readiness;cloud service level agreement;customer information;data availability;data confidentiality;data integrity;data privacy;data security;financial industry;financial institutions;governance issues;risk assessment;vendor lock in;vendor transparency;Cloud computing;Companies;Security;Standards organizations;South Africa;cloud computing;financial institutions;framework;implementation;organisational adoption;readiness;technology-organization-environment}, 
doi={10.1109/CONFLUENCE.2014.6949250}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{5328581, 
author={D. Bernstein}, 
booktitle={2009 Sixth IFIP International Conference on Network and Parallel Computing}, 
title={Keynote 2: The Intercloud: Cloud Interoperability at Internet Scale}, 
year={2009}, 
volume={}, 
number={}, 
pages={xiii-xiii}, 
abstract={Today, cloud computing is seen largely as isolated providers or enterprise instances of a special kind of hosting or application container. Virtual machines, or managed code executing against cloud API's, are limited to that provider or that enterprise in terms of direct context or reach. This reminds us very much of the state of networking before the Internet where LANs of various domains and protocols did not interconnect. It will either be history repeating, or our collective manifest destiny, to evolve cloud computing to a worldwide, interoperable, transparent platform. In other words, cloud will become to computing just what the Internet is for data. Unfortunately, there are many aspects of the platform on which cloud computing depends which are preventing this. For example, for the Internet to work, someone had to invent IP addressing, domain name service, peering and routing protocols such as AS numbering, OSPF and BGP, and certificates to enable SSL. In cloud, for the broader vision of cloud interoperability to work, ranging from VM mobility to storage federation to multicast and media streaming interoperability to identity and presence and everything in between, analogous technologies need to be invented. This talk overviews the "grand challenges" in making such changes on the scale of the Internet, and then speaks to specific work completed to-date and in-progress in standards bodies. The attendee will leave the talk with a new understanding of how following the blueprints of the Internet itself (exchange and peering, geographical dispersion, etc) are enabling cloud interoperability at a fundamental level. This is what is being called the "intercloud".}, 
keywords={Internet;application program interfaces;open systems;virtual machines;Internet;application programming interface;cloud API;cloud computing;cloud interoperability;collective manifest destiny;intercloud paradigm;media streaming interoperability;virtual machine;Cloud computing;Containers;History;IP networks;LAN interconnection;Routing protocols;Streaming media;Virtual machining;Virtual manufacturing;Web and internet services}, 
doi={10.1109/NPC.2009.7}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{7207419, 
author={K. Yongsiriwit and M. Sellami and W. Gaaloul}, 
booktitle={2015 IEEE International Conference on Services Computing}, 
title={Semantic Process Fragments Matching to Assist the Development of Process Variants}, 
year={2015}, 
volume={}, 
number={}, 
pages={712-719}, 
abstract={With the increasing adoption of Cloud Computing, Business Process as a Service (BPaaS) has recently emerged as the delivery of business process outsourcing services that are sourced from the cloud and constructed for multitenancy. BPaaS providers may look for available business processes from other cloud providers to improve their processes. However, today's BPaaS solutions lack an explicit and formal semantics which prevent an easy and dynamic interoperability between different cloud providers. In this paper, we propose firstly to semantically populate a shared knowledge base of process models deployed by BPaaS providers. Therefore, using this knowledge base we aim at finding for selected positions in a business process suitable process fragments for recommendation to assist process variant modeling. To do so, we define a process fragment as a neighborhood context graph, which captures order constraints between tasks and their neighbors. Thus, we compute similarity between fragments to select the most similar ones for recommendation. As a proof of concept, we provide a tool that allows process designers to retrieve similar process fragments that can be used to design new process variants. We also performed experiments on large public datasets and experimental results show that our approach is feasible and efficient.}, 
keywords={business data processing;cloud computing;outsourcing;BPaaS;Business Process as a Service;business process outsourcing services;business process suitable process;cloud computing;cloud providers;dynamic interoperability;formal semantics;neighborhood context graph;process variant development;process variant modeling;semantic process fragments matching;Business;Computational modeling;Context;Ontologies;Semantics;Unified modeling language;Business Process as a Service (BPaaS);Cloud Computing;Ontology;Process Fragment;Semantic technology}, 
doi={10.1109/SCC.2015.101}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{6240697, 
author={V. Čačković and Ž. Popović}, 
booktitle={2012 Proceedings of the 35th International Convention MIPRO}, 
title={The use of IMS for cloud based services control and management}, 
year={2012}, 
volume={}, 
number={}, 
pages={501-505}, 
abstract={Cloud computing as defined by NIST is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction. Focus of this paper will be on identifying the capabilities and requirements that need to be standardized in a cloud environment for successful deployment of the Cloud computing service. IP Multimedia Subsystem (IMS) is a standardized architecture that ensures interoperability and simplifies integration of cloud services while supporting regulatory, QoS and capacity requirements.}, 
keywords={IP networks;cloud computing;multimedia communication;telecommunication network management;IMS;IP multimedia subsystem;NIST;QoS;capacity requirements;cloud based services control;cloud based services management;cloud computing service;cloud environment;cloud services integration;configurable computing resources;convenient access;on-demand network access;service provider;ubiquitous access;Cloud computing;Computer architecture;IP networks;Protocols;Quality of service}, 
doi={}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{6570634, 
author={K. Grolinger and M. A. M. Capretz and E. Mezghani and E. Exposito}, 
booktitle={2013 Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises}, 
title={Knowledge as a Service Framework for Disaster Data Management}, 
year={2013}, 
volume={}, 
number={}, 
pages={313-318}, 
abstract={Each year, a number of natural disasters strike across the globe, killing hundreds and causing billions of dollars in property and infrastructure damage. Minimizing the impact of disasters is imperative in today's society. As the capabilities of software and hardware evolve, so does the role of information and communication technology in disaster mitigation, preparation, response, and recovery. A large quantity of disaster-related data is available, including response plans, records of previous incidents, simulation data, social media data, and Web sites. However, current data management solutions offer few or no integration capabilities. Moreover, recent advances in cloud computing, big data, and NoSQL open the door for new solutions in disaster data management. In this paper, a Knowledge as a Service (KaaS) framework is proposed for disaster cloud data management (Disaster-CDM), with the objectives of 1) storing large amounts of disaster-related data from diverse sources, 2) facilitating search, and 3) supporting their interoperability and integration. Data are stored in a cloud environment using a combination of relational and NoSQL databases. The case study presented in this paper illustrates the use of Disaster-CDM on an example of simulation models.}, 
keywords={SQL;cloud computing;emergency management;open systems;relational databases;social networking (online);KaaS framework;NoSQL database;Web sites;big data;cloud computing;disaster cloud data management;information and communication technology;interoperability;knowledge as a service framework;relational database;response plans;simulation data;social media data;Data models;Disaster management;Information management;Ontologies;Relational databases;Tagging;Knowledge as a Service (KaaS);NoSQL;big data;cloud computing;disaster management}, 
doi={10.1109/WETICE.2013.48}, 
ISSN={1524-4547}, 
month={June},}
@INPROCEEDINGS{7266936, 
author={B. Zhang and J. Hwang and L. Ma and T. Wood}, 
booktitle={2015 IEEE International Conference on Autonomic Computing}, 
title={Towards Security-Aware Virtual Server Migration Optimization to the Cloud}, 
year={2015}, 
volume={}, 
number={}, 
pages={71-80}, 
abstract={Cloud computing, featured by shared servers and location independent services, has been widely adopted by various businesses to increase computing efficiency, and reduce operational costs. Despite significant benefits and interests, enterprises have a hard time to decide whether or not to migrate thousands of servers into the cloud because of various reasons such as lack of holistic migration (planning) tools, concerns on data security and cloud vendor lock-in. In particular, cloud security has become the major concern for decision makers, due to the nature weakness of virtualization -- the fact that the cloud allows multiple users to share resources through Internet-facing interfaces can be easily taken advantage of by hackers. Therefore, setting up a secure environment for resource migration becomes the top priority for both enterprises and cloud providers. To achieve the goal of security, security policies such as firewalls and access control have been widely adopted, leading to significant cost as additional resources need to employed. In this paper, we address the challenge of the security-aware virtual server migration, and propose a migration strategy that minimizes the migration cost while promising the security needs of enterprises. We prove that the proposed security-aware cost minimization problem is NP hard and our solution can achieve an approximate factor of 2. We perform an extensive simulation study to evaluate the performance of the proposed solution under various settings. Our simulation results demonstrate that our approach can save 53%moving cost for a single enterprise case, and 66% for multiple enterprises case comparing to a random migration strategy.}, 
keywords={cloud computing;cost reduction;resource allocation;security of data;virtualisation;Internet-facing interfaces;NP hard problem;cloud computing;cloud security;cloud vendor lock-in;data security;moving cost savings;resource migration;resource sharing;security policy;security-aware cost minimization problem;security-aware virtual server migration optimization;virtualization;Approximation algorithms;Approximation methods;Cloud computing;Clustering algorithms;Home appliances;Security;Servers;Cloud Computing;Cloud Migration;Cloud Security;Cost Minimization}, 
doi={10.1109/ICAC.2015.45}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{6550490, 
author={Y. Demchenko and C. Ngo and C. de Laat and J. A. Garcia-Espin and S. Figuerola and J. Rodriguez and L. M. Contreras and G. Landi and N. Ciulli}, 
booktitle={2013 27th International Conference on Advanced Information Networking and Applications Workshops}, 
title={Intercloud Architecture Framework for Heterogeneous Cloud Based Infrastructure Services Provisioning On-Demand}, 
year={2013}, 
volume={}, 
number={}, 
pages={777-784}, 
abstract={This paper presents on-going research to develop the Intercloud Architecture Framework (ICAF) that addresses problems in multi-provider multi-domain heterogeneous cloud based infrastructure services and applications integration and interoperability, to allow their on-demand provisioning. The paper refers to existing standards and ongoing standardisation activity in Cloud Computing, in particular, recently published NIST Cloud Computing Reference Architecture (CCRA) and ITU-T JCA-Cloud activity. The proposed ICAF defines four complementary components addressing Intercloud integration and interoperability: multi-layer Cloud Services Model that combines commonly adopted cloud service models, such as IaaS, PaaS, SaaS, in one multilayer model with corresponding inter-layer interfaces, Intercloud Control and Management Plane that supports cloud based applications interaction, Intercloud Federation Framework, and Intercloud Operations Framework. The paper briefly describes the Service delivery and lifecycle management as an important ICAF component that provides a basis for consistent management and security of the provisioned on-demand complex cloud based services. The paper describes an implementation of the Intercloud Control and Management Plane in the GEYSERS project to allow optimal provisioning of the combined Network+IT resources in the inter-cloud environment. The proposed architecture is intended to provide an architectural model for developing Intercloud middleware and in this way will facilitate clouds interoperability and integration.}, 
keywords={cloud computing;open systems;software architecture;GEYSERS project;ICAF component;IaaS;PaaS;SaaS;cloud based applications interaction;cloud computing;cloud interoperability;cloud service model;heterogeneous cloud based infrastructure services;intercloud architecture framework;intercloud control;intercloud federation framework;intercloud integration;intercloud middleware;intercloud operations framework;interlayer interface;lifecycle management;management plane;multilayer cloud services model;multilayer model;on-demand provisioning;service delivery;standardisation activity;Cloud computing;Computer architecture;Interoperability;Monitoring;Security;Service-oriented architecture;Standards;Cloud Computing Reference Architecture;Cloud Security;Intercloud Architecture;Intercloud Control and Management Plane;Intercloud Federation Framework;Intercloud Operation Framework;Multi-layer Cloud Services Model}, 
doi={10.1109/WAINA.2013.237}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{7431426, 
author={A. P. Achilleos and G. M. Kapitsaki and E. Constantinou and G. Horn and G. A. Papadopoulos}, 
booktitle={2015 IEEE/ACM 8th International Conference on Utility and Cloud Computing (UCC)}, 
title={Business-Oriented Evaluation of the PaaSage Platform}, 
year={2015}, 
volume={}, 
number={}, 
pages={322-326}, 
abstract={Cloud computing is an efficient and cost effective realization of the utility function principle. Over the last years, a vast pool of choices for businesses has been created. This diversity of cloud infrastructures, platforms, and tools creates several challenges. In particular, it hinders interoperability, promotes vendor lock-in, but more importantly prevents businesses from making informed and optimal decisions when transitioning to the cloud. This paper presents the results of a business-oriented evaluation for cloud computing in the industry in Cyprus. The evaluation confirms that a set of key features is important for overcoming the above challenges and enables businesses to exploit the full potential of the cloud. Finally, PaaSage, a platform for autonomic multi-cloud deployment addressing these key features, is shortly presented.}, 
keywords={business data processing;cloud computing;PaaSage platform;autonomic multicloud deployment;business oriented evaluation;cloud computing;cloud infrastructures;optimal decisions;utility function principle;Business;Cloud computing;Elasticity;Measurement;Monitoring;Scalability;Servers;cloud computing;cloud deployment;component-based development}, 
doi={10.1109/UCC.2015.51}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6076952, 
author={}, 
booktitle={2011 13th Asia-Pacific Network Operations and Management Symposium}, 
title={[Front cover]}, 
year={2011}, 
volume={}, 
number={}, 
pages={c1-c1}, 
abstract={The following topics are dealt with: network operations management; smart network; device service; cloud service; cloud management; virtual environments; policy management; traffic management; mobile network management; wireless network management; packet trace side splitting; usage pattern analysis; internal systems anomaly detection; remote time system; frequency calibration system; smart-phone traffic analysis; end-to-end QoS performance management; fine granularity source address validation; automatic learned filter table; communications-as-a-service; machine-to-machine network management; pattern-matching localization scheme; content management; beacon-based trust management; network selection delay comparison; adaptable mobile-aware clustering algorithm; distributed collaboration scheme; middleware approach; legacy telecom operational support systems; virtual network hierarchical management system; optical distribution network management; cloud computing network architecture; NG-SDH bandwidth utilization improvement; dynamic charging plan; distributed resource management mechanism; autonomic resource management mechanism; structure configuration language; policy based management framework; integrated monitoring software; network measurement system; DNS server fingerprinting method; innovative ICT service creation approach; dynamic routing algorithm; modified adaptive resonance theory; cloud boss; LTE base station OSS; operation record analysis system; mobile traffic measurement analysis; energy-awared mobile network planning; energy-awared mobile network management; contract net based task allocation algorithm; WSN configuration; mesh topology approach; fuzzy based joint radio resource management; single-ended PMD measuring technology; utility-based fuzzy wavelength assignment; mobile communication network; multidomain fault localization model; IPv6 SNMPv3 agent; patch impact test target pinpointing; mobile network diagnosis; mobile network location services;- channel monitoring scheme; round-trip-time; netflow-based network traffic monitoring; cooperative network measurement platform; self-powered wireless communication platform; practical Chinese wall security model; event-based POI service; worm scanning strategies; customer perceived quality evaluation; ad hoc social network; password-based pairing protocol security; parasitic communication system; seamless online service upgrade; STUN-based connection sequence; sFlow; tracker traffic analysis; content searching scheme; improved network performance anomaly detection; next generation network; 3GPP femto-cell network; Internet traffic classification; peer-to-peer contents delivery system; IPTV execution tool; IPTV STB remote firmware upgrade process; black-box application programs; new Japanese academic backbone network; simple source routing algorithm; wavelength switched optical networks; load balancing method; information retrieval efficiency; interoperability test; IPTV unicast service analysis; LTE/LTE-A system-level simulator; mobile data offloading; DDoS attack defense solution; IPv6 development; trouble detection technology; and intelligent social network platform.}, 
keywords={IP networks;IPTV;Internet;Long Term Evolution;cloud computing;computer network performance evaluation;computer network security;firmware;information retrieval;middleware;mobile computing;open systems;optical burst switching;optical communication;pattern clustering;pattern matching;peer-to-peer computing;protocols;social networking (online);telecommunication network management;telecommunication network planning;telecommunication network routing;telecommunication traffic;wavelength assignment;wireless sensor networks;3GPP femto-cell network;DNS server fingerprinting method;IPTV STB remote firmware upgrade process;IPTV execution tool;IPTV unicast service analysis;IPv6 SNMPv3 agent;IPv6 development;Internet traffic classification;LTE base station OSS;LTE/LTE-A system-level simulator;NG-SDH bandwidth utilization improvement;STUN-based connection sequence;WSN configuration;ad hoc social network;adaptable mobile-aware clustering algorithm;attack defense solution;automatic learned filter table;autonomic resource management mechanism;beacon-based trust management;black-box application programs;channel monitoring scheme;cloud boss;cloud computing network architecture;cloud management;cloud service;communications-as-a-service;content management;content searching scheme;contract net based task allocation algorithm;cooperative network measurement platform;customer perceived quality evaluation;device service;distributed collaboration scheme;distributed resource management mechanism;dynamic charging plan;dynamic routing algorithm;end-to-end QoS performance management;energy-awared mobile network management;energy-awared mobile network planning;event-based POI service;fine granularity source address validation;frequency calibration system;fuzzy based joint radio resource management;improved network performance anomaly detection;information retrieval efficiency;innovative ICT service creation approach;integrated monitoring software;intelligent social network platform;internal systems anomaly detection;interoperability test;legacy telecom operational support systems;load balancing method;machine-to-machine network management;mesh topology approach;middleware approach;mobile communication network;mobile data offloading;mobile network diagnosis;mobile network location services;mobile network management;mobile traffic measurement analysis;modified adaptive resonance theory;multidomain fault localization model;netflow-based network traffic monitoring;network measurement system;network operations management;;network selection delay comparison;new Japanese academic backbone network;next generation network;operation record analysis system;optical distribution network management;packet trace side splitting;parasitic communication system;password-based pairing protocol security;patch impact test target pinpointing;pattern-matching localization scheme;peer-to-peer contents delivery system;policy based management framework;policy management;practical Chinese wall security model;remote time system;round-trip-time;sFlow;seamless online service upgrade;self-powered wireless communication platform;simple source routing algorithm;single-ended PMD measuring technology;smart network;smart-phone traffic analysis;structure configuration language;tracker traffic analysis;traffic management;trouble detection technology;usage pattern analysis;utility-based fuzzy wavelength assignment;virtual environments;virtual network hierarchical management system;wavelength switched optical networks;wireless network management;worm scanning strategies}, 
doi={10.1109/APNOMS.2011.6076952}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6470933, 
author={B. Zwattendorfer and A. Tauber}, 
booktitle={2012 International Conference for Internet Technology and Secured Transactions}, 
title={Secure cross-cloud single sign-on (SSO) using eIDs}, 
year={2012}, 
volume={}, 
number={}, 
pages={150-155}, 
abstract={Most cloud computing service providers secure their offered cloud services by username/password schemes, which have been proven to be weak. While such schemes may be sufficient for simple personalized services, e-Government or e-Health applications in the cloud require more reliable and stronger mechanisms. One of such mechanisms are electronic IDs (eID), which allow for unique qualified identification and strong authentication. EIDs have been rolled-out in many EU Member States since years. In this paper we present how various national eIDs can be used for secure cloud authentication. We therefore extended the STORK eID interoperability framework, which will be the relevant identification and authentication framework across Europe in future. Furthermore, we increased usability by additionally applying single sign-on (SSO). Single sign-on defines the ability to authenticate just once in a distributed environment and gain access to several protected services. In fact, by our extended STORK architecture citizens of 18 EU Member States - those Member States that support STORK - are able to use seamless authentication at different cloud service providers by using their own national eID.}, 
keywords={authorisation;cloud computing;government data processing;message authentication;open systems;STORK eID interoperability framework;authentication framework;cloud authentication;cloud computing service provider;cross-cloud single sign-on;distributed environment;e-government application;e-health application;electronic ID;extended STORK architecture citizen;identification;national eID;password scheme;personalized service;username scheme;Authentication;Europe;Cloud computing;SSO;STORK;authentication;eID;electronic identification;single-sign-on}, 
doi={}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6915555, 
author={G. Caragnano and K. Goga and P. Ruiu and L. Mossucca and O. Terzo and G. G. Z. Kashani}, 
booktitle={2014 Eighth International Conference on Complex, Intelligent and Software Intensive Systems}, 
title={Scalability of a Parallel Application in Hybrid Cloud}, 
year={2014}, 
volume={}, 
number={}, 
pages={451-456}, 
abstract={Cloud computing is a convenient, on demand, model which relies on shared pool of computing resources that can be rapidly provisioned and needs minimal management effort. As cloud computing obtains popularity nowadays, customers are looking for cloud solutions to adapt their organization's requirements. The more changes occur, customers are trying to decide what kind of cloud they are going to choose. Beside that, users are concerned about security, privacy, vendor lock-in and cost issues. A hybrid cloud is a mix of one private cloud and at least one public cloud, customers could benefit interoperability and flexibility. There are many elements that should be considered in hybrid cloud architecture. This paper represents a set of mpi benchmarking test executed on a private and public cloud environment in order to evaluate the QoS when real application is running.}, 
keywords={cloud computing;data privacy;message passing;parallel processing;quality of service;MPI;QoS evaluation;cloud solutions;cost issue;hybrid cloud computing;message passing interface;parallel application scalability;privacy issue;private cloud;public cloud;security issue;vendor lock-in issue;Cloud computing;Computer architecture;Interoperability;Standards;Virtual machining;Virtual private networks;Cloud computing;VPN;hybrid cloud;mpi;network;scalability}, 
doi={10.1109/CISIS.2014.64}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{7584353, 
author={N. Kratzke and R. Peinl}, 
booktitle={2016 IEEE 20th International Enterprise Distributed Object Computing Workshop (EDOCW)}, 
title={ClouNS - a Cloud-Native Application Reference Model for Enterprise Architects}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-10}, 
abstract={The capability to operate cloud-native applications can generate enormous business growth and value. But enterprise architects should be aware that cloud-native applications are vulnerable to vendor lock-in. We investigated cloud-native application design principles, public cloud service providers, and industrial cloud standards. All results indicate that most cloud service categories seem to foster vendor lock-in situations which might be especially problematic for enterprise architectures. This might sound disillusioning at first. However, we present a reference model for cloud-native applications that relies only on a small subset of well standardized IaaS services. The reference model can be used for codifying cloud technologies. It can guide technology identification, classification, adoption, research and development processes for cloud-native application and for vendor lock-in aware enterprise architecture engineering methodologies.}, 
keywords={business data processing;cloud computing;ClouNS;IaaS service;cloud technology;cloud-native application design principle;cloud-native application reference model;industrial cloud standard;public cloud service provider;vendor lock-in aware enterprise architecture engineering;Business;Cloud computing;Computer architecture;Containers;Interoperability;Standards}, 
doi={10.1109/EDOCW.2016.7584353}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{7148448, 
author={R. Patel and D. Dahiya}, 
booktitle={International Conference on Computing, Communication Automation}, 
title={Aggregation of cloud providers: A review of opportunities and challenges}, 
year={2015}, 
volume={}, 
number={}, 
pages={620-626}, 
abstract={A single cloud provider alone is not able to satisfy the increasing demand for its services as the number of online users and services deployed by organizations grow exponentially. To achieve the promises of cloud computing, the necessity of aggregating different cloud provider into a single framework emerges. This concept overcomes the limitations of interoperability, portability, vendor lock in problem, scalability and elasticity of contemporary cloud computing. Collaborating with different cloud providers is not an easy task because each cloud provider has different kinds of architecture, virtualization technology, service level agreement, enterprise solution and interface for accessing services. This scenario is identified by many synonyms in the literature such as cloud federation, Inter-cloud, Multi-Cloud etc. This paper discusses various driving forces and advantages that attract researchers towards it. Further, this paper concentrates on exploring related work done in addressing different issues and finding gaps that will create opportunities for further research and development. This work will tend to emerge as a step towards the next-generation enterprise solution.}, 
keywords={cloud computing;cloud computing;cloud providers aggregation;enterprise solution;service access interface;service level agreement;virtualization technology;Cloud computing;Computational modeling;Computer architecture;Interoperability;Monitoring;Resource management;Virtualization;Cloud Computing;Cloud Federation;Inter-cloud;Multi-Cloud}, 
doi={10.1109/CCAA.2015.7148448}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{7113278, 
author={A. Dey and A. Fekete and U. Röhm}, 
booktitle={2015 IEEE 31st International Conference on Data Engineering}, 
title={Scalable distributed transactions across heterogeneous stores}, 
year={2015}, 
volume={}, 
number={}, 
pages={125-136}, 
abstract={Typical cloud computing systems provide highly scalable and fault-tolerant data stores that may sacrifice other features like general multi-item transaction support. Recently techniques to implement multi-item transactions in these types of systems have focused on transactions across homogeneous data stores. Since applications access data in heterogeneous storage systems for legacy or interoperability reasons, we propose an approach that enables multi-item transactions with snapshot isolation across multiple heterogeneous data stores using only a minimal set of commonly implemented features such as single item consistency, conditional updates, and the ability to store additional meta-data. We define an client-coordinated transaction commitment protocol that does not rely on a central coordinating infrastructure. The application can take advantage of the scalability and fault-tolerance characteristics of modern key-value stores and access existing data in them, and also have multi-item transactional access guarantees with little performance impact. We have implemented our design in a Java library called Cherry Garcia (CG), that supports data store abstractions to Windows Azure Storage (WAS), Google Cloud Storage (GCS) and our own high-performance key-value store called Tora.}, 
keywords={Java;cloud computing;distributed databases;meta data;open systems;software fault tolerance;software libraries;software maintenance;transaction processing;Cherry Garcia;Google Cloud Storage;Java library;Tora;Windows Azure Storage;client-coordinated transaction commitment protocol;cloud computing systems;conditional updates;fault-tolerant data stores;general multi item transaction support;heterogeneous storage systems;high-performance key-value store;meta-data;multiple heterogeneous data stores;scalable data stores;scalable distributed transactions;single item consistency;snapshot isolation;Cloud computing;Fault tolerance;Fault tolerant systems;Google;Java;Libraries;Protocols}, 
doi={10.1109/ICDE.2015.7113278}, 
ISSN={1063-6382}, 
month={April},}
@INPROCEEDINGS{6658038, 
author={R. Chalse and A. Selokar and A. Katara}, 
booktitle={2013 5th International Conference and Computational Intelligence and Communication Networks}, 
title={A New Technique of Data Integrity for Analysis of the Cloud Computing Security}, 
year={2013}, 
volume={}, 
number={}, 
pages={469-473}, 
abstract={Cloud computing is a latest and fast growing technology that offers an innovative, efficient and scalable business model for organizations to adopt various information technology resources i.e. software, hardware, network, storage, bandwidth etc. Cloud Computing is a jargon term without a commonly accepted non-ambiguous scientific or technical definition. At the foundation of cloud computing is the broader concept of converged infrastructure and shared services. It has the capability to incorporate multiple internal and external cloud services together to provide high interoperability there can be multiple accounts associated with a single or multiple service provider (SPs). So, Security in terms of integrity is most important aspects in cloud computing environment. In this paper, a detailed analysis of the cloud security problem is presented. Also the different problem in a cloud computing system and their effect upon the different cloud users are analyzed. It is providing a comparably scalable, position independent. Low cost platform for client's data. Since cloud computing environment is constructed based on open Architecture and interface. Based on this analysis various computing system and their effect upon the system, upon organizations and also upon different cloud users are analyzed. It is providing a comparably scalable, position-independent, low cost platform for client's data. Since cloud computing environment is constructed based on open architecture and interface. Based on this analysis various researches have also presented a view of measures that can be taken to deal with the cloud security problem and prevention that must be taken into account by any organization and cloud users seeking investment in cloud computing.}, 
keywords={cloud computing;data integrity;open systems;security of data;software architecture;business model;cloud computing security analysis;data integrity technique;high interoperability;information technology resources;multiple service provider;open architecture;open interface;single service provider;Cloud computing;Computational modeling;Memory;Protocols;Security;Servers;Cloud security;IaaS;PaaS;SaaS;data storage;integrity verification}, 
doi={10.1109/CICN.2013.103}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{7431467, 
author={R. Baig and F. Freitag and A. Moll and L. Navarro and R. Pueyo and V. Vlassov}, 
booktitle={2015 IEEE/ACM 8th International Conference on Utility and Cloud Computing (UCC)}, 
title={Experiences in Building Micro-cloud Provider Federation in the Guifi Community Network}, 
year={2015}, 
volume={}, 
number={}, 
pages={516-521}, 
abstract={Cloud federation is foreseen to happen among large cloud providers. The resulting interoperability of cloud services among these providers will then increase even more the elasticity of cloud services. The cloud provisioned that is targeted by this scenario is mainly one which combines the cloud services offered by large enterprises. Cloud computing, however, has started moving to the edge. We now increasingly see the tendency to fullfil cloud computing requirements by multiple levels and different kind of infrastructures, where the Fog Computing paradigm has started playing its role. For this scenario of edge computing, we show in this paper the case of the federation of multiple independent micro-cloud providers within a community network, where providers pool their resources and services into a community cloud. Federation happens here primarily at the service level and the domain of trust is the community of practice. While we can today already report this case in the context of community networks, IPv6 deployment in the Internet will principally allow micro-cloud providers to appear everywhere, needing cloud federation mechanisms. We describe for a real case how this micro-cloud provider federation has been built and argue why micro-cloud provider should be considered for the integration in cloud federations.}, 
keywords={Web services;cloud computing;open systems;Guifi community network;IPv6 deployment;Internet;cloud computing requirements;cloud service elasticity;cloud service interoperability;community of practice;edge computing;fog computing paradigm;microcloud provider federation building;microcloud provider federation mechanism;Cloud computing;Computer numerical control;Hardware;IP networks;Interoperability;Peer-to-peer computing;Intercloud;community cloud}, 
doi={10.1109/UCC.2015.92}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6228199, 
author={P. Jurczyk and L. Xiong and S. Goryczka}, 
booktitle={2012 IEEE 28th International Conference on Data Engineering}, 
title={DObjects+: Enabling Privacy-Preserving Data Federation Services}, 
year={2012}, 
volume={}, 
number={}, 
pages={1325-1328}, 
abstract={The emergence of cloud computing implies and facilitates managing large collections of highly distributed, autonomous, and possibly private databases. While there is an increasing need for services that allow integration and sharing of various data repositories, it remains a challenge to ensure the privacy, interoperability, and scalability for such services. In this paper we demonstrate a scalable and extensible framework that is aimed to enable privacy preserving data federations. The framework is built on top of a distributed mediator-wrapper architecture where nodes can form collaborative groups for secure anonymization and secure query processing when private data need to be accessed. New anonymization models and protocols will be demonstrated that counter potential attacks in the distributed setting.}, 
keywords={cloud computing;data privacy;distributed databases;open systems;protocols;query processing;security of data;DObjects+;anonymization security;cloud computing;collaborative groups nodes;data repository integration;data repository sharing;data service interoperability;data service privacy;data service scalability;distributed anonymization protocols;distributed mediator-wrapper architecture;distributed-autonomous-private databases;privacy-preserving data federation services;query processing security;Computer architecture;Data privacy;Distributed databases;Privacy;Protocols;Query processing}, 
doi={10.1109/ICDE.2012.138}, 
ISSN={1063-6382}, 
month={April},}
@INPROCEEDINGS{7019873, 
author={R. M. Fujimoto}, 
booktitle={Proceedings of the Winter Simulation Conference 2014}, 
title={Parallel and distributed simulation}, 
year={2014}, 
volume={}, 
number={}, 
pages={5-5}, 
abstract={Driven by the widespread availability of commercial multiprocessor systems and advances in computer networking, the parallel and distributed simulation field emerged and flourished in the late 1970s and 1980s. The field has evolved since that time to address critical issues such as synchronization and interoperability, and remains an active area of research to this day. Many impressive successes have been reported to date. Today, new platforms ranging from massively parallel, heterogeneous supercomputers and cloud computing environments as well as broader technology trends such as big data and the Internet of Things present new challenges and opportunities. This presentation will review work in the parallel and distributed simulation field from seminal research in the 1970s and 80s to important successes that illustrate the potential offered by this technology. Key impediments that have prevented the technology from achieving more widespread adoption by the general modeling and simulation community are discussed as well as important challenges that remain in exploiting new and emerging computing platforms and technology trends.}, 
keywords={}, 
doi={10.1109/WSC.2014.7019873}, 
ISSN={0891-7736}, 
month={Dec},}
@INPROCEEDINGS{8000070, 
author={R. Calegari and E. Denti and S. Mariani and A. Omicini}, 
booktitle={2017 IEEE 14th International Conference on Networking, Sensing and Control (ICNSC)}, 
title={Logic Programming as a Service (LPaaS): Intelligence for the IoT}, 
year={2017}, 
volume={}, 
number={}, 
pages={72-77}, 
abstract={The widespread diffusion of low-cost computing devices, such as Arduino boards and Raspberry Pi, along with improvements of Cloud computing platforms, are paving the way towards a whole new set of opportunities for Internet of Things (IoT) applications and services. Varying degrees of intelligence are often required for supporting adaptation and self-management-yet, they should be provided in a light-weight, easy to use and customise, highly-interoperable way. Accordingly, in this paper we explore the idea of Logic Programming as a Service (LPaaS) as a novel and promising re-interpretation of distributed logic programming in the IoT era. After introducing the reference context and motivating scenarios of LPaaS as a key enabling technology for intelligent IoT, we define the LPaaS general system architecture. Then, we present a prototype implementation built on top of the tuProlog system, which provides the required interoperability and customisation. We showcase the LPaaS potential through a case study designed as a simplification of the motivating scenarios.}, 
keywords={Internet of Things;PROLOG;cloud computing;distributed programming;logic programming;open systems;Arduino board;Internet of Things application;IoT services;LPaaS general system architecture;Raspberry Pi;cloud computing platform;customisation;distributed logic programming;intelligent IoT;interoperability;logic programming as a service;low-cost computing devices;tuProlog system;Acoustics;Servers;IoT;LPaaS;artificial intelligence;interoperability;logic programming;pervasive computing}, 
doi={10.1109/ICNSC.2017.8000070}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{6973755, 
author={G. F. Anastasi and E. Carlini and M. Coppola and P. Dazzi}, 
booktitle={2014 IEEE 7th International Conference on Cloud Computing}, 
title={QBROKAGE: A Genetic Approach for QoS Cloud Brokering}, 
year={2014}, 
volume={}, 
number={}, 
pages={304-311}, 
abstract={The broad diffusion of Cloud Computing has fostered the proliferation of a large number of cloud computing providers. The need of Cloud Brokers arises for helping consumers in discovering, considering and comparing services with different capabilities and offered by different providers. Also, consuming services exposed by different providers, when possible, may alleviate the vendor lock-in. While it can be straightforward to choose the best provider when deploying small and homogeneous applications, things get harder if the size and complexity of applications grow up. In this paper we propose a genetic approach for Cloud Brokering, focusing on finding Infrastructure-as-a-Service (IaaS) resources for satisfying Quality of Service (QoS) requirements of applications. We performed a set of experiments with an implementation of such broker. Results show that our broker can find near-optimal solutions even when dealing with hundreds of providers, trying at the same time to mitigate the vendor lock-in.}, 
keywords={cloud computing;quality of service;IaaS resources;QBROKAGE;QoS cloud brokering;QoS requirement;cloud brokers;cloud computing;infrastructure-as-a-service resources;quality of service requirement;vendor lock-in;Cloud computing;Genetic algorithms;Genetics;Home appliances;Quality of service;Sociology;Statistics;Cloud Broker;Cloud Computing;Genetic Algorithms;QBrokage;Quality of Service}, 
doi={10.1109/CLOUD.2014.49}, 
ISSN={2159-6182}, 
month={June},}
@INPROCEEDINGS{7051866, 
author={C. Dsouza and G. J. Ahn and M. Taguinod}, 
booktitle={Proceedings of the 2014 IEEE 15th International Conference on Information Reuse and Integration (IEEE IRI 2014)}, 
title={Policy-driven security management for fog computing: Preliminary framework and a case study}, 
year={2014}, 
volume={}, 
number={}, 
pages={16-23}, 
abstract={With the increasing user demand for elastic provisioning of resources coupled with ubiquitous and on-demand access to data, cloud computing has been recognized as an emerging technology to meet such dynamic user demands. In addition, with the introduction and rising use of mobile devices, the Internet of Things (IoT) has recently received considerable attention since the IoT has brought physical devices and connected them to the Internet, enabling each device to share data with surrounding devices and virtualized technologies in real-time. Consequently, the exploding data usage requires a new, innovative computing platform that can provide robust real-time data analytics and resource provisioning to clients. As a result, fog computing has recently been introduced to provide computation, storage and networking services between the end-users and traditional cloud computing data centers. This paper proposes a policy-based management of resources in fog computing, expanding the current fog computing platform to support secure collaboration and interoperability between different user-requested resources in fog computing.}, 
keywords={Internet of Things;cloud computing;computer centres;open systems;resource allocation;security of data;Internet of things;IoT;cloud computing data centers;dynamic user demands;elastic resources provisioning;exploding data usage;fog computing;interoperability;networking services;on-demand data access;policy-driven security management;real-time data analytics;secure collaboration;storage services;ubiquitous data access;user-requested resources;virtualized technologies;Cloud computing;Collaboration;Computer architecture;Educational institutions;Global Positioning System;Security;Vehicles}, 
doi={10.1109/IRI.2014.7051866}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{7780130, 
author={N. Naik}, 
booktitle={2016 IEEE 10th International Symposium on the Maintenance and Evolution of Service-Oriented and Cloud-Based Environments (MESOCA)}, 
title={Migrating from Virtualization to Dockerization in the Cloud: Simulation and Evaluation of Distributed Systems}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={Virtualization is the nucleus of the cloud computing for providing its services on-demand. Cloud-based distributed systems are predominantly developed using virtualization technology. However, the requirement of significant resources and issues of interoperability and deployment make it less adopt- able in the development of many types of distributed systems. Dockerization or Docker Container-based virtualization has been introduced in the last three years and gaining popularity in the software development community. Docker has recently introduced its distributed system development tool called Swarm, which extends the Docker Container-based system development process on multiple hosts in multiple clouds. Docker Swarm-based containerized distributed system is a brand new approach and needs to be compared with the virtualized distributed system. Therefore, this paper presents the simulation and evaluation of the development of a distributed system using virtualization and dockerization. This simulation is based on Docker Swarm, VirtualBox, Ubuntu, Mac OS X, nginx and redis. To simulate and evaluate the distributed system in the same environment, all Swarm Nodes and Virtual Machines are created using VirtualBox on the same Mac OS X host. For making this evaluation rational, almost similar system resources are allocated to both at the beginning. Subsequently, similar servers nginx and redis are installed on the Swarm Node and Virtual Machine. Finally, based on the experimental simulation results, it evaluates their required resources and operational overheads; thus, their performance and effectiveness for designing distributed systems.}, 
keywords={cloud computing;operating systems (computers);virtual machines;virtualisation;Mac OS X;Ubuntu;VirtualBox;cloud computing;cloud-based distributed systems;distributed system development tool;docker container-based virtualization;docker swarm;nginx;operational overheads;redis;software development community;virtual machines;virtualization technology;virtualized distributed system;Cloud computing;Computer architecture;Containers;Servers;Virtual machine monitors;Virtual machining;Virtualization;Cloud;Container;Distributed Systems;Docker;Dockerization;Hypervisor;Virtual Machine;Virtual Machine Monitor;Virtualization}, 
doi={10.1109/MESOCA.2016.9}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6618756, 
author={S. Mtibaa and M. Tagina}, 
booktitle={2013 World Congress on Computer and Information Technology (WCCIT)}, 
title={IT as a service broker for e-learning systems}, 
year={2013}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={The increasing demand of services delivery in existing heterogeneous e-learning systems is a hot research issue. In order to enable the interoperability, we propose a solution based on cloud computing technology for instant building and delivering new services composed of existing web services discovered through UDDI or web services marketplace. In this paper, we present our approach to solve integration problems between heterogeneous e-learning systems. A larger variety of e-learning providers and requesters will be connected through a broker. Then, we expose our research in modeling services composition with a support of quality of service properties. Thus a model based on extension of Petri-nets aims to transform the operational semantics of service composition framework. In fact, this paper suggests this model to the analysis of web services composition in order fully match different users' request.}, 
keywords={Petri nets;Web services;cloud computing;computer aided instruction;open systems;quality of service;IT;Petri-nets;UDDI;Web services composition analysis;cloud computing technology;heterogeneous e-learning systems;interoperability;modeling services composition;operational semantic transformation;quality of service property;service broker;service composition framework;Business;Computational modeling;Educational institutions;Electronic learning;Quality of service;Training;Web services;Petri-nets;broker;cloud computing;e-learning;integration problems;interoperability;quality of service;web services composition;web services marketplace}, 
doi={10.1109/WCCIT.2013.6618756}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{7092812, 
author={}, 
booktitle={2015 IEEE International Conference on Cloud Engineering}, 
title={[Copyright notice]}, 
year={2015}, 
volume={}, 
number={}, 
pages={iv-iv}, 
abstract={The following topics are dealt with: cloud engineering; cloud sustainability; data security; Internet-of-Things; scheduling; software defined systems; cloud analytics; cloud computing; interoperability.}, 
keywords={Internet of Things;cloud computing;computer network security;open systems;scheduling;software radio;Internet-of-Things;cloud analytics;cloud computing;cloud engineering;cloud sustainability;data security;interoperability;scheduling;software defined systems}, 
doi={10.1109/IC2E.2015.3}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{6104586, 
author={Deyi Li and T. Li}, 
booktitle={2011 IEEE 8th International Conference on e-Business Engineering}, 
title={Keynote Abstracts}, 
year={2011}, 
volume={}, 
number={}, 
pages={xxxii-xxxiv}, 
abstract={The following topics are dealt with: e-business engineering; data management; service-oriented knowledge management; emergency communications; multi-agent supply chain collaboration operation model; cloud computing; business analytics; business optimization; Web service selection; user centric security mode; mobile commerce; pervasive commerce; service engineering; software engineering; warehousing approach; RFID; process automation; nonintrusive load monitoring system; e-marketplace integration; e-marketplace interoperability; cloud services; and business intelligence.}, 
keywords={cloud computing;competitive intelligence;knowledge management;mobile commerce;multi-agent systems;open systems;radiofrequency identification;security of data;service-oriented architecture;supply chain management;warehouse automation;RFID;Web service selection;business analytics;business intelligence;business optimization;cloud computing;cloud services;data management;e-business engineering;e-marketplace integration;e-marketplace interoperability;emergency communications;mobile commerce;multiagent supply chain collaboration operation model;nonintrusive load monitoring system;pervasive commerce;process automation;service engineering;service-oriented knowledge management;software engineering;user centric security mode;warehousing approach}, 
doi={10.1109/ICEBE.2011.80}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{7939141, 
author={A. Darabseh and N. M. Freris}, 
booktitle={2017 Fourth International Conference on Software Defined Systems (SDS)}, 
title={A Software Defined architecture for Cyberphysical Systems}, 
year={2017}, 
volume={}, 
number={}, 
pages={54-60}, 
abstract={The explosive proliferation of smart devices and cloud computing has ushered the era of Cyberphysical Systems (CPS), a congruence of physical dynamical systems with the cyberspace. The success of deploying an Internet of Things (IoT) interconnecting billions of devices relies heavily upon making the right choices in revisiting traditional architectures for networked control and information processing. Inspired by the concept of Software Defined Systems (SDSys), we propose a control architecture for cyberphysical systems and discuss its advantages in terms of scalability, robustness, security, flexibility, and interoperability. The proposed architecture explicitly leverages the fact that agents possess computational units that may be used for in-network processing and decentralized control actions. We integrate a set of components such as sensors, actuators, access points and coordinators and specify the communication flow, the data flow, and the control flow in a programmable fashion. Control is spread over multiple layers (self-controllers, coordinators, local area controllers, and super-controllers) that form a hierarchy with added autonomy for distributed and decentralized actions. A middleware layer is integrated into the proposed design with several services and units to account for real-time operations in highly dynamic environments. We proceed to identify a wide range of potential vulnerabilities to cyberattacks at all levels, and propose solutions for effective resilience, detection and recovery. The proposed architecture aims at a holistic view with increased adaptability, where the controllers efficiently collaborate to quickly capture and respond to abnormal situations in a self-adjusting manner.}, 
keywords={Internet of Things;cyber-physical systems;software defined networking;CPS;Internet of Things;IoT;SDSys;cyberphysical systems;decentralized control actions;in-network processing;middleware layer;software defined architecture;software defined systems;Aerospace electronics;Computer architecture;Mobile nodes;Real-time systems;Security;Sensors;Software;Cyber Security;Cyberphysical Systems (CPS);Decentralized Control;Distributed Systems;Middleware;Software Defined Systems (SDSys);System Architecture}, 
doi={10.1109/SDS.2017.7939141}, 
ISSN={}, 
month={May},}
@ARTICLE{6517049, 
author={Z. Sanaei and S. Abolfazli and A. Gani and R. Buyya}, 
journal={IEEE Communications Surveys Tutorials}, 
title={Heterogeneity in Mobile Cloud Computing: Taxonomy and Open Challenges}, 
year={2014}, 
volume={16}, 
number={1}, 
pages={369-392}, 
abstract={The unabated flurry of research activities to augment various mobile devices by leveraging heterogeneous cloud resources has created a new research domain called Mobile Cloud Computing (MCC). In the core of such a non-uniform environment, facilitating interoperability, portability, and integration among heterogeneous platforms is nontrivial. Building such facilitators in MCC requires investigations to understand heterogeneity and its challenges over the roots. Although there are many research studies in mobile computing and cloud computing, convergence of these two areas grants further academic efforts towards flourishing MCC. In this paper, we define MCC, explain its major challenges, discuss heterogeneity in convergent computing (i.e. mobile computing and cloud computing) and networking (wired and wireless networks), and divide it into two dimensions, namely vertical and horizontal. Heterogeneity roots are analyzed and taxonomized as hardware, platform, feature, API, and network. Multidimensional heterogeneity in MCC results in application and code fragmentation problems that impede development of cross-platform mobile applications which is mathematically described. The impacts of heterogeneity in MCC are investigated, related opportunities and challenges are identified, and predominant heterogeneity handling approaches like virtualization, middleware, and service oriented architecture (SOA) are discussed. We outline open issues that help in identifying new research directions in MCC.}, 
keywords={application program interfaces;cloud computing;middleware;mobile computing;open systems;API;MCC;SOA;code fragmentation;convergent computing;cross-platform mobile application;middleware;mobile cloud computing;multidimensional heterogeneity;service oriented architecture;taxonomy;virtualization;Cloud computing;Mobile communication;Mobile computing;Smart phones;Taxonomy;Wireless networks;Interoperability;Mobile Cloud Computing;Mobile computation offloading;Portability;Seamless communication;Vertical and Horizontal heterogeneity}, 
doi={10.1109/SURV.2013.050113.00090}, 
ISSN={1553-877X}, 
month={First},}
@INPROCEEDINGS{8003795, 
author={F. Messina and R. Mikkilineni and G. Morana and D. Rosaci}, 
booktitle={2017 IEEE 26th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE)}, 
title={Track Chair's Report: Convergence of Distributed Clouds, Grids and their Management CDCGM 2017}, 
year={2017}, 
volume={}, 
number={}, 
pages={92-94}, 
abstract={This track started in 2009 with opening remarks from the Chair observing that the computing cloud evolution depends on research efforts from the infrastructure providers creating next generation hardware that is service friendly, service developers that embed business service intelligence in the computing infrastructure to create distributed business workflow execution services and service providers who assure service delivery on a massive scale with global interoperability. The state of the art architecture and evolution of the cloud at that time was already increasing datacenter complexity by piling up new layers of management over the many layers that already exist. Since then, the scale of distributed applications and their management have taken a new dimension demanding tolerance to wild fluctuations both in workloads and available computing resource pools. There are many calls to go cloud native and architect applications using the many services provided by the cloud providers such as Amazon Web Services. On the other hand, there are also calls for avoiding vendor lock-in by going multi-cloud and becoming cloud agnostic. In this conference there is a new paper that proposes cloud agnostic approach with globally interoperable cloud network using private or public network while reducing the complexity of Virtual machine image motion across clouds. In addition, there are 7 papers describing advances in current distributed and cloud computing practices dealing with quality of service, adaptive algorithms and software defined network architectures.}, 
keywords={cloud computing;computer centres;grid computing;software defined networking;CDCGM 2017;business service intelligence;cloud architect applications;cloud evolution computing;cloud providers;computing infrastructure;computing resource pools;convergence-of-distributed cloud-grid-and-their-management;datacenter complexity;distributed business workflow execution services;globally interoperable cloud network;infrastructure providers;next generation hardware;private network;public network;software defined network architectures;virtual machine image motion;Business;Cloud computing;Collaboration;Computational modeling;Computer architecture;Conferences;Cloud Computing;Distributed Intelligent Managed Element Networks;Distributed Services Management;Parallel Computing;Services Virtualization;grid computing}, 
doi={10.1109/WETICE.2017.34}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{7172841, 
author={D. Ardagna}, 
booktitle={2015 IEEE/ACM 7th International Workshop on Principles of Engineering Service-Oriented and Cloud Systems}, 
title={Cloud and Multi-cloud Computing: Current Challenges and Future Applications}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-2}, 
abstract={Computing systems are becoming increasingly virtual. We come from a world where applications were entirely developed by organizations for their own use, possibly exploiting components and/or platforms developed by third parties, but mainly deployed and executed on the organizations own IT facilities. With Service Oriented systems, we moved into a world in which a software application may delegate part of its functionality to already existing software services run by external organizations. Recent advances in Cloud computing are pushing virtuality even further: users can access third party software components, hardware physical resources or full application stacks that support execution and automatic management of Cloud based applications, and pay only for the resources they use. Cloud computing is growing daily, providing a vibrant technical environment where innovative solutions and services can be created. The Cloud promises the capability for cheap and flexible services for end-users and allows small organizations and individuals to host and offer world-scale services, themselves. However, while there has been substantial research in the field already, there still remain open challenges. Specifically, Cloud business models and technologies introduce critical issues, such as proprietary APIs and lack of interoperability [1]. The choice of the application architecture matching and fully exploiting the characteristics of the underlying Cloud environments is also critical [2], [3]. At the infrastructural layer, resource contentions lead to unpredictable performance [4] and additional work for resource management [5], automated VM and service migration [6] is still needed. Also networks are frequently the Cloud bottleneck and data center energy management is very critical [7]. To cope with such challenges the adoption of multi-Clouds [8], has been advocated by many researchers, since deploying software on multiple Clouds overcomes single provider unavailability and a- lows to build cost efficient follow the sun applications. Moreover, Cloud computing is also becoming a mainstream solution to provide very large clusters in a pay per use basis to support Big data applications [9]. Many cloud providers already include in their offering MapReduce based platforms (i.e., one of the most adopted framework to support large volume unstructured information processing) such as Google MapReduce framework, Microsoft HDinsight, and Amazon Elastic Compute Cloud. IDC estimates that by 2020, nearly 40% of Big Data analyses will be supported by public cloud. To support such challenges a Model-Driven Development (MDD) approach developed within the MODAClouds (www. modaclouds.eu) and DICE (dice-h2020.eu) European projects will be presented. MDD allows shifting the paradigm from code-centric to model-centric. Models are thus the main artefacts of the development process and enable developers to work at a high level of abstraction by focusing on Cloud concerns rather than implementation details [10]. Model transformations help automating the work of going from abstract concepts to implementation. Moreover, models can also be used to reason about the QoS properties of an application [2] and to support design-time exploration in order to identify the Cloud deployment configuration of minimum cost, while satisfying QoS constraints [3]. Finally, models can be kept alive also at runtime to trigger dynamic adaptation [10], [5], providing QoS guarantees even under workload fluctuations, virtualized systems performance degradations, or failures.}, 
keywords={Big data;Cloud computing;Conferences;Organizations;Quality of service;Resource management;Application portability;Cloud computing;Model Driven Development;Quality of Service}, 
doi={10.1109/PESOS.2015.8}, 
ISSN={2156-7921}, 
month={May},}
@INPROCEEDINGS{5662715, 
author={S. Lei and D. Zishan and G. Jindi}, 
booktitle={2010 Ninth International Conference on Grid and Cloud Computing}, 
title={Research on Key Management Infrastructure in Cloud Computing Environment}, 
year={2010}, 
volume={}, 
number={}, 
pages={404-407}, 
abstract={Cloud customers and providers need to guard against data loss and theft. Encryption of personal and enterprise data is strongly recommended, Strong encryption with key management is one of the core mechanisms that Cloud Computing systems should use to protect data. In cases where the cloud provider must perform key management, in this paper, cloud key management (CKMI) is proposed, its creation and subsequent adoption will reduce the complexity of encryption management. By enabling support for interoperability between cloud cryptographic clients and cloud key management servers, CKMI reduces infrastructure costs and the risks.}, 
keywords={cloud computing;cryptography;CKMI;cloud computing;cloud cryptographic client;cloud key management server;data loss;data theft;encryption management;key management infrastructure;cloud computing;data encryption;key management infrastructure}, 
doi={10.1109/GCC.2010.84}, 
ISSN={2160-4908}, 
month={Nov},}
@INPROCEEDINGS{6975358, 
author={J. Wettinger and K. Görlach and F. Leymann}, 
booktitle={2014 IEEE 18th International Enterprise Distributed Object Computing Conference Workshops and Demonstrations}, 
title={Deployment Aggregates - A Generic Deployment Automation Approach for Applications Operated in the Cloud}, 
year={2014}, 
volume={}, 
number={}, 
pages={173-180}, 
abstract={One of the most essential requirements to make use of the benefits of Cloud computing is fully automated provisioning and deployment of applications including all related resources. This leads to crucial cost reductions when deploying and operating applications in the Cloud because manual processes are slow, error-prone, and thus costly. Both Cloud providers and the open-source community provide a huge variety of tools, APIs, domain-specific languages, and reusable artifacts to implement deployment automation. However, the meta-models behind these approaches are diverse. This diversity makes it challenging to combine different approaches, avoiding vendor lock-in and tooling lock-in. In this work we propose deployment aggregates as a generic means to use and orchestrate different kinds of deployment approaches. We define a generic meta-model and show its relation to existing meta-models in the domain of deployment automation. Moreover, we discuss how existing artifacts can be used as deployment aggregates as a result of transformation and enrichment.}, 
keywords={cloud computing;cloud computing;deployment aggregates;generic deployment automation approach;generic meta-model;Aggregates;Automation;Cloud computing;Databases;Semantics;Topology;Cloud computing;Deployment;DevOps;aggregate;meta-model;operations;orchestration;provisioning;topology;transformation;unification}, 
doi={10.1109/EDOCW.2014.34}, 
ISSN={2325-6583}, 
month={Sept},}
@ARTICLE{6412954, 
author={T. W. Kim and H. C. Kim}, 
journal={IET Communications}, 
title={Service-oriented architecture structure for healthcare systems utilising vital signs}, 
year={2012}, 
volume={6}, 
number={18}, 
pages={3238-3247}, 
abstract={Vital signs such as respiration and pulse and electrocardiography are crucial for monitoring disease and promoting health in the age of ubiquitous cloud computing. However, systems and devices that sense, process and analyse vital signs suffer from a lack of interoperability caused by differences in the platforms, devices and data formats used. Consequently, a particular vendor can provide a limited number of services, but users are not able to access more shared services. To counter these problems, this study proposes a service-oriented architecture for healthcare systems utilising vital signs. The proposed structure differs from the one used to handle business logics in general, because vital signs data are distinct from the types of data used in other enterprises. In this study, these data are expressed as the Health Level Seven standard schema, and the structure uses Object Constraint Language (OCL), a platform-independent specification language, to access the vital signs data and evaluate the state of health. In particular, the use of OCL enables a fast response to changes in service content and reduces maintenance costs.}, 
keywords={cloud computing;electrocardiography;health care;open systems;service-oriented architecture;specification languages;ubiquitous computing;disease monitoring;electrocardiography;health level seven standard schema;healthcare systems;interoperability;maintenance cost;object constraint language;service content;service-oriented architecture structure;specification language;ubiquitous cloud computing;vital signs}, 
doi={10.1049/iet-com.2011.0086}, 
ISSN={1751-8628}, 
month={Dec},}
@INPROCEEDINGS{5072540, 
author={D. Bernstein and E. Ludvigson and K. Sankar and S. Diamond and M. Morrow}, 
booktitle={2009 Fourth International Conference on Internet and Web Applications and Services}, 
title={Blueprint for the Intercloud - Protocols and Formats for Cloud Computing Interoperability}, 
year={2009}, 
volume={}, 
number={}, 
pages={328-336}, 
abstract={Cloud computing is a term applied to large, hosted datacenters, usually geographically distributed, which offer various computational services on a ldquoutilityrdquo basis. Most typically the configuration and provisioning of these datacenters, as far as the services for the subscribers go, is highly automated, to the point of the service being delivered within seconds of the subscriber request. Additionally, the datacenters typically use hypervisor based virtualization as a technique to deliver these services. The concept of a cloud operated by one service provider or enterprise interoperating with a clouds operated by another is a powerful idea. So far that is limited to use cases where code running on one cloud explicitly references a service on another cloud. There is no implicit and transparent interoperability. Use cases for interoperability, as well as work-in-progress around inter-cloud protocols and formats for enabling those use cases, are discussed in this paper.}, 
keywords={open systems;protocols;cloud computing interoperability;computational services;datacenters;hypervisor based virtualization;inter-cloud protocols;transparent interoperability;Cloud computing;Protocols;Cloud Computing;Intercloud}, 
doi={10.1109/ICIW.2009.55}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{6641155, 
author={E. Blasch and A. Steinberg and S. Das and J. Llinas and C. Chong and O. Kessler and E. Waltz and F. White}, 
booktitle={Proceedings of the 16th International Conference on Information Fusion}, 
title={Revisiting the JDL model for information exploitation}, 
year={2013}, 
volume={}, 
number={}, 
pages={129-136}, 
abstract={The original Joint Directors of Laboratories (JDL) model was developed in the early 90's, with revisits in 1998, and 2004. Today, with new technologies of big data, cloud computing, and machine analytics, there is an ever increasing need for integration of people and machines. The original JDL model focused on the data fusion (correlation, filtering, and association) issues, while today there is an increasing emphasis on an integrated approach to information exploitation over sensors, users, and missions using enterprise architectures, interoperability standards, and intelligence to the edge. Given these recent changes to computation and distributed access, we examine ways for extending the JDL model from 1998 to support exploitation functions and information management for situation awareness, massive data analytics for contextual awareness, and domain-specific needs for mission awareness.}, 
keywords={information management;open systems;sensor fusion;ubiquitous computing;JDL model;Joint Directors of Laboratories;big data;cloud computing;contextual awareness;data fusion;distributed access;domain-specific needs;enterprise architectures;exploitation functions;information exploitation;information management;intelligence;interoperability standards;machine analytics;massive data analytics;mission awareness;people-machines integration;sensors;situation awareness;Analytical models;Computational modeling;Context;Context modeling;Data integration;Data models;Information management;JDL model;contextual reasoning;data fusion;enterprise architectures;information management}, 
doi={}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{5999790, 
author={T. El-Ghazawi and F. Pinel and E. G. Talbi and S. Vialle}, 
booktitle={2011 International Conference on High Performance Computing Simulation}, 
title={[Front and back cover]}, 
year={2011}, 
volume={}, 
number={}, 
pages={c1-c4}, 
abstract={The following topics are dealt with: cloud computing interoperability; energy efficient distributed systems; multiprocessor systems; MPSoC; high performance computing systems; security systems; peer-to-peer architectures; manycore system; pattern analysis; pattern recognition; hardware accelerators; biomedical systems; bioinformatics; digital home networks; multimedia contents protection; distributed data mining; parallel data mining; cellular automata and benchmarking.}, 
keywords={benchmark testing;bioinformatics;cellular automata;cloud computing;data mining;energy conservation;multiprocessing systems;open systems;pattern recognition;peer-to-peer computing;security of data;system-on-chip;MPSoC;benchmarking;bioinformatics;biomedical systems;cellular automata;cloud computing interoperability;digital home networks;distributed data mining;energy efficient distributed systems;hardware accelerators;high performance computing systems;manycore system;multimedia contents protection;multiprocessor systems;parallel data mining;pattern analysis;pattern recognition;peer-to-peer architectures;security systems}, 
doi={10.1109/HPCSim.2011.5999790}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{7304339, 
author={A. Giardina and Y. Yang and H. Vu and R. Vasa}, 
booktitle={2015 IEEE 11th International Conference on e-Science}, 
title={Multi-node Multi-agent Cloud Simulation: Approximating Synchronisation}, 
year={2015}, 
volume={}, 
number={}, 
pages={542-550}, 
abstract={Traffic engineering is a key in effective utilisation of the road network infrastructure. Simulation assists traffic engineers making informed decisions on how to operate and direct traffic within the road networks. These simulations are complex, generate big data and require high-powered computers, which can process information faster than real time, to ensure the results can be used to affect traffic. Cloud computing, a relatively new technology paradigm, can meet the essential requirements, such as scalability, interoperability, availability and high-end performance. In this paper, a novel approach to a synchronisation strategy of large-scale complex simulations is proposed. This approach builds upon advancements achieved in distributed computing. The new synchronisation strategy is designed to allow different granularities of synchronisation accuracy. Through this strategy, synchronisation overhead is reduced, thus allowing the computing bandwidth to be applied to simulation performance increases as a result of the trade off between synchronisation accuracy and performance.}, 
keywords={Big Data;cloud computing;multi-agent systems;road traffic;synchronisation;traffic engineering computing;Big data generation;cloud computing;distributed computing;large scale complex simulation;multinode multiagent cloud simulation;road network infrastructure;synchronisation accuracy;synchronisation approximation;synchronisation overhead reduction;synchronisation strategy;traffic engineering;Computational modeling;Computer architecture;Load modeling;Mathematical model;Roads;Synchronization;Vehicles;Agent Based;Cloud;Computing;Simulation;Synchronisation;Traffic}, 
doi={10.1109/eScience.2015.32}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{6215742, 
author={M. A. Muhammad and S. H. Supangkat}, 
booktitle={2012 International Conference on Cloud Computing and Social Networking (ICCCSN)}, 
title={Cloud ITS Indonesia: Transportation information sharing platform}, 
year={2012}, 
volume={}, 
number={}, 
pages={1-4}, 
abstract={Information heterogeneity of ITS Indonesia becomes an obstacle to provide interoperability. The transportation information resource sharing is affected by this condition. ITS generally comprise a distinguished form of large-scale, distributed information system deployed in some form of tangible or virtual network. Cloud computing could benefits ITS for it's essential characteristics, which are on-demand self-service, broad network access, resource pooling, rapid elasticity, and measured service. By establishing Cloud ITS based on cloud computing, it is feasible to accommodate transportation information sharing platform.}, 
keywords={automated highways;cloud computing;open systems;traffic information systems;transportation;broad network access;cloud ITS Indonesia;cloud computing;distributed information system;information heterogeneity;intelligent transportation systems;interoperability;on-demand self-service;resource pooling;transportation information sharing platform;virtual network;Cloud computing;Clouds;Computer architecture;Vehicles;ITS;cloud computing;information sharing;interoperability;transportation;web service}, 
doi={10.1109/ICCCSN.2012.6215742}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{6787267, 
author={S. Boob and H. González-Vélez and A. M. Popescu}, 
booktitle={2014 22nd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing}, 
title={Automated Instantiation of Heterogeneous Fast Flow CPU/GPU Parallel Pattern Applications in Clouds}, 
year={2014}, 
volume={}, 
number={}, 
pages={162-169}, 
abstract={Parallel scientific workloads typically entail highly-customised software environments, involving complex data structures, specialised systems software, and even distinct hardware, where virtualisation is not necessarily supported by third-party providers. Considering the expansion of cloud computing in different domains and the development of different proprietary (e.g. Amazon Web Services, Azure) and open source cloud platforms (Eucalyptus, OpenStack, OpenNebula), users should arguably be able to automatically and seamlessly migrate their parallel workloads across cloud platforms using standardised virtual machines. However, even if it is easier to migrate the workload between nodes when the nodes have a similar configuration on the same platform, the transition between different platforms typically raises different issues such as vendor lock-in, portability, and interoperability. In this paper, we describe our work to automatically deploy a complex parallel software stack on heterogeneous hybrid cloud platforms. We have elastically deployed FastFlow - a C/C++ pattern-based programming framework for multi-/many-core and distributed platforms -- using virtual machines on both CPU and GPU-based architectures between heterogeneous virtualised platforms. Our approach relies on the standard Open Virtualization Format (OVF) in order to achieve a universal description of virtual appliances. Such a description is not only useful for elastically migrating and deploying, but also to determine the hardware/system software configuration needed switching to any new (cloud) image format. We have successfully evaluated our work using virtual machines based on VirtualBox and Amazon Web Services on local cluster and public cloud providers.}, 
keywords={cloud computing;data structures;graphics processing units;parallel programming;virtual machines;virtualisation;Amazon Web services;C/C++ pattern-based programming framework;Eucalyptus;GPU-based architecture;OpenNebula;OpenStack;VirtualBox;automated instantiation;cloud computing;complex data structures;complex parallel software stack;customised software environment;distributed platform;hardware-system software configuration;heterogeneous FastFlow CPU-GPU parallel pattern application;heterogeneous hybrid cloud platform;heterogeneous virtualised platform;image format;local cluster;multicore platform;open source cloud platform;public cloud provider;standard open virtualization format;standardised virtual machine;third-party providers;virtual machine;Automation;Cloud computing;Graphics processing units;Hardware;Monitoring;Servers;Virtual machining;Algorithmic Skeletons;Cloud Computing;FastFlow;Parallel Patterns;Parallel Programming;Platform Interoperability;Virtualization}, 
doi={10.1109/PDP.2014.88}, 
ISSN={1066-6192}, 
month={Feb},}
@INPROCEEDINGS{6927038, 
author={R. Mikkilineni and G. Morana}, 
booktitle={2014 IEEE 23rd International WETICE Conference}, 
title={Infusing Cognition into Distributed Computing: A New Approach to Distributed Datacenters with Self-Managing Services on Commodity Hardware (Virtualized or Not)}, 
year={2014}, 
volume={}, 
number={}, 
pages={131-136}, 
abstract={The advent of virtualization technologies and cloud computing has improved application provisioning speed, resource utilization, fault-management, availability using auto-failover and performance optimization using auto-scaling in distributed computing environments. However, heterogeneous virtualization technologies offered by different service providers with disparate infrastructure and their orchestration and management systems have also increased the complexity of managing distributed applications and vendor lock-in. In this paper we utilize new computing, management and programming models introduced using the DIME network architecture to provide end to end service visibility and control across distributed physical or virtual infrastructure. Resulting decoupling of application and service transaction management from myriad distributed infrastructure management systems at run-time enables policy based, secure, service mobility across physical servers or virtual machines deployed in data enters or public clouds. Using the new architecture we have implemented service self-repair, auto-scaling, live-migration and end-to-end service transaction security independent of server and network security mechanisms.}, 
keywords={cloud computing;cognition;computer centres;distributed processing;resource allocation;virtualisation;DIME network architecture;cloud computing;cognition infusion;commodity hardware;distributed computing;distributed datacenters;distributed infrastructure management systems;heterogeneous virtualization technologies;resource utilization;self-managing services;Computational modeling;Computer architecture;Fluctuations;Security;Servers;Turing machines;Cognitive Container;DIME network architecture (DNA);business processes;cloud computing;cognition;distributed computing;service management}, 
doi={10.1109/WETICE.2014.67}, 
ISSN={1524-4547}, 
month={June},}
@INPROCEEDINGS{6477673, 
author={N. Marangos and P. Rizomiliotis and L. Mitrou}, 
booktitle={2012 IEEE Globecom Workshops}, 
title={Digital forensics in the Cloud Computing Era}, 
year={2012}, 
volume={}, 
number={}, 
pages={775-780}, 
abstract={Cloud Computing (CC) is a promising next-generation computing paradigm providing network and computing resources on demand via the web. The cloud market is still in its infancy and all major issues, ranging from interoperability and standardization, to legislation and SLA contracts are still wide open. However, the main obstacle for a more catholic acceptance of the cloud model is security. In the CC model, the client has limited control over his data and computations as he outsources everything to the cloud provider. This basic CC feature influences several security related areas. In this paper, we investigate the impact that the CC model has on the digital forensics methodologies. Digital Forensics (DF) is the branch of computer science that develops evidence pertained in the digital world for use in civil or criminal court proceedings and this shared ownership of digital resources that the CC model inherits influences severely their analysis.}, 
keywords={cloud computing;digital forensics;CC model;Web;cloud computing era;digital forensics methodologies;digital resources;interoperability;next-generation computing paradigm;Cloud computing;Computational modeling;Digital forensics;NIST;cloud computing;digital forensics;digital investigation}, 
doi={10.1109/GLOCOMW.2012.6477673}, 
ISSN={2166-0077}, 
month={Dec},}
@INPROCEEDINGS{6297204, 
author={M. Phankokkruad}, 
booktitle={2012 International Conference on Computer Information Science (ICCIS)}, 
title={Implement of cloud computing for e-learning system}, 
year={2012}, 
volume={1}, 
number={}, 
pages={7-11}, 
abstract={E-learning systems provide processes of delivering the learning contents to learners who have different backgrounds, interests, and locations away from a classroom in order to maximize the effectiveness of learning. Usually, the classical e-learning system is based on client/server architecture thus they lack of the scalability, flexibility and interoperability. It makes the learning resources cannot share, and the system improvement is not easily. This paper proposes the cloud computing architecture in the e-learning system that the architecture separate into three layers includes infrastructure, platform and application. This architecture needs to design components in order to transfer the learning resources to the cloud platform. Infrastructure layer, the learning resources from the traditional system are transferred to the cloud database instead of the usual DBMS. Platform layer, a new e-learning system that consists of the CMS, AMS, and other service components were developed. These components were developed to be the intermediary between cloud database and the applications. Finally, application layer, CAT web application and WBI application were developed for interacting with the student's client. The results shown that all applications co-operated with the other components suitably. Applying the cloud computing makes the classical e-learning more scalability, flexibility, and interoperability. Moreover, cloud computing induces the way that e-learning can be share and distribute the learning resources to any kind of devices and platforms. Since the e-learning services are used for a relative short time, pay per use of the cloud could reduce the cost thus the organization pay only for capacity that actually used.}, 
keywords={client-server systems;cloud computing;computer aided instruction;database management systems;educational courses;open systems;AMS;CAT web application;CMS;DBMS;WBI application;application layer;classroom;client-server architecture;cloud computing architecture;cloud database;cloud platform;e-learning services;e-learning system;infrastructure layer;interoperability;learning contents;learning resources;service components;student client;system improvement;Computer architecture;Databases;Energy management;Ontologies;Scalability;Servers;Software}, 
doi={10.1109/ICCISci.2012.6297204}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{7019373, 
author={R. S. Amshavalli and G. Kavitha}, 
booktitle={2014 IEEE International Conference on Advanced Communications, Control and Computing Technologies}, 
title={Increasing the availability of cloud resources using broker with semantic technology}, 
year={2014}, 
volume={}, 
number={}, 
pages={1578-1582}, 
abstract={Cloud computing is the blending technology of parallel and distributing computing, and its main aim is providing Everything as a Service to the consumers. The private cloud is one of the deployment models and it offers resources in an on-demand manner. Resource Management is the challenging task between different private cloud because of the interoperability issues since the private clouds are managed by different type of cloud middleware's and each of them has their own mechanism and protocols. To manage the resource efficiently and to increase the resource availability it is essential to overcome the interoperability issues between the private clouds. In this paper a common mechanism called Semantic Cloud Resource Broker (SCRB) is introduced between the Eucalyptus and Open Nebula based private clouds. It also includes the semantic technology to achieve meaningful search. Hence an OWL-based ontology indexing and retrieval algorithms is implemented to improve precision and recall and thereby improves the success rate of cloud resources.}, 
keywords={cloud computing;data privacy;indexing;information retrieval;knowledge representation languages;middleware;ontologies (artificial intelligence);open systems;semantic Web;Eucalyptus;OWL-based ontology indexing;Open Nebula;SCRB;blending technology;cloud middleware;deployment models;distributing computing;everything as a service;interoperability issues;parallel computing;private cloud;resource management;retrieval algorithms;semantic cloud resource broker;semantic technology;Authentication;Handheld computers;Indexes;Ontologies;Scalability;Semantics;Availability;Interoperability;Ontology;Resource management;Semantic search}, 
doi={10.1109/ICACCCT.2014.7019373}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{5159214, 
author={R. Mikkilineni and V. Sarathy}, 
booktitle={2009 18th IEEE International Workshops on Enabling Technologies: Infrastructures for Collaborative Enterprises}, 
title={Cloud Computing and the Lessons from the Past}, 
year={2009}, 
volume={}, 
number={}, 
pages={57-62}, 
abstract={The skyrocketing demand for a new generation of cloud-based consumer and business applications is driving the need for next generation of data centers that must be massively scalable, efficient, agile, reliable and secure. The authors see a parallel between the state of the data centers today and the evolution of the Intelligent Network (IN) infrastructure in telecommunication. The telecommunications networks have for many years, demonstrated their ability to reliably enable network (voice) services creation, assurance and delivery on a massive scale. Based on an analysis of the Intelligent Networks in telecommunications to identify proven concepts and key lessons that can be applied to enable next generation IT datacenters experience this paper asserts that: (1) In order to scale cloud services reliably to millions of service developers and billions of end users the next generation cloud computing and datacenter infrastructure will have to follow an evolution similar to the one that led to the creation of scalable telecommunication networks. (2) In the future network-based cloud service providers will leverage virtualization technologies to be able to allocate just the right levels of virtualized compute, network and storage resources to individual applications based on real-time business demand while also providing full service level assurance of availability, performance and security at a reasonable cost. (3) A key component - identified in this paper as the Virtual Resource Mediation Layer (VRML), must be developed through industry collaboration to enable interoperability of various public and private clouds. This layer will form the basis for ensuring massive scalability of cloud infrastructure by enabling distributed service creation, service delivery and service assurance without any single vendor domination. (4) The next generation virtualization technologies must allow applications to dynamically access CPU, memory, bandwidth and storage (capacity, I/O and - throughput) in a manner similar to that of the telecommunications 800 Service Call Model with one level of indirection and mediation. The authors believe that the next generation cloud evolution is a fundamental transformation - and not just an evolutionary stack of XaaS implementations, which will enable global service collaboration networks utilizing optimally distributed and managed computing, network and storage resources driven in real-time by business priorities.}, 
keywords={Internet;computer centres;electronic commerce;intelligent networks;open systems;business applications;cloud computing;cloud-based consumer;data centers;distributed service creation;intelligent network infrastructure;interoperability;private clouds;public clouds;service assurance;service delivery;virtual resource mediation layer;virtualization;Application virtualization;Cloud computing;Computer networks;Intelligent networks;Mediation;Next generation networking;Resource management;Resource virtualization;Telecommunication computing;Telecommunication network reliability;Cloud Computing;Service Collaboration Network;xAAS}, 
doi={10.1109/WETICE.2009.14}, 
ISSN={1524-4547}, 
month={June},}
@INPROCEEDINGS{6753840, 
author={M. Franke and A. Wuttig and T. Schlegel}, 
booktitle={2013 IEEE 5th International Conference on Cloud Computing Technology and Science}, 
title={Enabling Virtual, Cloud-Based Sensors in Assisted Living Environments}, 
year={2013}, 
volume={1}, 
number={}, 
pages={513-518}, 
abstract={In this work, we combine the field of cloud computing with assisted living to utilize an improved activity classification. The proposed system addresses the challenge of enabling heterogeneous, cloud-based sensors in small home environments. With a semantic and model-based approach, we seamlessly integrate Web services as virtual sensors and, therefore, increasing the accuracy of human activity classifiers. We solve the most important compelling issue of interoperability, by using generated wrapper classes and semantically unify all heterogeneous sensor events within the system. Our approach is evaluated with a test installation by means of the requirements for Sensor Web Infrastructures combined with the one for assisted living environments.}, 
keywords={Web services;assisted living;cloud computing;open systems;pattern classification;semantic Web;sensors;Web service integration;assisted living environments;heterogeneous cloud-based sensors;human activity classifier accuracy improvement;interoperability;model-based approach;semantic unification approach;sensor Web infrastructures;small-home environments;virtual-cloud-based sensors;wrapper classes;Clouds;Middleware;Semantics;Sensor phenomena and characterization;Sensor systems;Temperature sensors;assisted living environments;cloud-based sensors;semantic middleware;semantic sensor networks;sensor web}, 
doi={10.1109/CloudCom.2013.74}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{7018544, 
author={T. Nodehi and S. Ghimire and R. Jardim-Gonçalves}, 
booktitle={2014 2nd International Conference on Model-Driven Engineering and Software Development (MODELSWARD)}, 
title={Toward a unified intercloud interoperability conceptual model for IaaS cloud service}, 
year={2014}, 
volume={}, 
number={}, 
pages={673-681}, 
abstract={The concept of interoperation between cloud providers is a recent research challenging objective. Current cloud systems have been developed without concerns of seamless cloud interconnection, and actually they do not support intercloud interoperability. The paper proposes a conceptual model for Intercloud Interoperability, to enable schedule dynamic operation for Infrastructure as a Service (IaaS) between different clouds. The paper is providing a better understanding of elaborates on the cloud computing architecture, appropriate metrics for Service Level Agreements (SLA) and Quality of Service (QoS) models that are required for seamless integration and interoperability between cloud environments. Then, a conceptual model for the Intercloud Interoperability Framework for Workload Migration is proposed. The novel component of the framework that provides interoperability is the Transformation Engine that maps workload between heterogeneous cloud providers, whilst Model Driven Architecture (MDA) is adopted as an applicable method for developing the Transformation Engine module.}, 
keywords={Cloud computing;Computational modeling;Computer architecture;Engines;Interoperability;Measurement;Quality of service;Cloud Computing;Intercloud Interoperability;Model Driven Architecture (MDA);Service Level Agreements (SLA)}, 
doi={}, 
ISSN={}, 
month={Jan},}
@INPROCEEDINGS{7149634, 
author={A. Tashkandi and I. Al-Jabri}, 
booktitle={2015 International Conference on Cloud Computing (ICCC)}, 
title={Cloud Computing Adoption by Higher Education Institutions in Saudi Arabia: Analysis Based on TOE}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={(1) Background, Motivation and Objective: Academic study of Cloud Computing within Saudi Arabia is an emerging research field. Saudi Arabia represents the largest economy in the Arabian Gulf region. This positions it as a potential market of cloud computing technologies. Adoption of new innovations should be preceded by analysis of the added value, challenges and adequacy from technological, organizational and environmental perspectives. (2) Statement of Contribution/Method: This cross-sectional exploratory empirical research is based on Technology, Organization and Environment model targeting higher education institutions. In this study, the factors that influence the adoption by higher education institutions were analyzed and tested using Partial Least Square. (3) Results, Discussion and Conclusions: Three factors were found significant in this context. Relative Advantage, Data Privacy and Complexity are the most significant factors. The model explained 43% of the total adoption measure variation. Significant differences in the areas of cloud computing compatibility, complexity, vendor lock-in and peer pressure between large and small institutions were revealed. Items for future cloud computing research were explored through open-ended questions. Adoption of cloud services by higher education institutions has been started. It was found that the adoption rate among large universities is higher than small higher education institutions. Improving the network and Internet Infrastructure in Saudi Arabia at an affordable cost is a pre-requisite for cloud computing adoption. Cloud service provider should address the privacy and complexity concerns raised by non-adopters. Future information systems that are potential for hosting in cloud were prioritized.}, 
keywords={cloud computing;computer aided instruction;data privacy;educational institutions;further education;Arabian Gulf region;Internet infrastructure;Saudi Arabia;TOE model;cloud computing;data privacy;higher education institutions;partial least square;technology, organization and environment model;universities;Cloud computing;Complexity theory;Computational modeling;Context;Education;Organizations;Technological innovation}, 
doi={10.1109/CLOUDCOMP.2015.7149634}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{6720767, 
author={C. Viana-Ferreira and C. Costa}, 
booktitle={2013 IEEE 15th International Conference on e-Health Networking, Applications and Services (Healthcom 2013)}, 
title={A cloud based architecture for medical imaging services}, 
year={2013}, 
volume={}, 
number={}, 
pages={707-709}, 
abstract={Medical imaging has been increasingly a computational matter, from image acquisition, to its storage, processing and visualization. The recent advances in cloud computing also represent a great opportunity to distribute and process imaging workflows. However, this combination brings a new set of challenges. In this paper we discuss why and how cloud technologies can become a future environment for the deployment of medical imaging services. Furthermore, we propose an architecture with technological approaches oriented to this demanding scenario, that deals well with critical issues such as security, communication latency and interoperability.}, 
keywords={biomedical imaging;cloud computing;data visualisation;medical information systems;open systems;cloud based architecture;cloud technologies;communication latency;computational matter;image acquisition;interoperability;medical imaging services;process imaging workflows;Cloud computing;DICOM;Logic gates;Medical services;Picture archiving and communication systems;Security;DICOM;PACS;cloud;medical imaging}, 
doi={10.1109/HealthCom.2013.6720767}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{5928894, 
author={Chi-Jen Wu and Jan-Ming Ho and Ming-Syan Chen}, 
booktitle={2011 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, 
title={Time-critical event dissemination in geographically distributed clouds}, 
year={2011}, 
volume={}, 
number={}, 
pages={654-659}, 
abstract={Cloud computing has rapidly become a new infrastructure for organizations to reduce their capital cost in IT investment and to develop planetary-scale distributed applications. One of the fundamental challenges in geographically distributed clouds is to provide efficient algorithms for supporting intercloud data management and dissemination. In this paper, we present Plume, a generic distributed intercloud overlay for time-critical event dissemination services. Plume aims at improving the interoperability of interclouds in time-critical event dissemination services, such as computing policy updating, message sharing, event notifications and so forth. Plume organizes these distributed clouds into a novel quorum ring overlay to support a constant event dissemination latency. Our numerical results show that the proposed Plume greatly improves the efficiency as compared to a DHT-based overlay approach and provides better scalability than the fully-meshed approach.}, 
keywords={cloud computing;open systems;DHT-based overlay approach;IT investment;Plume;capital cost reduction;cloud computing;computing policy updating;event notifications;geographically distributed clouds;intercloud data dissemination;intercloud data management;interclouds interoperability;message sharing;planetary-scale distributed applications;time-critical event dissemination services}, 
doi={10.1109/INFCOMW.2011.5928894}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{6583487, 
author={M. Serrano and H. N. M. Quoc and M. Hauswirth and W. Wang and P. Barnaghi and P. Cousin}, 
booktitle={2013 IEEE 14th International Symposium on "A World of Wireless, Mobile and Multimedia Networks" (WoWMoM)}, 
title={Open services for IoT cloud applications in the future internet}, 
year={2013}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Internet of Things (IoT) is an emerging area that not only requires development of infrastructure but also deployment of new services capable of supporting multiple, scalable (cloud-based) and interoperable (multi-domain) applications. In the race of designing the IoT as part of the Future Internet architecture, academic and ICT's (Information and Communication Technology) industry communities have realized that a common IoT problem to be tackled is the interoperability of the information. In this paper we review recent trends and challenges on interoperability, and discuss how semantic technologies, open service frameworks and information models can support data interoperability in the design of the Future Internet, taking the IoT and Cloud Computing as reference examples of application domains.}, 
keywords={Internet of Things;cloud computing;open systems;ICT industry;Internet architecture;Internet of Things;IoT cloud applications;cloud computing;data interoperability;information and communication technology;multidomain applications;open services;semantic technologies;Cloud computing;Data models;Interoperability;Ontologies;Semantics;Sensors;Cloud Computing;Cloud Services;Future Internet;Intenet of Things;Interoperability;Open Services;Semantics}, 
doi={10.1109/WoWMoM.2013.6583487}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{6649727, 
author={J. Zhang and B. Iannucci and M. Hennessy and K. Gopal and S. Xiao and S. Kumar and D. Pfeffer and B. Aljedia and Y. Ren and M. Griss and S. Rosenberg and J. Cao and A. Rowe}, 
booktitle={2013 IEEE International Conference on Services Computing}, 
title={Sensor Data as a Service -- A Federated Platform for Mobile Data-centric Service Development and Sharing}, 
year={2013}, 
volume={}, 
number={}, 
pages={446-453}, 
abstract={The Internet of Things (IoT) offers the promise of integrating the digital world of the Internet with the physical world in which we live. But realizing this promise necessitates a systematic approach to integrating the sensors, actuators, and information on which they operate into the Internet we know today. This paper reports the design and development of an open community-oriented platform aiming to support federated sensor data as a service, featuring interoperability and reusability of heterogeneous sensor data and data services. The concepts of virtual sensors and virtual devices are identified as central autonomic units to model scalable and context-aware configurable/reconfigurable sensor data and services. The decoupling of the storage and management of sensor data and platform-oriented metadata enables the handling of both discrete and streaming sensor data. A cloud computing-empowered prototyping system has been established as a proof of concept to host smart community-oriented sensor data and services.}, 
keywords={Internet of Things;cloud computing;meta data;mobile computing;open systems;virtual reality;Internet of things;IoT;central autonomic units;cloud computing-empowered prototyping system;context-aware configurable sensor data;context-aware reconfigurable sensor data;data services;discrete sensor data;federated platform;federated sensor data as a service;heterogeneous sensor data;interoperability;mobile data-centric service development;mobile data-centric service sharing;open community-oriented platform;platform-oriented metadata;reusability;smart community-oriented sensor data;smart community-oriented sensor services;streaming sensor data;virtual devices;virtual sensors;Data models;Data visualization;Databases;Internet;Interoperability;Scalability;Temperature sensors}, 
doi={10.1109/SCC.2013.34}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{5541981, 
author={R. Mikkilineni}, 
booktitle={2010 19th IEEE International Workshops on Enabling Technologies: Infrastructures for Collaborative Enterprises}, 
title={WETICE 2010 2nd Workshop on Collaboration and Cloud Computing (CCC) Theme: Computing Clouds with Telecom Grade "Trust" and Global Interoperability}, 
year={2010}, 
volume={}, 
number={}, 
pages={44-47}, 
abstract={The combination of hardware assisted virtualization and the broadband Internet have taken the Information Technology (IT) hosted managed services to a next level of evolution, where the software applications have become independent of the hardware infrastructure and can be migrated at will. This introduces two key issues that need to be addressed to fully leverage the potential that the new servers and virtualization offer: 1. The operation and management of virtual services have to be decoupled from the operation and management of the server, network and storage physical infrastructure that hosts them 2. Resource provisioning must be application sensitive, dynamic to meet the transient nature of services that can migrate and must accommodate latency constraints of services that utilize them. The second international IEEE Workshop On collaboration & Cloud Computing under the aegis of 19th IEEE International Workshops on Enabling Technologies: Infrastructures for Collaborative Enterprises (WETICE) 2010, is devoted to address the operation and management issues in the next generation cloud computing. Seven papers discuss various aspects of bringing telecom grade “trust” and global interoperability to distributed collaborating computing clouds.}, 
keywords={Business;Cloud computing;Clouds;Hardware;Servers;Telecommunications;Cloud Computing;Data Center;Distributed Computing;Virtualization}, 
doi={10.1109/WETICE.2010.13}, 
ISSN={1524-4547}, 
month={June},}
@INPROCEEDINGS{5764071, 
author={Chun-Chia Wang and Wen-Chang Pai and N. Y. Yen}, 
booktitle={2011 3rd International Conference on Computer Research and Development}, 
title={A sharable e-Learning platform based on Cloud computing}, 
year={2011}, 
volume={2}, 
number={}, 
pages={1-5}, 
abstract={Over the Internet, e-Learning has speeded up the knowledge transfer without restrictions on time and space in recent years. In order to achieve the goal of knowledge sharing and reusing interactively, lots of available e-Learning standards have been adapted to complete this purpose. Normally, learning objects meeting these standards are sharable with other e-Learning platforms. Most e-Learning platforms, however, are unable to share learning objects directly on the Internet. The characteristics of Cloud computing provide a promising infrastructure to compute and store resources as services. Hence, this paper introduces Cloud computing into an e-Learning platform to allow the integration of different e-Learning standards to enhance interoperability of learning objects. By combining the characteristics of e-Learning and approach of Cloud computing, educators have not to re-construct learning objects to satisfy e-Learning environments developed from different e-Learning standards.}, 
keywords={cloud computing;computer aided instruction;Internet;cloud computing;knowledge sharing;sharable e-learning platform;Cloud computing;Computer architecture;Electronic learning;Least squares approximation;Standards;XML;Cloud Computing;Learning Objects;Learning Standards;e-Learning}, 
doi={10.1109/ICCRD.2011.5764071}, 
ISSN={}, 
month={March},}
@INBOOK{7493792, 
author={San Murugesan and Irena Bojanova}, 
booktitle={Encyclopedia of Cloud Computing}, 
title={Engineering Applications of the Cloud}, 
year={2016}, 
volume={}, 
number={}, 
pages={744-}, 
abstract={Cloud computing, where services are delivered over a network, has the potential to transform the practice of engineering. With tools and services residing in the cloud environment, engineering and manufacturing companies can now have access to shared computing resources and advanced application services everywhere and anytime on an as-needed basis. This results in considerable cost savings in expenditure on information technology (IT) and enhances their ability to deliver high-quality engineered products. This chapter reviews cloud service models and discusses the approaches that cloud service providers use to deliver their application services. For cloud computing truly to deliver values to engineering enterprises, information and service interoperability and collaborative technologies are needed to support the entire engineering product life cycle. Two example applications are introduced to illustrate the potential deployment of cloud service environment for supporting information interoperability and collaborative design. The first example introduces the incorporation of engineering information models for product information sharing and exchange in the cloud environment. The second example describes deploying application services in the cloud environment to support virtual brainstorming and team engagement in collaborative engineering design.}, 
keywords={}, 
doi={10.1002/9781118821930.ch40}, 
ISSN={}, 
publisher={Wiley-IEEE Press}, 
isbn={9781118821930}, 
url={http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7493792},}
@INPROCEEDINGS{8001708, 
author={V. Tam and M. Gupta}, 
booktitle={2017 IEEE 17th International Conference on Advanced Learning Technologies (ICALT)}, 
title={Facilitating the Open Learning and Education through Facial Analytics and Video Streaming}, 
year={2017}, 
volume={}, 
number={}, 
pages={31-33}, 
abstract={With the popularity of many massive online courses (MOOCs) and relevant platforms such as the Coursera, edX and Udemy, open learning and education will obviously become a very influential and significant sector in education all over the world, especially for developing countries like China and India with large population sizes and huge demands for tertiary education to develop the knowledge-based economy. Due to the potentially large class sizes for courses on an open learning platform, it can be difficult to monitor each individual or averaged performance in each open learning course, thus possibly leading to a relatively higher dropout rate at the end of the course. This is where computationally intelligent methods such as the machine learning or learning analytics techniques may help to effectively monitor each individual or group performance in an open learning course. In this work, we propose a cloud-based and personalized learning platform enhanced by a very efficient and intelligent facial analytics algorithm to capture learners' real-time responses when viewing any open educational resources such as the Ted Talks, YouTube or MERLOT on mobile devices. After analyzing learners' instant responses and attention spans, it may help to quickly identify those difficult and/or less interesting topics. Besides, interactive quizzes can be flexibly added by course instructors into different sections of an online educational resource to evaluate each individual learner's actual level of understanding while relevant video files or course material is being streamed onto the learner's mobile device from the Dropbox cloud storage. All the data about the learning progress will be securely uploaded onto a password-protected cloud computing platform for further analyzes. Furthermore, the cloud platform ensures the interoperability of various mobile devices in this newly enhanced learning analytic system with which some initial and positive students' feedback was collected- This work clearly provides many promising directions for future extensions of the next-generation open learning and education platform.}, 
keywords={cloud computing;computer aided instruction;Dropbox cloud storage;MOOC;cloud-based personalized learning platform;facial analytics;massive online courses;open learning;open learning course;password-protected cloud computing platform;video streaming;Androids;Cloud computing;Education;Humanoid robots;Mobile handsets;Streaming media;Synchronization;facial analytics;interactive quizzes;open learning and education;personalized learning;video streaming}, 
doi={10.1109/ICALT.2017.110}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{7009018, 
author={J. Opara-Martins and R. Sahandi and F. Tian}, 
booktitle={International Conference on Information Society (i-Society 2014)}, 
title={Critical review of vendor lock-in and its impact on adoption of cloud computing}, 
year={2014}, 
volume={}, 
number={}, 
pages={92-97}, 
abstract={Cloud computing offers an innovative business model for organizations to adopt IT services at a reduced cost with increased reliability and scalability. However organizations are slow in adopting the cloud model due to the prevalent vendor lock-in issue and challenges associated with it. While the existing cloud solutions for public and private companies are vendor locked-in by design, their existence is subject to limited possibility to interoperate with other cloud systems. In this paper we have presented a critical review of pertinent business, technical and legal issues associated with vendor lock-in, and how it impacts on the widespread adoption of cloud computing. The paper attempts to reflect on the issues associated with interoperability and portability, but with a focus on vendor lock-in. Moreover, the paper demonstrates the importance of interoperability, portability and standards applicable to cloud computing environments along with highlighting other corporate concerns due to the lock-in problem. The outcome of this paper provides a foundation for future analysis and review regarding the impact of vendor neutrality for corporate cloud computing application and services.}, 
keywords={business data processing;cloud computing;law;open systems;IT service adoption;business issues;cloud computing environment;cloud model;cloud solutions;cloud system interoperation;corporate cloud computing application;innovative business model;legal issues;portability;private companies;public companies;standards;technical issues;vendor lock-in issue;vendor neutrality;Cloud computing;Interoperability;Organizations;Standards organizations;API's;cloud computing;data;enterprise migration;interoperability;portability;standards;vendor lock-in}, 
doi={10.1109/i-Society.2014.7009018}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{6470851, 
author={Y. Hu and Fangjie Lu and I. Khan and G. Bai}, 
booktitle={2012 International Conference for Internet Technology and Secured Transactions}, 
title={A cloud computing solution for sharing healthcare information}, 
year={2012}, 
volume={}, 
number={}, 
pages={465-470}, 
abstract={In recent years, sharing healthcare information becomes one of essential requirements of e-health development. To cover this gap, different solutions are presented through different technologies. In this paper, we proposed a cloud computing solution for sharing healthcare information based on Google App Engine (GAE). With the experiment test results, we achieve interoperability among different healthcare centers and between healthcare providers and receivers with high stability and availability.}, 
keywords={cloud computing;health care;information management;medical information systems;open systems;GAE;Google App Engine;cloud computing solution;e-health development;electronic health;healthcare center;healthcare information sharing;healthcare provider;healthcare receiver;interoperability;Educational institutions;Hospitals;Monitoring;Read only memory;GAE;cloud computing;healthcare information;interoperability}, 
doi={}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{7247443, 
author={D. Armstrong and R. Kavanagh and K. Djemame}, 
booktitle={2015 IEEE International Conference on Communication Workshop (ICCW)}, 
title={Towards an interoperable energy efficient Cloud computing architecture - practice amp; experience}, 
year={2015}, 
volume={}, 
number={}, 
pages={1807-1812}, 
abstract={The energy consumption of Cloud computing continues to be an area of significant concern as data center growth continues to increase. This paper reports on an energy efficient interoperable Cloud architecture realized as a Cloud toolbox that focuses on reducing the energy consumption of Cloud applications holistically across all deployments models. The architecture supports energy efficiency at service construction, deployment, and operation and interoperability through the use of the Open Virtualization Format (OVF) standard. We discuss our practical experience during implementation and present an initial performance evaluation of the architecture. The results show that the implementing Cloud provider interoperability is feasible and incurs minimal performance overhead during application deployment in comparison to the time taken to instantiate Virtual Machines.}, 
keywords={cloud computing;energy conservation;open systems;power aware computing;virtualisation;application deployment;cloud applications;cloud provider interoperability;cloud toolbox;interoperable energy efficient cloud computing;open virtualization format standard;performance overhead;Cloud computing;Computer architecture;Energy consumption;Interoperability;Measurement;Servers;Standards;Cloud Architectures;Cloud Computing;Cloud Interoperability;Energy;Energy Efficiency;IaaS;PaaS;Performance Evaluation;Power;SaaS}, 
doi={10.1109/ICCW.2015.7247443}, 
ISSN={2164-7038}, 
month={June},}
@INPROCEEDINGS{6489788, 
author={J. Bermejo Muñoz and S. G. Galán and L. R. López and R. P. Prado and J. E. Muñoz and T. Grimstad and D. R. López}, 
booktitle={Proceedings of 2012 IEEE 17th International Conference on Emerging Technologies Factory Automation (ETFA 2012)}, 
title={Interoperability in large scale cyber-physical systems}, 
year={2012}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={While the capability for growing on demand is the design foundation of the new generation of software platforms, physical systems always have limited resources. Therefore, there is a need to optimise the existing infrastructures and evolving them building on interoperability. The optimisation of the infrastructure entails not only addressing the computational and storage capabilities but also the network, its associated intelligence and the exchanged information. Therefore, the interoperability requirement in a large scale cyber-system spans from the lowest layers, interfacing with the physical resources, to the software building blocks, client devices and handled data. In this paper, several initiatives addressing interoperability among cloud IaaS layers, IaaS-PaaS, PaaS-SaaS, Cloud-Network and data are presented.}, 
keywords={cloud computing;large-scale systems;optimisation;IaaS-PaaS;PaaS-SaaS;client devices;cloud IaaS layers;cloud-network;computational capabilities;design foundation;infrastructure optimisation;interoperability;large scale cyber-physical systems;physical resources;software building blocks;software platforms;storage capabilities;Cloud computing;Interoperability;OCCI;OSGi}, 
doi={10.1109/ETFA.2012.6489788}, 
ISSN={1946-0740}, 
month={Sept},}
@ARTICLE{7054724, 
author={S. Bitam and A. Mellouk and S. Zeadally}, 
journal={IEEE Wireless Communications}, 
title={VANET-cloud: a generic cloud computing model for vehicular Ad Hoc networks}, 
year={2015}, 
volume={22}, 
number={1}, 
pages={96-102}, 
abstract={Cloud computing is a network access model that aims to transparently and ubiquitously share a large number of computing resources. These are leased by a service provider to digital customers, usually through the Internet. Due to the increasing number of traffic accidents and dissatisfaction of road users in vehicular networks, the major focus of current solutions provided by intelligent transportation systems is on improving road safety and ensuring passenger comfort. Cloud computing technologies have the potential to improve road safety and traveling experience in ITSs by providing flexible solutions (i.e., alternative routes, synchronization of traffic lights, etc.) needed by various road safety actors such as police, and disaster and emergency services. In order to improve traffic safety and provide computational services to road users, a new cloud computing model called VANET-Cloud applied to vehicular ad hoc networks is proposed. Various transportation services provided by VANET-Cloud are reviewed, and some future research directions are highlighted, including security and privacy, data aggregation, energy efficiency, interoperability, and resource management.}, 
keywords={cloud computing;data privacy;intelligent transportation systems;mobile computing;road safety;road traffic;traffic engineering computing;vehicular ad hoc networks;ITS;Internet;VANET-cloud;data aggregation;data privacy;data security;energy efficiency;generic cloud computing model;intelligent transportation system;interoperability;network access model;resource management;road safety;traffic accident;vehicular ad hoc networks;Ad hoc networks;Cloud computing;Computational modeling;Intelligent vehicles;Logic gates;Mobile communication;Vehicular ad hoc networks}, 
doi={10.1109/MWC.2015.7054724}, 
ISSN={1536-1284}, 
month={February},}
@ARTICLE{7152867, 
author={S. Guan and R. De Grande and A. Boukerche}, 
journal={IEEE Transactions on Cloud Computing}, 
title={A Multi-layered Scheme for Distributed Simulations on the Cloud Environment}, 
year={2015}, 
volume={PP}, 
number={99}, 
pages={1-1}, 
abstract={In order to improve simulation performance and to integrate simulation resources among geographically distributed locations, the concept of distributed simulation is proposed. Several types of distributed simulation standards, such as DIS and HLA, are established to formalize simulations and achieve reusability and interoperability of simulation components. To implement these distributed simulation standards and to manage the underlying system of distributed simulation applications, we employ Grid Computing and Cloud Computing technologies. These tackle the details of operation, configuration, and maintenance of simulation platforms in which simulation applications are deployed. However, for modelers who may not be familiar with the management of distributed systems, it is challenging to make a simulation-run-ready environment among different types of computing resources and network environments. In this article, a new multi-layered cloud-based scheme is proposed for enabling modeling and simulation based on different distributed simulation standards. This scheme is designed to ease the management of underlying resources and to achieve rapid elasticity that can provide unlimited computing capability to end users; it considers energy consumption, security, multi-user availability, scalability, and deployment issues. A mechanism for handling diverse network environments is described; by adopting it, idle public resources can be easily configured as additional computing capabilities for the local resource pool. A fast deployment model is built to relieve the migration and installation process of this platform. An energy-saving strategy is utilized to reduce the consumption of computing resources. Security components are implemented to protect sensitive information and block malicious attacks in the cloud. In the experiments, the proposed scheme is compared with its corresponding grid computing platform; the cloud computing platform achieves similar performance, but in- orporates many advantages that the Cloud can provide.}, 
keywords={Analytical models;Cloud computing;Computational modeling;Energy consumption;Load modeling;Security;Standards;Availability;Cloud Computing;DIS;Distributed Simulations;Elasticity;Energy Consumption;HLA;Usability}, 
doi={10.1109/TCC.2015.2453945}, 
ISSN={2168-7161}, 
month={},}
@INPROCEEDINGS{7845474, 
author={J. Delsing and J. Eliasson and J. van Deventer and H. Derhamy and P. Varga}, 
booktitle={2016 IEEE 3rd World Forum on Internet of Things (WF-IoT)}, 
title={Enabling IoT automation using local clouds}, 
year={2016}, 
volume={}, 
number={}, 
pages={502-507}, 
abstract={Various forms of cloud computing principles and technologies are becoming important recently. This paper addresses cloud computing for automation and control applications. It's argued that the open Internet cloud idea has such limitations that its not appropriate for automation. Since automation is physically and geographically local, it is inevitable to introduce the concept of local automation clouds. It's here proposed that local automation clouds should be self contained an be able to execute the intended automation functionalities without any external resources. Thus providing a fence at the rim of the local cloud preventing any inbound or outbound communication. Such a local cloud provides possibilities to address key requirements of both todays and future automation solutions. Adding mechanisms for secure inter-cloud administration and data tranfere enables local automation cloud to meet IoT automation system requirements as: 1) Interoperability of a wide range of IoT and legacy devices 2) Automation requirement on latency guarantee/prediction for communication and control computations. 3) Scalability of automation systems enabling very large integrated automation systems 4) Security and related safety of automation systems 5) Ease of application engineering 6) Multi stakeholder integration and operations agility. How these requirements can be met in such a local automation cloud is discussed with references to proposed solutions. The local automation cloud concept is further verified for a compartment climate control application. The control application included an IoT controller, four IoT sensors and actuators, and a physical layer communication gateway. The gateway acted as host for local cloud core functionalities. The climate control application has successfully been implemented using the open source Arrowhead Framework and its supports for design and implementation of self contained local automation clouds.}, 
keywords={Internet of Things;cloud computing;internetworking;open systems;public domain software;IoT actuators;IoT automation;IoT controller;IoT sensors;automation cloud concept;cloud computing principles;interoperability;local automation clouds;local clouds;open Internet cloud;open source;physical layer communication gateway;secure inter-cloud administration;IoT;Local automation clouds;SoS}, 
doi={10.1109/WF-IoT.2016.7845474}, 
ISSN={}, 
month={Dec},}
@ARTICLE{4907679, 
author={F. Douglis}, 
journal={IEEE Internet Computing}, 
title={Staring at Clouds}, 
year={2009}, 
volume={13}, 
number={3}, 
pages={4-6}, 
abstract={Cloud computing's premise is to lower computing costs by providing computational resources in a shared infrastructure. This could be a godsend to smaller organizations, but interoperability and security challenges still exist for this emerging technology.}, 
keywords={cost reduction;open systems;security of data;cloud computing;computational resources;cost reduction;interoperability;security;Application software;Cloud computing;Ecosystems;Hardware;Licenses;Monitoring;Open source software;Sun;Videos;Cloud Computing Expo;cloud computing;virtualization}, 
doi={10.1109/MIC.2009.70}, 
ISSN={1089-7801}, 
month={May},}
@INPROCEEDINGS{7781214, 
author={V. H. Nguyen and Y. Besanger and Q. T. Tran}, 
booktitle={2016 IEEE Power Energy Society Innovative Smart Grid Technologies Conference (ISGT)}, 
title={Novel hybrid cloud based SCADA approach for interoperability of micro-grid platforms}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={In the context of smart grid development, this paper considers the problem of interoperability of micro-grid platforms, particularly among research institutions. Various levels of interoperability are introduced with the respective requirements. The primary aim of the paper is to propose a suitable private hybrid cloud based SCADA architecture satisfying various necessities in the framework of interoperability of micro-grid platforms while maintaining security restrictions. Due to the limited time restriction of critical SCADA functions in the electrical grid, only selected non-critical SCADA functions are accessible to partners from the private cloud. The critical SCADA tasks functionality remains under control of local server, thus, a hybrid cloud architecture. The communication model is based on Platform as a Service (PaaS) delivery model of cloud computing.}, 
keywords={SCADA systems;cloud computing;distributed power generation;open systems;power engineering computing;power grids;power system security;PaaS delivery model;cloud computing;electrical grid;hybrid cloud based SCADA architecture;interoperability;microgrid platform;noncritical SCADA function;platform as a service delivery model;security restriction;smart grid development;Cloud computing;Cryptography;Databases;Logic gates;Reliability;Servers;Hybrid Cloud Based SCADA;Interoperability;Platform as a Service;Security Control;Smart Grid}, 
doi={10.1109/ISGT.2016.7781214}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6100930, 
author={P. Balboni and B. Iafelice}, 
booktitle={2011 Technical Symposium at ITU Telecom World (ITU WT)}, 
title={Mobile cloud for enabling the EU eHealth sector Regulatory issues and opportunities}, 
year={2011}, 
volume={}, 
number={}, 
pages={51-56}, 
abstract={Mobile cloud computing technologies can help the growth of the EU eHealth sector by enabling patient data portability, seamless accessibility, lowering related public expenses, and enhancing IT capabilities and performance. This paper will: (a) briefly analyse the main benefits of deploying mobile cloud computing technology to the eHealth sector; (ii) single out the main legal issues related to data security and privacy; (iii) stress the possible contribution that mobile cloud computing services can provide, to achieve EU specific objectives, such as cross-boarder interoperability, better data protection and data security compliance; and (iv) recommend the way forward focusing on the critical success factors: clear workable rules from Europe, privacy sensitive Cloud Service Providers (CSPs), investing in and promoting robust network and mobile broadband to move data.}, 
keywords={broadband networks;cloud computing;data privacy;medical administrative data processing;mobile computing;open systems;EU e-health sector;European Union;IT capability;IT performance;critical success factor;cross-boarder interoperability;data privacy;data protection;data security;information technology;mobile broadband;mobile cloud computing technology;patient data portability;privacy sensitive cloud service provider;Cloud computing;Data security;Law;Medical services;Mobile communication;Process control;Mobile cloud computing;compliance;data protection;data security;eHealth;interoperability;legal issues;telemedicine},
doi={}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6185480, 
author={}, 
booktitle={2012 26th International Conference on Advanced Information Networking and Applications Workshops}, 
title={2012 26th International Conference on Advanced Information Networking and Applications Workshops [Cover art]}, 
year={2012}, 
volume={}, 
number={}, 
pages={C1-C1}, 
abstract={The following topics are dealt with: advanced Information networking; information system; network application; heterogeneous wireless network; wireless network performance analysis; security; multimodality; pervasive environment; data management; wireless communication; pervasive communication; mining; World Wide Web; telecommunication networking; biocomputing; intelligent computing; information technology; innovative service; disaster; emergency information network system; cloud computing; cloud service; interoperability; protocols; multihoming support; complex information flow; bioinformatics; life science modelling; life science computing; interclouds; collective intelligence; object-oriented intelligent Web information technology; and networked virtual enterprise.}, 
keywords={bioinformatics;cloud computing;data mining;disasters;emergency services;knowledge based systems;object-oriented methods;open systems;protocols;radio networks;telecommunication security;ubiquitous computing;virtual enterprises;World Wide Web;biocomputing;bioinformatics;cloud computing;cloud service;collective intelligence;complex information flow;data management;disaster;emergency information network system;heterogeneous wireless network;innovative service;intelligent computing;interclouds;interoperability;life science computing;life science modelling;mining;multihoming support;multimodality;network application;networked virtual enterprise;object-oriented intelligent Web information technology;pervasive communication;pervasive environment;protocol;security;telecommunication networking;wireless communication;wireless network performance analysis}, 
doi={10.1109/WAINA.2012.291}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{7919518, 
author={T. J. Kalidoss and S. Ravi}, 
booktitle={2016 IEEE International Conference on Computational Intelligence and Computing Research (ICCIC)}, 
title={Disaster management system leveraging the emerging digital technologies}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-7}, 
abstract={This conceptual paper aims to bring the fusion of emerging technologies and available data in order to gain insights and use them efficiently at the time of natural crisis. The global displacement scale due to disasters between 2008 and 2014 stands at an alarming rate of over 25 million lives on an average. Chennai floods 2015 has been the trigger for us to visualize the disaster management issue in various dimensions and come up with an approach by leveraging emerging technologies which has the potential to disseminate alerts seamlessly. The objective is to put forth some ideas on utilizing the existing information databases and signals from prevailing alert systems and integrate it using emerging technologies by leveraging the power of digital forces such as Mobility, Social media and Analytics. The proposed conceptual architecture could get data of various types and alerts in real time, process data streams and group them based on metadata and alert appropriate stakeholders. This proposed conceptual system based on the secondary research highlights how the benefits could be taken to various stakeholders such as government authorities, volunteers, media, residents of the disaster prone area and local authorities in those areas. The digital forces such as mobility, cloud computing, analytics and social media are fast emerging and the computing resources are available at a much lower costs almost like a commodity. This paper also leaves room for futuristic research in the IT technologies and their interoperability, performing analytics on the available inputs at the time of crisis and maximize the benefit to society and also emphasizes on smart integrated communication using cutting edge IT technologies.}, 
keywords={data visualisation;emergency management;meta data;open systems;sensor fusion;IT technologies;alert systems;alerts dissemination;cloud computing;data fusion;data stream processing;digital technologies;disaster management issue visualization;disaster management system;global displacement scale;information databases;interoperability;metadata;mobility;smart integrated communication;social media;Disaster management;Internet of Things;digital technologies;smart communication;urban planning}, 
doi={10.1109/ICCIC.2016.7919518}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6743310, 
author={D. Juan}, 
booktitle={2013 2nd International Symposium on Instrumentation and Measurement, Sensor Network and Automation (IMSNA)}, 
title={The research to open BIM-based building information interoperability framework}, 
year={2013}, 
volume={}, 
number={}, 
pages={440-443}, 
abstract={In the development process of the Architecture Engineering Construction (AEC) industry, as the lack of unified standard and integration mechanism to interoperability, the information exchange and sharing between different building application systems in the different phases of the building life are difficult. The emergence of Open BIM effectively improves the interoperability of building information. Based on cloud computing and open Web environment, dependent on the mainstream BIM standard-IFC and IDM, the paper puts forward the innovative cloud-based building information interaction framework. Besides, the paper analyzes the interactive process to the implementation of building information and also brings out the key technology to the realization of the framework1.}, 
keywords={buildings (structures);cloud computing;construction industry;interactive systems;open systems;structural engineering computing;AEC industry;IDM BIM standard;IFC BIM standard;architecture engineering construction industry;building application systems;building information;building life phases;cloud computing;cloud-based building information interaction framework;information exchange;information sharing;interactive process;open BIM-based building information interoperability framework;open Web environment;Buildings;Business;Cloud computing;Data models;Interoperability;Standards;IDM;IFC;Interoperability;Open BIM}, 
doi={10.1109/IMSNA.2013.6743310}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{7995354, 
author={C. E. Poenaru and D. Merezeanu and R. Dobrescu and E. Posdarascu}, 
booktitle={2017 E-Health and Bioengineering Conference (EHB)}, 
title={Communication issues in e-Health context}, 
year={2017}, 
volume={}, 
number={}, 
pages={33-36}, 
abstract={The paper proposes a modern solution to sustain data communication in an e-Health framework and also the design principles for an e-Health Interoperability Platform for Health Information Systems support. Additionally, the paper presents a mediating service mechanism used to map and convert the context-specific data exchanged between the different parties that are communicating and a dedicated interface mechanism which enables the access of the platform in a cloud computing applications.}, 
keywords={cloud computing;medical information systems;open systems;Health Information Systems support;cloud computing;communication issues;context-specific data;data communication;e-Health Interoperability Platform;Cloud computing;Databases;Information and communication technology;Information systems;Interoperability;Medical services;Telemedicine;Healthcare Information Systems;cross-context;e-Health;interoperability platform;mediating service mechanism}, 
doi={10.1109/EHB.2017.7995354}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{5974229, 
author={L. A. Bastião Silva and C. Costa and A. Silva and J. L. Oliveira}, 
booktitle={6th Iberian Conference on Information Systems and Technologies (CISTI 2011)}, 
title={A PACS Gateway to the Cloud}, 
year={2011}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={The amount of medical images has increased significantly over the last decade as result of the increase of number and quality of studies. Following some researchers, this trend will continue over the next years. Cloud computing is a new concept based on a well-know model named “pay-as-you-go”. There is a new concept dubbed PACS Cloud, which the fundamental idea is to do PACS outsourcing taking advantages of the clouds elasticity and scalability, avoiding hardware obsolescence, providing universal access to the information anywhere, anytime and increase the data availability. This paper presents a module of PACS Cloud architecture to grant interoperability with DICOM devices. PACS Cloud Gateway is a component of PACS Cloud, which focuses mainly on the translation from DICOM commands to non-DICOM and vice-versa. While data outsource to the cloud can relieve users from the burden of local storage and maintenance, it also brings new security concerns. This paper presents a secure PACS Cloud Gateway to access PACS Cloud archive, which provides a high security level and without cloud's provider dependence. The workflows of each process was described carefully, specifying data flows since that Gateway is contacted by DICOM device, until it releases the process. Finally, the platform was instantiated in biggest Internet Cloud providers and the solution's results was analysed.}, 
keywords={biomedical imaging;cloud computing;medical computing;DICOM device;Internet cloud provider;PACS cloud archive;PACS cloud concept;PACS gateway;PACS outsourcing;digital imaging and communications in medicine;medical image;pay-as-you-go model;picture archive and communications system;Cloud computing;DICOM;Indexes;Logic gates;Picture archiving and communication systems;Cloud Computing;DICOM;Medical Imaging;PACS;Telemedicine}, 
doi={}, 
ISSN={2166-0727}, 
month={June},}
@INPROCEEDINGS{5708445, 
author={N. Loutas and V. Peristeras and T. Bouras and E. Kamateri and D. Zeginis and K. Tarabanis}, 
booktitle={2010 IEEE Second International Conference on Cloud Computing Technology and Science}, 
title={Towards a Reference Architecture for Semantically Interoperable Clouds}, 
year={2010}, 
volume={}, 
number={}, 
pages={143-150}, 
abstract={This paper focuses on the emerging problem of semantic interoperability between heterogeneous cooperating Cloud platforms. We try to pave the way towards a Reference Architecture for Semantically Interoperable Clouds (RASIC). To this end, three fundamental and complementary computing paradigms, namely Cloud computing, Service Oriented Architectures (SOA) and lightweight semantics are used as the main building blocks. The open, generic Reference Architecture for Semantically Interoperable Clouds introduces a scalable, reusable and transferable approach for facilitating the design, deployment and execution of resource intensive SOA services on top of semantically interlinked Clouds. In order to support the development of semantically interoperable Cloud systems based on RASIC, the model of a common Cloud API is also specified.}, 
keywords={application program interfaces;cloud computing;open systems;service-oriented architecture;RASIC;common cloud API;reference architecture;semantically interoperable clouds;service oriented architectures;Cloud computing;Computer architecture;Semantics;Service oriented architecture;Standards;Sun;Virtual machining;Cloud computing;SOA;common Cloud API;reference architecture;semantic interoperability}, 
doi={10.1109/CloudCom.2010.38}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{6427607, 
author={Y. Demchenko and M. X. Makkes and R. Strijkers and C. de Laat}, 
booktitle={4th IEEE International Conference on Cloud Computing Technology and Science Proceedings}, 
title={Intercloud Architecture for interoperability and integration}, 
year={2012}, 
volume={}, 
number={}, 
pages={666-674}, 
abstract={This paper presents on-going research to develop the Intercloud Architecture Framework (ICAF) that addresses problems in multi-provider multi-domain heterogeneous cloud based infrastructure services and applications integration and interoperability. The paper refers to existing standards in Cloud Computing, in particular, recently published NIST Cloud Computing Reference Architecture (CCRA). The proposed ICAF defines four complementary components addressing Intercloud integration and interoperability: multilayer Cloud Services Model that combines commonly adopted cloud service models, such as IaaS, PaaS, SaaS, in one multilayer model with corresponding inter-layer interfaces; Intercloud Control and Management Plane that supports cloud based applications interaction; Intercloud Federation Framework, and Intercloud Operation Framework. The paper briefly describes the architectural framework for cloud based infrastructure services provisioned on-demand being developed in the framework of the GEYSERS project that is used as a basis for building multilayer cloud services integration framework that allows optimized provisioning of both computing, storage and networking resources. The proposed architecture is intended to provide an architectural model for developing Intercloud middleware and in this way will facilitate clouds interoperability and integration.}, 
keywords={cloud computing;middleware;open systems;resource allocation;software architecture;CCRA;GEYSERS project;ICAF;IaaS;NIST;PaaS;SaaS;cloud computing reference architecture;cloud-based applications interaction;computing resource provisioning;infrastructure services;inter-layer interfaces;intercloud architecture framework;intercloud control and management plane;intercloud federation framework;intercloud integration;intercloud interoperability;intercloud middleware development;intercloud operation framework;multilayer cloud services model;multiprovider multidomain heterogeneous cloud;networking resource provisioning;storage resource provisioning;Cloud computing;Computational modeling;Computer architecture;Conferences;Interoperability;NIST;Architectural framework for Cloud infrastructure services provisioned on-demand;Cloud Computing Reference Architecture;In tercloud Federations Framework;Intercloud Architecture;Intercloud Control and Management Plane;Intercloud Operation Framework;Multi-layer Cloud Services Model}, 
doi={10.1109/CloudCom.2012.6427607}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6747567, 
author={J. Zhang and C. Gu and X. Wang and H. Huang}, 
booktitle={2013 IEEE Third International Conference on Information Science and Technology (ICIST)}, 
title={A unified MetaScheduler architecture for telecom grade cloud computing}, 
year={2013}, 
volume={}, 
number={}, 
pages={354-360}, 
abstract={In cloud computing, Some Cloud Service Providers (CSPs) have their own cloud infrastructure which is centralized or geographically distributed, small or large-scale. Others act as Brokers (CSBs) who integrate and launch services based on multiple CSPs' infrastructures. How to meet the complex requirements for different scenarios while provide high quality, especially telecom grade cloud services in terms of most appropriate resource utilization, high service level assurance, operation, administration, maintenance, and security, even interoperability amongst different clouds is becoming more and more concerned. In this paper, a unified MetaScheduler architecture is proposed to address the aforementioned challenges. The functions of the components are defined and workflows for different networking scenarios are described. The detailed analysis shows that the architecture can support different scenario cloud system implementation and realize telecom grade services.}, 
keywords={Cloud computing;Computer architecture;Interoperability;Protocols;Quality of service;Resource management}, 
doi={10.1109/ICIST.2013.6747567}, 
ISSN={2164-4357}, 
month={March},}
@INPROCEEDINGS{7027546, 
author={H. Sequeira and P. Carreira and T. Goldschmidt and P. Vorst}, 
booktitle={2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing}, 
title={Energy Cloud: Real-Time Cloud-Native Energy Management System to Monitor and Analyze Energy Consumption in Multiple Industrial Sites}, 
year={2014}, 
volume={}, 
number={}, 
pages={529-534}, 
abstract={Industrial organizations use Energy Management Systems (EMS) to monitor, control, and optimize their energy consumption. Industrial EMS are complex and expensive systems due to the unique requirements of performance, reliability, and interoperability. Moreover, industry is facing challenges with current EMS implementations such as cross-site monitoring of energy consumption and CO2 emissions, integration between energy and production data, and meaningful energy efficiency benchmarking. Additionally, big data has emerged because of recent advances in field instrumentation that led to the generation of large quantities of machine data, with much more detail and higher sampling rates. This created a challenge for real-time analytics. In order to address all these needs and challenges, we propose a cloud-native industrial EMS solution with cloud computing capabilities. Through this innovative approach we expect to generate useful knowledge in a shorter time period, enabling organizations to react quicker to changes of events and detect hidden patterns that compromise efficiency.}, 
keywords={Big Data;cloud computing;energy consumption;energy management systems;open systems;organisational aspects;reliability;Big Data;EMS;cloud computing;energy cloud;energy consumption;industrial organizations;interoperability;multiple industrial sites;real-time cloud-native energy management system;reliability;Cloud computing;Energy consumption;Energy management;Industries;Monitoring;Production;Real-time systems;Energy efficiency;big data;cloud computing;energy management systems}, 
doi={10.1109/UCC.2014.79}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{7395924, 
author={S. Guan and R. E. De Grande and A. Boukerche}, 
booktitle={2015 IEEE/ACM 19th International Symposium on Distributed Simulation and Real Time Applications (DS-RT)}, 
title={Enabling HLA-based Simulations on the Cloud}, 
year={2015}, 
volume={}, 
number={}, 
pages={112-119}, 
abstract={The HLA framework is widely used to formalize simulations and achieve reusability and interoperability of simulation components. In order to manage the underlying system of HLA-based simulations, Grid Computing and Cloud Computing are employed to tackle the details of operation, configuration, and maintenance of simulation platforms that simulation applications run on. However, to make a simulation-run-ready environment among different types of computing resources and network environments is challenging, especially for modelers who may not be familiar with the management of distributed systems. In this article, we propose a new cloud-based scheme for HLA based simulations, aiming to ease the management of underlying resources, particularly for those located on geographically distributed locations, and to achieve rapid elasticity that can provide adequate computing capability to end users. An approach for handling diverse network environments is given, by adopting it, idle public resources can be easily configured as additional computing resources for the local cloud infrastructure. In the experiments, compared with its corresponding Grid Computing platform, this Cloud Computing platform achieves a similar performance but with many advantages that Cloud can provide, such as energy consumption, security, and multi-user availability.}, 
keywords={cloud computing;digital simulation;grid computing;open systems;resource allocation;software reusability;HLA-based simulations;cloud computing platform;distributed system management;grid computing;local cloud infrastructure;resource management;simulation component interoperability;simulation component reusability;Analytical models;Cloud computing;Computational modeling;Data models;Portals;Security;Virtualization;Availability;Cloud Computing;Distributed Simulations;HLA;Usability}, 
doi={10.1109/DS-RT.2015.36}, 
ISSN={1550-6525}, 
month={Oct},}
@ARTICLE{6845043, 
author={T. Taleb and A. Ksentini and A. Reznik and T. Metsch}, 
journal={IEEE Wireless Communications}, 
title={Research and standards: Leading the evolution of telecom network architectures}, 
year={2014}, 
volume={21}, 
number={3}, 
pages={10-11}, 
abstract={The emergence of new communication paradigms, such as cloud computing, the Internet of Things, the mobile traffic explosion, and the expectation of ubiquitous connectivity, is driving what is perhaps the most significant transformation of the architecture of mobile and wireless network systems yet. Simply put, telecom network architectures need to evolve to support an exponentially more complex and diverse set of applications. Not surprisingly, this challenge has been attracting ever increasing attention from researchers in both academia and industry, including telecom standards experts. As enablers of global systems interoperability, standards are at the heart of success of the communications industry. Since standardization is inherently a social enterprise, it is the perfect environment for promoting technologies that underpin an increasingly social world. Moreover, telecommunications-oriented standards development organizations such as the IEEE, Internet Engineering Task Force (IETF), Third Generation Partnership Project (3GPP), and others have a decades-long track record as drivers of real technological change across the industry.}, 
keywords={EPON;Long Term Evolution;Mobile communication;Special issues and sections;Telecommunication standards}, 
doi={10.1109/MWC.2014.6845043}, 
ISSN={1536-1284}, 
month={June},}
@ARTICLE{7990538, 
author={F. Tao and Q. Qi}, 
journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems}, 
title={New IT Driven Service-Oriented Smart Manufacturing: Framework and Characteristics}, 
year={2017}, 
volume={PP}, 
number={99}, 
pages={1-11}, 
abstract={Recently, along with the wide application of new generation information technologies (New IT) in manufacturing, many countries issued their national advanced manufacturing development strategies, such as Industrial Internet, Industry 4.0, and Made in China 2025. One common aim of these strategies is to achieve smart manufacturing, which demands the interoperation, integration, and fusion of the physical world and the cyber world of manufacturing. As well, New IT [such as Internet of Things (IoT), cloud computing, big data, mobile Internet, and cyber-physical systems (CPS)] have played pivotal roles in promoting smart manufacturing. Data generated in the physical world can be sensed and transfered to the cyber world through IoT and the Internet, and be processed and analyzed by cloud computing, big data technologies to adjust the physical world. The physical world and the cyber world of manufacturing are integrated based on CPS. On the other hand, servitization has become a prominent trend in the manufacturing. Embracing the concept of 'Manufacturing-as-a-Service,' manufacturing is provided as service for users. Because of the characteristics of interoperability and platform independence, services pave the way for large-scale smart applications and manufacturing collaboration. Combining New IT and services, this paper proposes a framework--New IT driven service-oriented smart manufacturing (SoSM). SoSM aims at facilitating the visions of smart manufacturing by making full use of New IT and services. Complementary to the framework of SoSM, the New IT driven typical characteristics of SoSM are also investigated and discussed, respectively.}, 
keywords={Big Data;Cloud computing;Collaboration;Industries;Manufacturing;Production;Big data;Internet of Things (IoT);cloud computing;cyber-physical integration;manufacturing service;smart manufacturing.}, 
doi={10.1109/TSMC.2017.2723764}, 
ISSN={2168-2216}, 
month={},}
@INPROCEEDINGS{5966607, 
author={S. Dowell and A. Barreto and J. B. Michael and M. T. Shing}, 
booktitle={2011 6th International Conference on System of Systems Engineering}, 
title={Cloud to cloud interoperability}, 
year={2011}, 
volume={}, 
number={}, 
pages={258-263}, 
abstract={Cloud computing describes a new distributed computing paradigm that allows system of systems to access a shared pool of configurable computing resources (e.g., networks, servers, storage, data, applications, and services) that can be rapidly provisioned and released over the Internet with minimal user-management effort or cloud-provider interaction. Interoperability is central to enabling sharing of resources from a pool of cloud-service providers in a seamless fashion. In this paper we describe some of the challenges in achieving interoperability for cloud computing and recommend an adaptation of the U.S. Department of Defense's LISI Maturity Model to address cloud-to-cloud interoperability.}, 
keywords={cloud computing;distributed processing;information systems;military computing;open systems;Internet;LISI maturity model;U.S. Department of Defense;cloud computing;cloud-provider interaction;cloud-to-cloud interoperability;configurable computing resources;distributed computing paradigm;levels of information system interoperability;minimal user-management effort;resource sharing;Cloud computing;Computational modeling;Computer architecture;Privacy;Protocols;Security;Standards;Cloud computing;LISI;interoperability}, 
doi={10.1109/SYSOSE.2011.5966607}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{7092962, 
author={A. Willner and R. Loughnane and T. Magedanz}, 
booktitle={2015 IEEE International Conference on Cloud Engineering}, 
title={FIDDLE: Federated Infrastructure Discovery and Description Language}, 
year={2015}, 
volume={}, 
number={}, 
pages={465-471}, 
abstract={Considerable efforts have been spent on designing architectures to manage heterogeneous resources across multiple administrative domains. Specific fields of application are federated cloud computing (Intercloud) approaches and distributed testbeds, among others. An important interoperability challenge that arises in this context is the exchange of information about the provided resources and their dependencies. Existing work usually rests upon schematic data models, which impede the discovery and management of heterogeneous resources between autonomous sites. One way of addressing this issue is to exchange semantic information models. In this paper, we exploit such approaches to formally define federations, including their infrastructures and the life-cycle of the offered resources and services. The requirements of this work have been derived from several research projects and the results are in process of being standardized by an international body. The main contribution of this work is a higher level (upper) ontology and initial integration concepts for it. These contributions form a basis for further work in the general context of distributed semantic resource management.}, 
keywords={cloud computing;data models;electronic data interchange;ontologies (artificial intelligence);open systems;resource allocation;FIDDLE;distributed semantic resource management;distributed testbeds;federated cloud computing;federated infrastructure discovery and description language;heterogeneous resource discovery;heterogeneous resource management;higher level ontology;initial integration concept;intercloud approach;international body;interoperability challenge;schematic data models;semantic information model exchange;Context;Data models;Interoperability;Ontologies;Resource description framework;Semantics;Unified modeling language;Infrastructure Federation;Intercloud;IoT;NFV;SDN;Semantic Web;Testbeds;e-infrastructures}, 
doi={10.1109/IC2E.2015.77}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{7840955, 
author={H. Ferguson and C. Vardeman and J. Nabrzyski}, 
booktitle={2016 IEEE International Conference on Big Data (Big Data)}, 
title={Linked data platform for building cloud-based smart applications and connecting API access points with data discovery techniques}, 
year={2016}, 
volume={}, 
number={}, 
pages={3016-3025}, 
abstract={Globalization and cloud computing have allowed major strides forward in terms of communication possibilities, but it is also illuminating how many different resource options and formats exist access to which would dramatically increase the accuracy and reliability of choices made as a result of computational output. As a result, there is increasing need for methods resolving levels of data translations necessary for the effectiveness of distributed Linked Data platforms, especially in the context of the Building Information Modeling domain in which we conduct our work. The following research presents the current state of our Linked Data Platform for handling and processing Resilience and BIM data from existing and remotely located data stores and simulation models. This approach focuses on data interoperability and illustrates the functional interactions of a set of lightweight API endpoints that serve resources as requests are extensible with the HYDRA Core Vocabulary to increase data discoverability opportunities.}, 
keywords={Linked Data;application program interfaces;cloud computing;open systems;API access points;BIM data;HYDRA core vocabulary;building information modeling domain;cloud computing;cloud-based smart applications;data discoverability opportunities;data interoperability;distributed Linked Data platforms;Buildings;Data models;Distributed databases;Interoperability;Resource description framework;Vocabulary;Big Data;Building Information Modeling;Data Modeling;HYDRA Core Vocabulary;Interoperability;Linked Data;Linked Data Platform;Linked Data Views;Ontology Alignment;REST APIs;Resilience Frameworks;Semantic Web}, 
doi={10.1109/BigData.2016.7840955}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{7882979, 
author={S. S. Chauhan and E. S. Pilli and R. C. Joshi}, 
booktitle={2016 International Conference on Emerging Trends in Communication Technologies (ETCT)}, 
title={A broker based framework for federated Cloud environment}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={Every industry is adopting Cloud Computing platform due to its low cost services and zero overheads of maintenance and upgrades. Several new issues are generated because of this wide adoption which are concern to both cloud service provider and cloud service users. Cloud service providers are facing the issue of resource limitations. Cloud service users are facing the issue of vendor lock-in. Federated Cloud through brokering can be used to solve the above mentioned issues. Cloud Federation is the place where cloud service providers can gather to share their resources and the cloud service consumers can buy those resources. The federation is either handled by one of the cloud service provider or a third party known as cloud service broker. The broker is solely responsible for providing services to the cloud consumers which are leased by cloud service providers. In this paper, we are proposing a framework for federated cloud based on the broker.}, 
keywords={business data processing;cloud computing;information industry;broker;cloud computing;cloud service provider;cloud service users;federated cloud;resource management;vendor lock-in issue;Cloud computing;Clouds;Computer architecture;Interoperability;Quality of service;Resource management;Standards;Broker;Cloud Computing;Federated Cloud;Resource Management}, 
doi={10.1109/ETCT.2016.7882979}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{6740239, 
author={N. Ferry and A. Rossini and F. Chauvel and B. Morin and A. Solberg}, 
booktitle={2013 IEEE Sixth International Conference on Cloud Computing}, 
title={Towards Model-Driven Provisioning, Deployment, Monitoring, and Adaptation of Multi-cloud Systems}, 
year={2013}, 
volume={}, 
number={}, 
pages={887-894}, 
abstract={In the landscape of cloud computing, the competition between providers has led to an ever growing number of cloud solutions offered to consumers. The ability to run and manage multi-cloud systems (i.e., applications on multiple clouds) allows exploiting the peculiarities of each cloud solution and hence optimising the performance, availability, and cost of the applications. However, these cloud solutions are typically heterogeneous and the provided features are often incompatible. This diversity hinders the proper exploitation of the full potential of cloud computing, since it prevents interoperability and promotes vendor lock-in, as well as it increases the complexity of development and administration of multi-cloud systems. This problem needs to be addressed promptly. In this paper, we provide a classification of the state-of-the-art of cloud solutions, and argue for the need for model-driven engineering techniques and methods facilitating the specification of provisioning, deployment, monitoring, and adaptation concerns of multi-cloud systems at design-time and their enactment at run-time.}, 
keywords={cloud computing;formal specification;open systems;cloud computing;cloud solutions;interoperability;model-driven adaptation;model-driven deployment;model-driven engineering techniques;model-driven monitoring;model-driven provisioning;multicloud systems;vendor lock-in;Adaptation models;Cloud computing;Interoperability;Java;Libraries;Licenses;Monitoring;CloudML;adaptation;cloud computing;deployment;domain-specific modelling language;model-driven engineering;models@run-time;monitoring;multi-cloud;provisioning}, 
doi={10.1109/CLOUD.2013.133}, 
ISSN={2159-6182}, 
month={June},}
@ARTICLE{6924633, 
author={R. Ranjan}, 
journal={IEEE Cloud Computing}, 
title={The Cloud Interoperability Challenge}, 
year={2014}, 
volume={1}, 
number={2}, 
pages={20-24}, 
abstract={Many efforts to develop open cloud standards, which could enable interoperability among clouds, are underway. However, the critical challenge here is to develop standardization solutions for a number of technical issues. Ultimately, coordinating the many standardization efforts will pose a hard challenge for future. The paper provides research issues and directions related to cloud interoperability. In the cloud computing landscape, “cloud interoperability” typically refers to the ability to seamlessly deploy, migrate, and manage application workloads across heterogeneous hardware and software resources provided by multiple datacenter cloud providers (such as Amazon and GoGrid).}, 
keywords={cloud computing;open systems;standardisation;Amazon;GoGrid;application workloads;cloud computing landscape;cloud interoperability challenge;datacenter cloud providers;heterogeneous hardware resource;heterogeneous software resource;open cloud standards;standardization solutions;Authentication;Cloud computing;Interoperability;Open systems;Quality of service;Virtualization;cloud;interoperability;standards;virtualization}, 
doi={10.1109/MCC.2014.41}, 
ISSN={2325-6095}, 
month={July},}
@INPROCEEDINGS{6396030, 
author={R. Rajagopal and M. Chitra}, 
booktitle={Computing Communication Networking Technologies (ICCCNT), 2012 Third International Conference on}, 
title={Trust based interoperability security protocol for grid and Cloud computing}, 
year={2012}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={Grid and cloud computing is a kind of important information technology which enables resource sharing globally to solve the large scale problem. Security plays very important role in any internet system, specifically in Grid and Cloud computing system. Since all the resources are shared in grid computing system, trust relationship is very crucial. Different domains have different policies in rendering their resources. Cloud Security combines parallel processing, grid computing, the judgment of unknown viruses and other emerging technologies and concepts, through the mass of the network client, detects status of all abnormal behavior and obtains the latest information of Trojans, viruses and other undesirable programs, sends information to the server for automatic analysis and processing, distributes solutions to each client to solve insecurity. This paper proposes an interoperability security protocol for both grid and cloud computing. There is no need for separate security protocol for grid and cloud computing environments.}, 
keywords={cloud computing;grid computing;invasive software;open systems;parallel processing;protocols;trusted computing;Internet system;abnormal behavior;automatic analysis;cloud computing;grid computing;large scale problem;network client;parallel processing;resource sharing;trust based interoperability security protocol;trust relationship;Communities;Computers;Cryptography;Fabrics;Protocols;Tunneling;Cloud Security;Grid Security;Network Security Protocols;Trust Factor}, 
doi={10.1109/ICCCNT.2012.6396030}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{6354365, 
author={S. Labes and J. Repschläger and R. Zarnekow and A. Stanik and O. Kao}, 
booktitle={2012 Federated Conference on Computer Science and Information Systems (FedCSIS)}, 
title={Standardization approaches within Cloud Computing: Evaluation of infrastructure as a service architecture}, 
year={2012}, 
volume={}, 
number={}, 
pages={923-930}, 
abstract={Cloud Computing is becoming increasingly established and offers several opportunities to obtain IT services in an on-demand manner. Especially infrastructure services, like storage and scalable computing resources, are gaining relevance and provide alternatives to conventional sourcing models. Despite the Cloud paradigm of flexible and limitless scalability the lack of standardization presents a big challenge in this context. Due to many providers, which are using different Cloud software including proprietary interfaces, the interoperability in the Cloud remains a theoretical construct. In this paper we examine standardization approaches within Cloud Computing and provide a comparison to practical implementations of interfaces of relevant Cloud software on the market. Finally, characteristics for a potential Cloud standard on the infrastructure level will be postulated.}, 
keywords={cloud computing;open systems;software architecture;IT services;cloud computing;cloud software;infrastructure-as-a-service architecture evaluation;interoperability;proprietary interfaces;standardization approaches;Cloud computing;Companies;Standards organizations}, 
doi={}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6132792, 
author={N. Bessis and S. Sotiriadis and V. Cristea and F. Pop}, 
booktitle={2011 Third International Conference on Intelligent Networking and Collaborative Systems}, 
title={Modelling Requirements for Enabling Meta-scheduling in Inter-Clouds and Inter-Enterprises}, 
year={2011}, 
volume={}, 
number={}, 
pages={149-156}, 
abstract={Cloud computing provides a promising paradigm for the deployment and utilization of online resources including hardware and software services by Internet users. In such an e-infrastructure environment, the scheduling of user-defined tasks is always considered as a complicated part of the overall system modelling. Specifically, in the case of inter-clouds and inter-enterprises scheduling optimization is fundamentally important for achieving the best possible capacity in terms of resource utilization. Thus, existing approaches that consider system dynamics, interoperability and heterogeneity issues become important aspects for providing advanced scheduling decisions. In this work, we survey some highly dynamic meta-schedulers that are suitable for enterprises using grids and/or clouds. Our intention is to elicit the characteristics and produce a model encompassing the architectural requirements that will enable high meta-scheduling performance in inter-cooperative e-infrastructures.}, 
keywords={business data processing;cloud computing;grid computing;open systems;Internet users;cloud computing;grids;heterogeneity issues;interclouds scheduling optimization;intercooperative e-infrastructures environment;interenterprises scheduling optimization;interoperability;meta-scheduling;online resources;requirements modelling;resource utilization;system dynamics;Algorithm design and analysis;Cloud computing;Dynamic scheduling;Heuristic algorithms;Scheduling algorithm;Cloud;Community Aware Scheduling;Federated Clouds;Inter-clouds;Inter-enterprises;Meta-schedulers}, 
doi={10.1109/INCoS.2011.120}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{6133153, 
author={J. Ejarque and J. Alvarez and R. Sirvent and R. M. Badia}, 
booktitle={2011 IEEE Third International Conference on Cloud Computing Technology and Science}, 
title={A Rule-based Approach for Infrastructure Providers' Interoperability}, 
year={2011}, 
volume={}, 
number={}, 
pages={272-279}, 
abstract={Cloud Computing is a new computing paradigm where a large amount of computing capacity is offered on demand and only paying for what you use. Several Infrastructure Providers have adopted this approach offering resources which are easily managed by means of web-based APIs. However, if a user wants to use different providers, the resource management becomes tedious because providers define different API requiring a special implementation for interacting with each of them. In this paper, we present a methodology for making the provider interoperability easier. In this methodology, each provider's API is modeled by an ontology. Equivalences between these ontologies are modeled by rules, and messages used in a provider's API are converted in calls to another provider's API applying these rules. With our approach, users interact with Infrastructure Providers using their most familiar API and the translation to the other APIs is automatically done by the system.}, 
keywords={application program interfaces;cloud computing;ontologies (artificial intelligence);open systems;Web-based API;cloud computing;computing paradigm;infrastructure provider interoperability;ontologies;resource management;rule-based approach;Cloud computing;Data models;Ontologies;Protocols;Resource description framework;Semantics;Servers;Cloud computing;IaaS;Interoperability;rules;semantics}, 
doi={10.1109/CloudCom.2011.44}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{7449238, 
author={S. Zahara and I. Pratomo and D. S. Rahardjo}, 
booktitle={2015 1st International Conference on Wireless and Telematics (ICWT)}, 
title={Application and data level interoperability on virtual machine in cloud computing environment}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={The rapid development of internet nowadays impact on increasing many applications that utilizing cloud computing technology for the sake of organization. Increasing requirements in applications caused by inevitable business process growth in organization enabling a tendency to switch from old cloud provider to more reliable one. However, in practice, application functionality failures often occur in case of migrating process to new cloud system due to several circumstances e.g. vendor lock-in problem. This paper introduces a new method for system migration testing between two cloud providers. The goal is to determine the interoperability level of application and data in virtual machine within hypervisor system that moves from one cloud provider to another cloud provider. The contribution of this paper is to provide a reference test method for measuring the interoperability between the two cloud systems were migrated.}, 
keywords={cloud computing;open systems;virtual machines;Internet reliability;application functionality failure;cloud computing environment;data level interoperability measurement;hypervisor system;organization inevitable business process growth;reference test method;system migration testing;virtual machine;Cloud computing;Interoperability;Operating systems;Testing;Virtual machine monitors;Virtual machining;cloud migration;interoperability;virtual machine}, 
doi={10.1109/ICWT.2015.7449238}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{6133235, 
author={}, 
booktitle={2011 IEEE Third International Conference on Cloud Computing Technology and Science}, 
title={[Title page i]}, 
year={2011}, 
volume={}, 
number={}, 
pages={i-i}, 
abstract={The following topics are dealt with: eScience; MapReduce; virtualization; security; privacy; standardization; services; application; architecture; public-private research fusion; innovation; HPCCLOUD; NETCCLOUD; cloud interoperability; portability research; IaaS; PaaS and cloud computing.}, 
keywords={cloud computing;data privacy;innovation management;natural sciences computing;HPCCLOUD;IaaS;MapReduce;NETCCLOUD;PaaS;application;architecture;cloud computing;cloud interoperability;eScience;innovation;portability research;privacy;public-private research fusion;security;services;standardization;virtualization}, 
doi={10.1109/CloudCom.2011.1}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{7987175, 
author={A. Alshammari and S. Alhaidari and A. Alharbi and M. Zohdy}, 
booktitle={2017 IEEE 4th International Conference on Cyber Security and Cloud Computing (CSCloud)}, 
title={Security Threats and Challenges in Cloud Computing}, 
year={2017}, 
volume={}, 
number={}, 
pages={46-51}, 
abstract={Cloud Computing has emerged as a new paradigm of computing that builds on the foundations of Distributed Computing, Grid Computing, and Virtualization. Cloud computing is Internet-accessible business model with flexible resource allocation on demand, and computing on a pay-per-use as utilities. Cloud computing has grown to provide a promising business concept for computing infrastructure, where concerns are beginning to grow about how safe an environment is. Security is one of the major issues in the cloud-computing environment. In this paper we investigate some prime security attacks and possible solutions for clouds: XML Signature Wrapping attacks, Browser Security, and Vendor Lock-in.}, 
keywords={XML;business data processing;cloud computing;digital signatures;online front-ends;resource allocation;Internet-accessible business model;XML signature wrapping attacks;browser security;cloud computing;computing infrastructure;flexible resource allocation;pay-per-use computing;security attacks;security threats;vendor lock-in;Browsers;Cloud computing;Computational modeling;Security;Simple object access protocol;Wrapping;XML;Browser Security;Cloud Computing;Lock in;SOAP message;Security Techniques;Service Oriented Architecture;Web Service Security;XML Signature Wrapping Attacks}, 
doi={10.1109/CSCloud.2017.59}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{6693461, 
author={C. Y. Yang and C. T. Liu}, 
booktitle={2013 International Conference on Social Computing}, 
title={Developing IHE-Based PHR Cloud Systems}, 
year={2013}, 
volume={}, 
number={}, 
pages={1022-1025}, 
abstract={Population aging in the world causes medical expenses to soar. Preventive health care attracts people and government's close attention. Integrated electronic health records (EHRs) and Personal Health Records (PHRs) play a crucial role in providing continuous health care. Although, IHE (Integrating the Healthcare Enterprise) has developed the XDS (Cross Enterprise Document Sharing) integration profile for sharing clinical documents among computer systems in healthcare, the XDS integration profile may not directly support cloud computing environments where repository systems are heterogeneous and virtualized. In this paper, we propose a PHR cloud system architecture based on the cloud computing Service Model defined by the National Institute of Standards and Technology (NIST), and adopt the IHE XDS integration profile for system interoperability. To enhance computation power and system scalability we include Hadoop parallel computing model and implement a NoSQL storage layer in this PHR cloud architecture. Our approach presented here to PHR Systems Cloud architecture could be a paradigm for sharing documents in health care settings and supporting cloud computing as well.}, 
keywords={cloud computing;document handling;health care;medical computing;medical information systems;parallel programming;software architecture;EHR;Hadoop parallel computing;IHE-based PHR cloud systems;NIST;National Institute of Standards and Technology;NoSQL storage layer;PHR cloud architecture;XDS;clinical documents;cloud computing;cross enterprise document sharing;health care enterprise;integrated electronic health records;medical expenses;personal health records;population aging;preventive health care;Cloud computing;Computational modeling;Computer architecture;Databases;Engines;Medical services;NIST;Cloud computing;Electronic Health Record;Personal Health Record;System interoperability}, 
doi={10.1109/SocialCom.2013.164}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{7300864, 
author={B. D. Martino and G. Cretella and A. Esposito}, 
booktitle={2015 3rd International Conference on Future Internet of Things and Cloud}, 
title={Classification and Positioning of Cloud Definitions and Use Case Scenarios for Portability and Interoperability}, 
year={2015}, 
volume={}, 
number={}, 
pages={538-544}, 
abstract={Cloud Computing has rapidly evolved and spread in the past few years, with always new services and functionalities being offered by providers in order to gain larger market sectors. This has caused in many cases a lot of distress and confusion to customers who have been often subjected to the "vendor lock-in" phenomenon, because of interoperability and portability issues often arising among different Cloud providers. In this paper we provide a brief introduction to the basic definitions of Cloud Computing, portability and interoperability and we also describe a set of established use cases. All these notions are mapped to a multi-dimensional space, which is used to classify both definitions and use cases. The focus here is represented by portability and interoperability features.}, 
keywords={cloud computing;electronic data interchange;open systems;cloud computing;cloud definition classification;cloud definition positioning;cloud providers;interoperability;portability;use case scenarios;Computer architecture;Interoperability;NIST;Platform as a service;Software as a service;Cloud Computing;Interoperability;Portability;Use cases}, 
doi={10.1109/FiCloud.2015.119}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{7173479, 
author={L. R. Techio and M. Misaghi}, 
booktitle={Fifth International Conference on the Innovative Computing Technology (INTECH 2015)}, 
title={EMSCLOUD #x2013; an evaluative model of cloud services cloud service management}, 
year={2015}, 
volume={}, 
number={}, 
pages={100-105}, 
abstract={Cloud computing is considered a paradigm both technology and business. Its widespread adoption is an increasingly effective trend. However, the lack of quality metrics and audit of services offered in the cloud slows its use, and it stimulates the increase in focused discussions with the adaptation of existing standards in management services for cloud services offered. This article describes the EMSCloud, that is an Evaluative Model of Cloud Services following interoperability standards, risk management and audit of cloud IT services. Aims to present that is possible to assess the life cycle of services offered in the cloud in the technical dimensions of usability, good practices and economic viability.}, 
keywords={Web services;cloud computing;open systems;risk management;EMSCloud;cloud IT services;cloud computing;cloud service management;economic viability;evaluative model of cloud services;interoperability standards;risk management;usability;Cloud computing;Computational modeling;IEC standards;ISO standards;Security;Usability;cloud computing;evaluation model component;risk management;service assessment}, 
doi={10.1109/INTECH.2015.7173479}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{6377878, 
author={R. Matos and J. Araujo and V. Alves and P. Maciel}, 
booktitle={2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
title={Experimental evaluation of software aging effects in the eucalyptus elastic block storage}, 
year={2012}, 
volume={}, 
number={}, 
pages={1103-1108}, 
abstract={The need for reliability, availability and performance has increased in modern applications, which need to handle rapidly growing demands while providing uninterrupted service. Cloud computing systems fundamentally provide access to large pools of data and computational resources. Eucalyptus is a software framework used to implement private clouds and hybrid-style Infrastructure as a Service. It implements the API Amazon Web Service (AWS), allowing interoperability with other AWS-based services. Elastic block storage is a technology which provides flexible allocation of remote storage volumes to the virtual machines running in a cloud computing environment. This work investigates the software aging effects on the Eucalyptus framework, considering workloads composed of intensive requests for attaching remote storage volumes to virtual machines. The results evidenced problems that may be harmful to system dependability and its performance due to RAM memory exhaustion and subsequent use of swap memory, besides high CPU utilization by the virtual machines and subsequent increase in the response time of applications running on the VMs.}, 
keywords={cloud computing;open systems;random-access storage;resource allocation;API Amazon Web Service;CPU utilization;Eucalyptus elastic block storage;RAM memory exhaustion;cloud computing;hybrid-style IaaS;infrastructure as a service;interoperability;software aging effects;virtual machines;Aging;Cloud computing;Memory management;Monitoring;Random access memory;Virtual machining;Cloud computing;Dependability and performance analysis;Software aging and rejuvenation}, 
doi={10.1109/ICSMC.2012.6377878}, 
ISSN={1062-922X}, 
month={Oct},}
@INPROCEEDINGS{8030656, 
author={S. Challita and F. Paraiso and P. Merle}, 
booktitle={2017 IEEE 10th International Conference on Cloud Computing (CLOUD)}, 
title={Towards Formal-Based Semantic Interoperability in Multi-Clouds: The FCLOUDS Framework}, 
year={2017}, 
volume={}, 
number={}, 
pages={710-713}, 
abstract={Multi-cloud computing has been proposed as a way to reduce vendor lock-in, to improve resiliency during outages and geo-presence, to boost performance and to lower costs. However, semantic differences between cloud providers, as well as their heterogeneous management interfaces, make changing from one provider to another very complex and costly. This is quite challenging for the implementation of multi-cloud systems. In this paper, we aim to take advantage of formal methods to define a precise semantics for multi-clouds. We propose fclouds, a formal-based framework for semantic interoperability in multi-clouds. This framework contains a catalogue of formal models that mathematically describe cloud APIs and reason over them. A precise alignment can be described between their concepts, which promotes semantic interoperability.}, 
keywords={application program interfaces;cloud computing;formal specification;open systems;FCLOUDS framework;cloud APIs;cloud providers;formal methods;formal-based semantic interoperability;heterogeneous management interfaces;multicloud computing;Cloud computing;Computational modeling;Interoperability;Libraries;Programming;Semantics;Virtual machining;Formal Language;Formal Verification;Interoperability;Multi-Clouds}, 
doi={10.1109/CLOUD.2017.98}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{6553936, 
author={M. Schnjakin and D. Korsch and M. Schoenberg and C. Meinel}, 
booktitle={2013 8th International Conference on Computer Science Education}, 
title={Implementation of a secure and reliable storage above the untrusted clouds}, 
year={2013}, 
volume={}, 
number={}, 
pages={347-353}, 
abstract={Cloud Computing as a service-on-demand architecture has grown in importance over the previous few years. One driving force of its growth is the ever increasing amount of data which is supposed to outpace the growth of storage capacity. This way, public cloud storage services enable organizations to manage their data with low operational expenses. However, the benefits of cloud computing come along with challenges and open issues such as security, reliability and the risk to become dependent on a provider for its service. In general, a switch of a storage provider is associated with high costs of adapting new APIs and additional charges for inbound and outbound bandwidth and requests. In this paper, we describe the design, architecture and implementation of Cloud-RAID, a system that improves availability, confidentiality and integrity of data stored in the cloud. To achieve this objective, we encrypt user's data and make use of the RAID-technology principle to manage data distribution across cloud storage providers. Our approach allows users to avoid vendor lock-in, and reduce significantly the cost of switching providers. In general, the data distribution is based on users' expectations regarding providers geographic location, quality of service, providers reputation, and budget preferences. In this paper, we also discuss the security functionality and reveal our observations on the overall performance when encrypting and encoding user's data.}, 
keywords={RAID;application program interfaces;budgeting;cloud computing;cryptography;information storage;quality of service;reliability;storage management;trusted computing;API;RAID-technology principle;budget preferences;cloud computing;cloud-RAID;data availability;data confidentiality;data distribution management;data integrity;inbound bandwidth;outbound bandwidth;provider reputation;public cloud storage services;quality of service;reliable storage implementation;secure storage implementation;security functionality;service-on-demand architecture;storage capacity;storage provider;untrusted clouds;user data encoding;user data encryption;Computers;Connectors;Encoding;Reliability}, 
doi={10.1109/ICCSE.2013.6553936}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{5279590, 
author={E. Elmroth and L. Larsson}, 
booktitle={2009 Eighth International Conference on Grid and Cooperative Computing}, 
title={Interfaces for Placement, Migration, and Monitoring of Virtual Machines in Federated Clouds}, 
year={2009}, 
volume={}, 
number={}, 
pages={253-260}, 
abstract={Current cloud computing infrastructure offerings are lacking in interoperability, which is a hindrance to the advancement and adoption of the cloud computing paradigm. As clouds are made interoperable, federations of clouds may be formed. Such federations are from the point of view of the user not burdened by vendor lock-in, and opens for business possibilities where a market place of cloud computing infrastructure can be formed. Federated clouds require unified management interfaces regarding the virtual machines (VMs) that comprise the services running in the cloud federation. Standardization efforts for the required management interfaces have so far focused on definition of description formats regarding VMs, and the control of already deployed VMs. We propose technology neutral interfaces and architectural additions for handling placement, migration, and monitoring of VMs in federated cloud environments, the latter as an extension of current monitoring architectures used in grid computing. The interfaces presented adhere to the general requirements of scalability, efficiency, and security in addition to specific requirements related to the particular issues of interoperability and business relationships between competing cloud computing infrastructure providers. In addition, they may be used equally well locally and remotely, creating a layer of abstraction that simplifies management of virtualized service components.}, 
keywords={grid computing;open systems;security of data;software architecture;software management;system monitoring;virtual machines;business relationships;cloud computing infrastructure;federated clouds;grid computing;monitoring architectures;security;technology neutral interfaces;virtual machines;virtualized service component management;Cloud computing;Computer architecture;Condition monitoring;Grid computing;Remote monitoring;Scalability;Standardization;Virtual machine monitors;Virtual machining;Voice mail;cloud computing;federated cloud;migration;monitoring}, 
doi={10.1109/GCC.2009.36}, 
ISSN={2160-4908}, 
month={Aug},}
@INPROCEEDINGS{7753437, 
author={S. Ahmadzada and M. A. Zayyad and M. Toycan}, 
booktitle={2016 HONET-ICT}, 
title={Readiness assessment for the use of cloud computing in eHealth systems: A field study of hospitals in the capital of Azerbaijan}, 
year={2016}, 
volume={}, 
number={}, 
pages={141-144}, 
abstract={Cloud computing technology platforms could be used amongst healthcare service providers in order to provide interoperability for electronic medical records of the community. As new and emerging technologies e-health and cloud computing together provide much more efficient medical help making it possible for healthcare organization to cure its patients on distance with maximum efficiency and minimum cost for both patient and hospital. Research is conducted to investigate the readiness of implementing cloud computing together with eHealth systems in hospitals across Baku, capital of Republic of Azerbaijan. Four major attributes for readiness were considered, Core, Technology, Policy and Social. A survey was conducted using quantitative method to obtain information from 10 different hospitals using stratified random sampling method. It was investigated that the core readiness shows a good characteristics, although social and policy readiness appears weak while technology readiness also shows reasonable results.}, 
keywords={cloud computing;electronic health records;health care;medical administrative data processing;open systems;Azerbaijan capital;Baku;cloud computing;eHealth systems;electronic medical records;healthcare service providers;hospital field study;interoperability;readiness assessment;stratified random sampling method;Government;Hospitals;Baku;cloud computing;eHealth;healthcare systems;hospitals;readiness}, 
doi={10.1109/HONET.2016.7753437}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{7569181, 
author={J. V. Chandra and N. Challa and S. K. Pasupuleti}, 
booktitle={2016 IEEE International Conference on Engineering and Technology (ICETECH)}, 
title={Advanced Persistent Threat defense system using self-destructive mechanism for Cloud Security}, 
year={2016}, 
volume={}, 
number={}, 
pages={7-11}, 
abstract={A Number of Dynamics such as on-demand and versatile cloud services, software interoperability standards, high bandwidth dynamic communication technologies, broad network access, virtualization technology, privacy and security measures made cloud computing so popular, where as Security is a key inhibitor to the cloud. In this paper we discussed different risks, threats and attacks. We focused on Advanced Persistent Threat which is stealthy, targeted and data focused, progressive defense system is designed and Implemented along with mathematical analysis concerned with networks and algorithms. A self-destructive and Constructive mechanism is adopted using bilinear mapping and reverse engineering methods. Prime issues for cloud securities such as Confidentiality and Authentication are discussed. A Practical and Computational Approach is designed and implemented using cryptography concepts such as Computational Diffie-Hellman assumption and ElGamal encryption and fuzzy logic system based on Advanced Intelligence system through a mathematical transformation and finally conceptual analysis is given.}, 
keywords={cloud computing;cryptography;mathematical analysis;open systems;reverse engineering;advanced persistent threat;advanced persistent threat defense system;bilinear mapping;cloud computing;cloud security;cryptography concepts;mathematical analysis;reverse engineering methods;self-destructive mechanism;versatile cloud services;Authentication;Cloud computing;Distributed databases;Encryption;Organizations;Advanced Persistent Threat;Cloud Security;Defense system;Reverse Engineering;Self-destructive mechanisms}, 
doi={10.1109/ICETECH.2016.7569181}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{6458581, 
author={E. N. Saad and K. E. Mahdi and M. Zbakh}, 
booktitle={2012 IEEE International Conference on Complex Systems (ICCS)}, 
title={Cloud computing architectures based IDS}, 
year={2012}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Today, cloud computing is an attractive and cost-saving service for buyers as it provides accessibility and reliability options for users and scalable sales for providers. Before implementing this method of computing, however, it is important to consider the security of the cloud. In this paper, we will present, a classification of specific and traditional attacks to the cloud computing according to their origin and their category, as a solution to protect the cloud from these attacks, the IDS integrated in the cloud remains among the best solution, therefore we will show some existing cloud computing architecture based Intrusion Detection System (IDS), their strengths and weaknesses. For the comparative study between the architectures, we have adopted transparency, alerts analysis, authentication, accountability, dynamic reaction, centralized management, interoperability, deployability and control from front office side as criterion for comparison, as a result of this comparative study, we propose a new architecture in one hand by correcting some weaknesses and in the other hand integrating certain concept.}, 
keywords={cloud computing;open systems;security of data;IDS;accessibility;alert analysis;authentication;centralized management;cloud computing architectures;cloud security;cost-saving service;deployability;dynamic reaction;front office side;interoperability;intrusion detection system;reliability;Cloud computing;Computer architecture;Intrusion detection;Monitoring;Virtual machine monitors;Virtual machining;cloud computing;cloud security;computer attacks;intrusion detection;intrusion prevention;network attacks}, 
doi={10.1109/ICoCS.2012.6458581}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{5569697, 
author={Y. Feng}, 
booktitle={2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery}, 
title={Towards knowledge discovery in Semantic era}, 
year={2010}, 
volume={5}, 
number={}, 
pages={2071-2075}, 
abstract={Knowledge discovery is the non-trivial process of identifying valid, novel, potentially useful and ultimately understandable patterns in data. The complicated computational environment with ultra-large-scale, heterogeneous, highly-dynamic, and semantic-implicit data in the 21st century puts forward new problems and challenges for traditional knowledge discovery. As a solution, Semantic Web and Cloud Computing addresses the problem of semantic interoperability and large-scale resources sharing, thus making it a proper environment for future's knowledge discovery and data mining. As a probing research, this paper aims to answer the question: “what is knowledge discovery in Semantic era”. We discuss the virtual organization of knowledge discovery in Semantic Era, and introduce five roles in this environment. Moreover, we emphasize four distinguishing characteristics of knowledge discovery in Semantic era: 1) the dynamic semantic extension and self-description of algorithm; 2) the semantic integration of heterogeneous data; 3) the enablement of high-level semantic reasoning and knowledge discovery; 4) the circular refinement of knowledge and semantics. Considering the approaching era of Semantic Web and Cloud Computing, the walking towards knowledge discovery in Semantic era could be expected.}, 
keywords={Internet;data mining;semantic Web;cloud computing;computational environment;data mining;knowledge discovery;semantic Web;semantic era;semantic interoperability;Cloud computing;Data mining;Ontologies;Organizations;Semantic Web;Semantics;Cloud Computing;Knowledge Discovery;Semantic Web}, 
doi={10.1109/FSKD.2010.5569697}, 
ISSN={}, 
month={Aug},}
@INBOOK{7493836, 
author={San Murugesan and Irena Bojanova}, 
booktitle={Encyclopedia of Cloud Computing}, 
title={Cloud Knowledge Modeling and Management}, 
year={2016}, 
volume={}, 
number={}, 
pages={744-}, 
abstract={Modeling cloud knowledge can be the basis for enabling a large range of reasoning applications. The modeling of cloud knowledge bases includes ontologies for cloud model representation at the levels of IaaS, SaaS and PaaS with all details regarding cloud resources. Additional aspects related to service level agreements and business metrics are also modeled to allow reasoning regarding cloud reconfiguration and adaptation to different conditions. The present state of the art shows a number of solutions and standards addressing mainly the problem of cloud interoperability and thus intercloud federation. The most widespread applications areas are related to (i) facilitating interoperability among public and private clouds, (ii) verification and validation of cloud configuration, (iii) discovering and brokering of services and resources, (iv) computing cloud simulation, (v) reasoning and adapting cloud workload conditions, and (vi) reasoning about cloud security. In this chapter, the main aspects of cloud knowledge modeling are presented and discussed by taking into account state-of-the-art solutions.}, 
keywords={}, 
doi={10.1002/9781118821930.ch52}, 
ISSN={}, 
publisher={Wiley-IEEE Press}, 
isbn={9781118821930}, 
url={http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7493836},}
@INPROCEEDINGS{6546108, 
author={K. Maheshwari and K. Birman and J. Wozniak and D. V. Zandt}, 
booktitle={2013 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing}, 
title={Evaluating Cloud Computing Techniques for Smart Power Grid Design Using Parallel Scripting}, 
year={2013}, 
volume={}, 
number={}, 
pages={319-326}, 
abstract={Applications used to evaluate next-generation electrical power grids(``smart grids'') are anticipated to be compute and data-intensive. In this work, we parallelize and improve performance of one such application which was run sequentially prior to the use of our cloud-based configuration. We examine multiple cloud computing offerings, both commercial and academic, to evaluate their potential for improving the turnaround time for application results. Since the target application does not fit well into existing computational paradigms for the cloud, we employ parallel scripting tool, as a first step toward a broader program of adapting portable, scalable computational tools for use as enablers of the future smart grids. We use multiple clouds as a way to reassure potential users that the risk of cloud-vendor lock-in can be managed. This paper discusses our methods and results. Our experience sheds light on some of the issues facing computational scientists and engineers tasked with adapting new paradigms and infrastructures for existing engineering design problems.}, 
keywords={cloud computing;parallel processing;power engineering computing;smart power grids;cloud computing technique;cloud-based configuration;cloud-vendor lock-in;engineering design problem;multiple cloud computing offerings;next-generation electrical power grid;parallel scripting tool;portable scalable computational tool;smart power grid design;turnaround time;Bandwidth;Cloud computing;Computational modeling;Mars;Resource management;Smart grids;cloud computing;parallel scripting;smart grid}, 
doi={10.1109/CCGrid.2013.26}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{7557384, 
author={S. Kolb and C. Röck}, 
booktitle={2016 IEEE World Congress on Services (SERVICES)}, 
title={Unified Cloud Application Management}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={From its early stages, cloud computing has evolved from being a principal source for computing resources to a fully fledged alternative for rapid application deployment. Especially the service model Platform as a Service facilitates the hosting of scalable applications in the cloud by providing managed and highly automated application environments. Although most offerings are conceptually comparable to each other, the interfaces for application deployment and management vary greatly between vendors. Despite providing similar functionalities, technically different workflows and commands provoke vendor lock-in and hinder portability as well as interoperability. To that end, we present a unified interface for application deployment and management among cloud platforms. We validate our proposal with a reference implementation targeting four leading cloud platforms. The results show the feasibility of our approach and promote the possibility of portable DevOps scenarios in PaaS environments.}, 
keywords={cloud computing;PaaS environments;application deployment;cloud computing;cloud platforms;computing resources;platform as a service;portable DevOps;service model;unified cloud application management;unified interface;vendor lock-in;workflows;Automation;Interoperability;Platform as a service;Reactive power;Runtime;Software as a service;API;Cloud Computing;DevOps;Interoperability;Platform as a Service;Portability}, 
doi={10.1109/SERVICES.2016.7}, 
ISSN={}, 
month={June},}
@ARTICLE{6928499, 
author={S. H. Lee and J. H. Song and I. K. Kim}, 
journal={IEEE Transactions on Services Computing}, 
title={CDA Generation and Integration for Health Information Exchange Based on Cloud Computing System}, 
year={2016}, 
volume={9}, 
number={2}, 
pages={241-249}, 
abstract={Successful deployment of Electronic Health Record helps improve patient safety and quality of care, but it has the prerequisite of interoperability between Health Information Exchange at different hospitals. The Clinical Document Architecture (CDA) developed by HL7 is a core document standard to ensure such interoperability, and propagation of this document format is critical for interoperability. Unfortunately, hospitals are reluctant to adopt interoperable HIS due to its deployment cost except for in a handful countries. A problem arises even when more hospitals start using the CDA document format because the data scattered in different documents are hard to manage. In this paper, we describe our CDA document generation and integration Open API service based on cloud computing, through which hospitals are enabled to conveniently generate CDA documents without having to purchase proprietary software. Our CDA document integration system integrates multiple CDA documents per patient into a single CDA document and physicians and patients can browse the clinical data in chronological order. Our system of CDA document generation and integration is based on cloud computing and the service is offered in Open API. Developers using different platforms thus can use our system to enhance interoperability.}, 
keywords={application program interfaces;cloud computing;document handling;electronic health records;hospitals;open systems;standards;CDA document format;CDA document integration system;CDA generation;Clinical Document Architecture;HIS;HL7;care quality;cloud computing system;document standard;electronic health record;health information exchange;hospitals;interoperability;open API service;patient safety;Charge coupled devices;Cloud computing;Hospitals;Interoperability;Servers;Standards;CDA;HL7;Health information exchange;cloud computing;software as a service}, 
doi={10.1109/TSC.2014.2363654}, 
ISSN={1939-1374}, 
month={March},}
@INPROCEEDINGS{6676755, 
author={I. Petri and M. Punceva and O. F. Rana and G. Theodorakopoulos}, 
booktitle={2013 IEEE Sixth International Conference on Cloud Computing}, 
title={Broker Emergence in Social Clouds}, 
year={2013}, 
volume={}, 
number={}, 
pages={669-676}, 
abstract={Cloud computing generally involves the use of data storage and computational resources from external providers. Although a number of commercial providers are currently on the market, it is often beneficial for a user to consider capability from a number of different ones. This would prevent vendor lock-in and more economic choice for a user. Based on this observation, work on "Social Clouds" has involved using social relationships formed between individuals and institutions to establish Peer-2-Peer resource sharing networks, enabling market forces to determine how demand for resources can be met by a number of different (often individually owned) providers. In this paper we identify how trading within such a network could be enhanced by the dynamic emergence (or identification) of brokers -- based on their social position in the network (based on connectivity metrics within a social network). We investigate how offering financial incentives to such brokers, once discovered, could help improve the number of trades that could take place with a network. A social score algorithm is described and simulated with PeerSim to validate our approach. We also compare the approach to a distributed dominating set algorithm - the closest approximation to our approach.}, 
keywords={cloud computing;distributed algorithms;peer-to-peer computing;resource allocation;set theory;social networking (online);PeerSim;broker emergence;cloud computing;commercial providers;computational resources;connectivity metrics;data storage;distributed dominating set algorithm;economic user choice;financial incentives;peer-to-peer resource sharing networks;resource demand;social clouds;social network;social relationships;vendor lock-in;Approximation algorithms;Approximation methods;Communities;Educational institutions;Measurement;Peer-to-peer computing;Social network services;broker-based architecture;cloud computing;social networks}, 
doi={10.1109/CLOUD.2013.38}, 
ISSN={2159-6182}, 
month={June},}
@INPROCEEDINGS{6226014, 
author={D. Ardagna and E. Di Nitto and P. Mohagheghi and S. Mosser and C. Ballagny and F. D'Andria and G. Casale and P. Matthews and C. S. Nechifor and D. Petcu and A. Gericke and C. Sheridan}, 
booktitle={2012 4th International Workshop on Modeling in Software Engineering (MISE)}, 
title={MODAClouds: A model-driven approach for the design and execution of applications on multiple Clouds}, 
year={2012}, 
volume={}, 
number={}, 
pages={50-56}, 
abstract={Cloud computing is emerging as a major trend in the ICT industry. While most of the attention of the research community is focused on considering the perspective of the Cloud providers, offering mechanisms to support scaling of resources and interoperability and federation between Clouds, the perspective of developers and operators willing to choose the Cloud without being strictly bound to a specific solution is mostly neglected. We argue that Model-Driven Development can be helpful in this context as it would allow developers to design software systems in a cloud-agnostic way and to be supported by model transformation techniques into the process of instantiating the system into specific, possibly, multiple Clouds. The MODAClouds (MOdel-Driven Approach for the design and execution of applications on multiple Clouds) approach we present here is based on these principles and aims at supporting system developers and operators in exploiting multiple Clouds for the same system and in migrating (part of) their systems from Cloud to Cloud as needed. MODAClouds offers a quality-driven design, development and operation method and features a Decision Support System to enable risk analysis for the selection of Cloud providers and for the evaluation of the Cloud adoption impact on internal business processes. Furthermore, MODAClouds offers a run-time environment for observing the system under execution and for enabling a feedback loop with the design environment. This allows system developers to react to performance fluctuations and to re-deploy applications on different Clouds on the long term.}, 
keywords={business data processing;cloud computing;decision support systems;risk analysis;software engineering;ICT industry;MODAClouds;application design;application execution;cloud adoption impact evaluation;cloud provider selection;cloud-agnostic way;decision support system;feedback loop;internal business process;model transformation techniques;model-driven approach;model-driven development;multiple cloud computing;risk analysis;software system design;Biological system modeling;Business;Computational modeling;Computer integrated manufacturing;Decision support systems;Quality of service;Software;Cloud computing;model-driven development;performance;portability}, 
doi={10.1109/MISE.2012.6226014}, 
ISSN={2156-7883}, 
month={June},}
@ARTICLE{5617066, 
author={P. Hofmann and D. Woods}, 
journal={IEEE Internet Computing}, 
title={Cloud Computing: The Limits of Public Clouds for Business Applications}, 
year={2010}, 
volume={14}, 
number={6}, 
pages={90-93}, 
abstract={The cloud computing model - especially the public cloud - is unsuited to many business applications and is likely to remain so for many years due to fundamental limitations in architecture and design. Enterprises that move their IT to the cloud are likely to encounter challenges such as security, interoperability, and limits on their ability to tailor their ERP to their business processes. The cloud can be a revolutionary technology, especially for small startups, but the benefits wane for larger enterprises with more complex IT needs. Utility computing still cannot match the "plug-and-play" simplicity of electricity. On the other hand, private clouds offer the benefits like scale and virtualization with fewer drawbacks.}, 
keywords={Internet;enterprise resource planning;open systems;security of data;business applications;business processes;cloud computing model;interoperability;public clouds;revolutionary technology;utility computing;Cloud computing;Clouds;Companies;Memory;Standards organizations;Cloud computing;private clouds;utility computing}, 
doi={10.1109/MIC.2010.136}, 
ISSN={1089-7801}, 
month={Nov},}
@INPROCEEDINGS{5474674, 
author={T. Dillon and C. Wu and E. Chang}, 
booktitle={2010 24th IEEE International Conference on Advanced Information Networking and Applications}, 
title={Cloud Computing: Issues and Challenges}, 
year={2010}, 
volume={}, 
number={}, 
pages={27-33}, 
abstract={Many believe that Cloud will reshape the entire ICT industry as a revolution. In this paper, we aim to pinpoint the challenges and issues of Cloud computing. We first discuss two related computing paradigms - Service-Oriented Computing and Grid computing, and their relationships with Cloud computing. We then identify several challenges from the Cloud computing adoption perspective. Last, we will highlight the Cloud interoperability issue that deserves substantial further research and development.}, 
keywords={Internet;grid computing;open systems;software architecture;ICT industry;cloud computing;cloud interoperability;grid computing;service-oriented Computing;Australia;Cloud computing;Computer networks;Distributed computing;Ecosystems;File servers;Grid computing;Intelligent networks;NIST;Physics computing;Cloud computing;Distributed Comptuing;Servcice-Oriented Computing;Web Services}, 
doi={10.1109/AINA.2010.187}, 
ISSN={1550-445X}, 
month={April},}
@INPROCEEDINGS{6546151, 
author={S. Jeuk and S. Zhou and M. Rio}, 
booktitle={2013 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing}, 
title={Tenant-ID: Tagging Tenant Assets in Cloud Environments}, 
year={2013}, 
volume={}, 
number={}, 
pages={642-647}, 
abstract={Cloud Computing facilitates the new generation of IT and the provisioning of services by introducing virtualization concepts throughout the network. Multi-tenancy introduces the capability to share cloud assets among service users. Service providers currently lack innovative means to enable true multi-tenancy in a cloud environment. There is an urgent need for technologies that introduce tenant security, traffic identification and tenant separation for better billing and fairness. This paper introduces a technology that tackles all these requirements by defining the concept of a Tenant-ID that is incorporated into the OSI Layer 2 frame header. We outline the concept of Tenant-IDs, the adapted 802.1q header and a way to automatically configure tenants via Cloud automation tools and software-defined networking approaches. The paper concludes by outlining interoperability to relevant layer-2 protocols and by introducing use-cases benefiting from the Tenant-ID concept.}, 
keywords={cloud computing;open systems;protocols;security of data;virtualisation;OSI Layer 2 frame header;Tenant-ID concept;cloud automation tool;cloud computing;cloud environment;interoperability;layer-2 protocol;multitenancy;service provider;software-defined networking approach;tenant asset tagging;tenant security;tenant separation;traffic identification;virtualization concept;Cloud computing;Databases;Protocols;Security;Servers;Switches;Tagging;Cloud Computing;Multi-Tenancy;Resource isolation;Security;Tenant separation}, 
doi={10.1109/CCGrid.2013.108}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{6999359, 
author={L. Zeng and C. Meng and Z. Li and X. Huang and Z. Liang}, 
booktitle={2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
title={Cloud computing and its decision-making for medical and health informatization in the context of big data}, 
year={2014}, 
volume={}, 
number={}, 
pages={201-206}, 
abstract={Cloud computing, as a new system and architecture of data mutual sharing, is composed of three service models i.e. cloud software as a service (SaaS), cloud platform as a service (PaaS) and cloud infrastructure as a service (IaaS), as well as including three key enabling technologies i.e. networks of fast wide-area, server computers of powerful and inexpensive specialty, and commodity hardware of high-performance virtualization. Cloud computing technology brings in innovative and constructive ideas for the medical and health informatization. However, it also challenges many traditional approaches to application design and management of medical-sanitary institutions or other datacenters, especially the relevant issues of security, interoperability, portability, et al. that cited as major barriers to broader adoption. Based on the concept, key technology, core problem and principles, the author attempts to discuss the main issues of cloud computing in the construction and development of the medical and health informatization. We hope these considerations can provide reference to the service for the present medical informatization construction and practical decision-making in the context of big data.}, 
keywords={Big Data;cloud computing;decision making;medical information systems;Big Data;IaaS;PaaS;SaaS;cloud computing;cloud infrastructure as a service;cloud platform as a service;cloud software as a service;data mutual sharing;decision-making;medical and health informatization;medical-sanitary institutions;Cloud computing;Computational modeling;Hardware;Hospitals;Security;Software as a service;Big data;Cloud computing;Cloud storage;Decision-making;Informatization;Medical and health;SaaS;Software as a service}, 
doi={10.1109/BIBM.2014.6999359}, 
ISSN={}, 
month={Nov},}
@INBOOK{7493855, 
author={San Murugesan and Irena Bojanova}, 
booktitle={Encyclopedia of Cloud Computing}, 
title={Cloud Data Management}, 
year={2016}, 
volume={}, 
number={}, 
pages={744-}, 
abstract={Cloud Data Management (CDM) substantially reduces the cost of data storage and data processing and is a rapidly expanding business. Major search and electronic commerce companies such as, Google, Microsoft, Amazon, and Alibaba have adopted CDM for their operations. CDM, however, presents major data management challenges such as large volume (Exabyte, or even Zettabyte) data storage, massively parallel query execution, analytical processing of big data, and online query processing. These challenges raise questions such as: How to deal with the large-scale datasets? How to provide a good scalability? How to provide a good cost-effective service and support fault tolerance? In this chapter, we outline the state-of-the-art data management technologies on extremely large datasets, and lessons learned on building data management solutions. We discuss cloud computing infrastructure for big data storage and computing, services discovery and content distribution in cloud computing infrastructures, cross-platform interoperability, query processing and indexing in cloud computing systems, and structure and non-structure data management. We also examine the limitations and opportunities of deploying CDM and speculate that large scale data analysis tasks, decision support systems, and application specific data marts are more likely to take advantages of cloud computing technologies than operational, transactional distribution file system and database systems.}, 
keywords={}, 
doi={10.1002/9781118821930.ch47}, 
ISSN={}, 
publisher={Wiley-IEEE Press}, 
isbn={9781118821930}, 
url={http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7493855},}
@INPROCEEDINGS{7335315, 
author={A. M. Khan and F. Freitag and L. Rodrigues}, 
booktitle={2015 IEEE 4th International Conference on Cloud Networking (CloudNet)}, 
title={Current trends and future directions in community edge clouds}, 
year={2015}, 
volume={}, 
number={}, 
pages={239-241}, 
abstract={Cloud computing promises access to computing resources that is cost-effective, elastic and easily scalable. With few key cloud providers in the field, despite the benefits, there are issues like vendor lock-in, privacy and control over data. In this paper we focus on alternative models of cloud computing, like the community clouds at the edge which are built collaboratively using the resources contributed by the users, either through solely relying on users' machines, or using them to augment existing cloud infrastructures. We study community network clouds in the context of other initiatives in community cloud computing, mobile cloud computing, social cloud computing, and volunteer computing, and analyse how the context of community networks can support the community clouds.}, 
keywords={cloud computing;mobile computing;volunteer computing;cloud infrastructure;community edge cloud;community network cloud computing;mobile cloud computing;social cloud computing;user machine;volunteer computing;Cloud computing;Computational modeling;Computer architecture;Context;Mobile communication;Resource management;cloud computing;community clouds}, 
doi={10.1109/CloudNet.2015.7335315}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6717860, 
author={M. Pyo and S. Bae and S. Han}, 
booktitle={2013 International Conference on IT Convergence and Security (ICITCS)}, 
title={Multicast Based Service Orchestration Protocol}, 
year={2013}, 
volume={}, 
number={}, 
pages={1-3}, 
abstract={Cloud computing has become the most attractive technology in distributed computing and a variety of cloud services have been introduced. However, there is still no widely accepted standard format to satisfy cloud service providers and users requests. Consequently, it caused the issue of interoperability among them. This paper proposes a cloud service orchestration protocol based on multicast. This protocol separates the network view of service information and the application view of service information when exchanging service information to support interoperability and it uses multicast at various point of protocol to support scalability. Cloud system may have a lot of services and users to communicate with each other. Hence, there are some needs for effective transfer method and the multicast is one of the ideal solutions for this problem. This protocol helps to interoperate with various cloud services like web services and embedded devices.}, 
keywords={cloud computing;multicast protocols;open systems;cloud computing;cloud service orchestration protocol;cloud services;distributed computing;interoperability;multicast based service orchestration protocol;Cloud computing;Computer architecture;Interoperability;Protocols;Registers;XML}, 
doi={10.1109/ICITCS.2013.6717860}, 
ISSN={}, 
month={Dec},}
@ARTICLE{6848733, 
author={}, 
journal={IEEE Cloud Computing}, 
title={Q amp; A with Mazin Yousif, IEEE Cloud Computing Editor in Chief}, 
year={2014}, 
volume={1}, 
number={1}, 
pages={8-9}, 
abstract={IEEE Cloud Computing Editor in Chief Mazin Yousif shares his thoughts on the future of cloud, key challenges, and drivers for broader adoption. Critical challenges, such as security, privacy, interoperability, and access, should be approached from three angles--technological, confidence building, and legal--with broad support from service providers, technology companies, the open source community, government, and standards bodies.}, 
keywords={Cloud computing;Computer applications;Interviews;Internet governance;big data;cloud;distributed systems;mobility;standards}, 
doi={10.1109/MCC.2014.18}, 
ISSN={2325-6095}, 
month={May},}
@INPROCEEDINGS{6133225, 
author={N. Loutas and E. Kamateri and F. Bosi and K. Tarabanis}, 
booktitle={2011 IEEE Third International Conference on Cloud Computing Technology and Science}, 
title={Cloud Computing Interoperability: The State of Play}, 
year={2011}, 
volume={}, 
number={}, 
pages={752-757}, 
abstract={Cloud computing is a promising IT paradigm which enables the Internet's evolution into a global market of collaborating services. Cloud computing semantic interoperability plays a key role in making this a reality. Towards this direction, a comprehensive and systematic survey of Cloud computing interoperability efforts by standardization groups, industry and research community is carried out. The main objective of this survey is to derive an initial set of semantic interoperability requirements to be supported by existing as well as next generation Cloud systems. Ôhe survey motivates and encourages the Cloud community to adopt a common Cloud computing interoperability framework with core dimensions the creation of a common data model and a standardized Cloud interface (API), which will constitute the base for the development of a semantically interoperable Cloud environment.}, 
keywords={application program interfaces;cloud computing;data models;open systems;IT paradigm;Internet evolution;cloud community;cloud computing semantic interoperability;data model;global collaborating service market;next generation cloud systems;standardization groups;standardized cloud interface;Cloud computing;Computational modeling;Computer architecture;Data models;Semantics;Standards;Cloud computing;interoperability;requirements;semantic interoperability}, 
doi={10.1109/CloudCom.2011.116}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{7724477, 
author={D. Tripathi and N. K. Joshi}, 
booktitle={2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom)}, 
title={Model for heterogeneous data integration on cloud}, 
year={2016}, 
volume={}, 
number={}, 
pages={1307-1309}, 
abstract={In today's scenario when more and more enterprises are shifting towards cloud computing, the variety volume and velocity of the cloud is expected to cope up to the expectations. Although big data centers and latest technologies have handled huge volumes of data but still the problem of integrating heterogeneous data on the cloud persists. This paper proposes a model for integrating heterogeneous data on the cloud focusing on the security of data at rest. The model is based on service oriented computing, as services are based on fundamental features of interoperability and loose coupling. The different layers of the proposed model deal with different aspects of data interpretation on cloud. The client layer provides interface to the client and works on basic request and response parameters. The service inventory layer comprises of different services working on integration and encryption of data and the cloud data layer holds the actual data in uniform format. The paper aims to provide a solution to the heterogeneous data integration problem on cloud and data security at rest.}, 
keywords={client-server systems;cloud computing;cryptography;data integration;distributed databases;open systems;client layer;cloud computing;data encryption;data interpretation;data security;heterogeneous data integration;interoperability;service inventory layer;service oriented computing;Conferences;Decision support systems;Handheld computers;Encryption;heterogeneous data;homomorphic encryption;integration;services and service oriented computing}, 
doi={}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{7184830, 
author={N. Suresh and J. Mbale and A. Terzoli and T. K. Mufeti}, 
booktitle={2015 International Conference on Emerging Trends in Networks and Computer Communications (ETNCC)}, 
title={Enhancing cloud connectivity among NRENs in the SADC region through a novel institution cloud infrastructure framework}, 
year={2015}, 
volume={}, 
number={}, 
pages={179-184}, 
abstract={It is increasingly being recognized that faster socioeconomic development in Africa is dependent upon the development of Information and Communication Technology (ICT) Infrastructure for the dissemination of data and educational services. The scalability and flexibility provided by Cloud services in terms of resource management, service provisioning and virtualization makes it an attractive system for use with educational and ICT services. The flexibility of pay-as-you-go models combined with the ability to scale computing, storage and/or networking resources makes Cloud computing an ideal candidate for use with education, research and scientific infrastructures. Notwithstanding its benefits, transitioning from a traditional IT infrastructure to a Cloud computing paradigm raises security concerns with respect to data storage, data transmission and user privacy. This paper presents on-going research for the development of Science, Technology and Innovation (STI) infrastructure for the distribution of Information Communication technologies (ICT) services in the African context. The Inter-Cloud Infrastructure Framework (ICIF) proposed, is conceived as a Cloud computing framework suitable for use with National Research and Education Networks (NRENs) in the SADC region. The ICIF system is used to create an Inter-Cloud infrastructure, and helps NRENs transition from traditional IT infrastructure systems to the Cloud computing paradigm. It also provides new functional/operational components and Cloud services to support the interconnection and/or interoperability among SADC NRENs through the ICIF infrastructure.}, 
keywords={cloud computing;data privacy;innovation management;virtualisation;Africa;ICIF;ICT infrastructure;NRENs;National Research and Education Networks;SADC region;STI infrastructure;cloud computing;cloud connectivity;data dissemination;data storage;data transmission;educational services;information and communication technology infrastructure;innovation infrastructure;institution cloud infrastructure framework;intercloud infrastructure framework;pay-as-you-go models;resource management;science infrastructure;service provisioning;socioeconomic development;user privacy;virtualization;Collaboration;Computational modeling;Computer architecture;Organizations;Platform as a service;Security;Cloud Computing;Cloud Services;Inter-Cloud Infrastructure}, 
doi={10.1109/ETNCC.2015.7184830}, 
ISSN={}, 
month={May},}
@ARTICLE{7912161, 
author={T. Sanislav and S. Zeadally and G. D. Mois}, 
journal={Computer}, 
title={A Cloud-Integrated, Multilayered, Agent-Based Cyber-Physical System Architecture}, 
year={2017}, 
volume={50}, 
number={4}, 
pages={27-37}, 
abstract={The cloud computing infrastructure has the power to increase the dependability, interoperability, and scalability of emerging cyber-physical systems (CPSs). Integrating intelligent agents and semantic ontologies can help manage the complexity of such systems and enable the development of large-scale CPSs.}, 
keywords={cloud computing;cyber-physical systems;ontologies (artificial intelligence);open systems;agent-based cyber-physical system architecture;cloud computing infrastructure;intelligent agents;large-scale CPS;semantic ontologies;Cloud computing;Computer architecture;Computer security;Cyber-physical systems;Interoperability;Medical services;Smart cities;CPSs;agent-based architecture;cloud;cyber-physical systems;cybersecurity;intelligent agent technologies;networking;security}, 
doi={10.1109/MC.2017.113}, 
ISSN={0018-9162}, 
month={April},}
@INPROCEEDINGS{7300969, 
author={M. Bahrami and M. Singhal}, 
booktitle={2015 IEEE International Conference on Information Reuse and Integration}, 
title={DCCSOA: A Dynamic Cloud Computing Service-Oriented Architecture}, 
year={2015}, 
volume={}, 
number={}, 
pages={158-165}, 
abstract={The emerging field of Cloud Computing provides several advantages over traditional in-house IT services, such as accessing to elastic on-demand computing and storage over the Internet, and cost effective pay-per-use subscription plans. However, according to the International Data Corporation (IDC), cloud computing has several issues, such as a lack of standardization, a lack of customization, and limited interoperability. In addition, there is an increasing demand for introduction and migration of a variety of services to cloud computing systems, which are abstract their offering services into various *-as-a-Services (*aaS) layers. Although each such service provides a new feature (e.g., simulation services in cloud), it aggravates the issues due to the lack of standardization and inability to customize services by a vendor because each *aaS has its own features, requirements and output. In this paper, we propose a cloud architecture to alleviate issues associated with standardization and customization. In the cloud, the proposed architecture uses a single layer, called Template-as-a-Service (TaaS), to provide: (i) a single service layer for interaction with all resources and major cloud services (e.g., IaaS, PaaS, SaaS and *aaS), (ii) a standardization for existing services and future *aaS across different cloud environments, and (iii) a customizable architecture which can be modified on demand by a cloud vendor, and its partners to provide the flexibility on cloud computing systems. A comparison with previous studies show that the proposed architecture provides customization and standardization for cloud services with minimum modifications.}, 
keywords={cloud computing;service-oriented architecture;*-as-a-services layers;*aaS layers;DCCSOA;IDC;International Data Corporation;Internet;TaaS;dynamic cloud computing service-oriented architecture;elastic on-demand computing;in-house IT services;template-as-a-service;Conferences;*-as-a-Service;Cloud Architecture;Cloud Computing;Cloud Customization;Cloud Standardization;SOA}, 
doi={10.1109/IRI.2015.33}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{6735452, 
author={G. C. Silva and L. M. Rose and R. Calinescu}, 
booktitle={2013 IEEE 5th International Conference on Cloud Computing Technology and Science}, 
title={A Systematic Review of Cloud Lock-In Solutions}, 
year={2013}, 
volume={2}, 
number={}, 
pages={363-368}, 
abstract={The heterogeneity of cloud semantics, technology and interfaces limits application and platform portability and interoperability, and can easily lead to vendor lock-in. We identify, analyse and classify existing solutions to cloud vendor lock-in, and highlight unresolved challenges. Our survey is based on a systematic review of 721 primary studies that describe the state-of-the-art in managing cloud lock-in, portability and interoperability. 78 of these primary studies were selected and used for a thorough analysis of cloud standards, commercial products and academic work related to cloud lock-in. Our review shows that most solutions proposed so far are platforms, APIs or architectures addressing infrastructure-as-a-service (IaaS) interoperability. From our review, we identify a need for: (i) exploiting established solutions from areas that are closely related to cloud computing, (ii) increasing empirical evidence to raise confidence in existing solutions, and (iii) addressing the socio-technical and business challenges related to cloud lock-in.}, 
keywords={application program interfaces;cloud computing;open systems;software architecture;software portability;API;IaaS interoperability;architecture;business challenges;cloud computing;cloud lock-in management;cloud lock-in solutions;cloud semantics heterogeneity;cloud standards;cloud vendor lock-;commercial products;infrastructure-as-a-service;platform portability;socio-technical challenges;vendor lock-in;Cloud computing;Computer science;Industries;Interoperability;Semantics;Standards;Systematics;cloud lock-in;interoperability;portability;review}, 
doi={10.1109/CloudCom.2013.130}, 
ISSN={}, 
month={Dec},}
@ARTICLE{6051416, 
author={L. Riungu-Kalliosaari and O. Taipale and K. Smolander}, 
journal={IEEE Software}, 
title={Testing in the Cloud: Exploring the Practice}, 
year={2012}, 
volume={29}, 
number={2}, 
pages={46-51}, 
abstract={As applications and services migrate to the cloud, testing will follow the same trend. Therefore, organizations must understand the dynamics of cloud-based testing. This article presents interviews with eight organizations that use cloud computing. The results suggest that cloud computing can make testing faster and enhance the delivery of testing services. Cloud computing also highlights important aspects of testing that require attention, such as integration and interoperability. This article includes a Web extra that provides additional references for further study.}, 
keywords={cloud computing;program testing;Web extra;cloud computing;cloud-based testing;interoperability;testing services;Cloud computing;Servers;Testing;Web and internet services;cloud computing;cloud-based testing;testing;testing in the cloud}, 
doi={10.1109/MS.2011.132}, 
ISSN={0740-7459}, 
month={March},}
@INPROCEEDINGS{7037749, 
author={C. A. Lee and N. Desai and A. Brethorst}, 
booktitle={2014 IEEE 6th International Conference on Cloud Computing Technology and Science}, 
title={A Keystone-Based Virtual Organization Management System}, 
year={2014}, 
volume={}, 
number={}, 
pages={727-730}, 
abstract={As distributed, on-line communities are increasingly supported by the global, interconnected computing infrastructure, methods must be developed to securely manage their interactions. The virtual organization (VO) concept provides a security and discovery context whereby collaboration across multiple administrative domains can be enabled while enforcing joint security policies. In the era of cloud computing, VOs can be used to manage "community clouds", i.e., Cloud federations. In this paper, we describe a method for re-purposing the Open Stack Keystone service to act as a VO Management System (VOMS) called Key VOMS. With minor changes, it can be used to manage access to services that are registered for use by members of any given VO. These services can be arbitrary infrastructure-level or application-level services. This is illustrated by using Key VOMS to manage access to a set of RSS feed topics. While very flexible, the use of an external, third-party, such as Key VOMS, raises fundamental semantic interoperability and trust delegation issues that must be addressed in future work.}, 
keywords={cloud computing;groupware;open systems;security of data;trusted computing;virtual enterprises;RSS feed topics;application-level services;cloud computing;collaboration;community cloud management;discovery context;infrastructure-level service;interconnected computing infrastructure;joint security policies;key VOMS;keystone-based virtual organization management system;online communities;open stack keystone service;security context;semantic interoperability;trust delegation issues;Catalogs;Cloud computing;Collaboration;Context;Feeds;Organizations;Security;Open Stack;Virtual organizations;cloud federation}, 
doi={10.1109/CloudCom.2014.31}, 
ISSN={}, 
month={Dec},}
@ARTICLE{8030494, 
author={C. Esposito and A. Castiglione and C. A. Tudorica and F. Pop}, 
journal={IEEE Communications Magazine}, 
title={Security and privacy for cloud-based data management in the health network service chain: a microservice approach}, 
year={2017}, 
volume={55}, 
number={9}, 
pages={102-108}, 
abstract={New and useful tools that facilitate the harmonization and interconnection of health data have become a requirement for monitoring and preventing illness and also for sharing medical knowledge. Nowadays, cloud-based solutions can support collaborative data science platforms and deliver all types of processing operations through the network service chain. In this article we deal with healthcare-related data management and exchange, and we propose security and privacy requirements together with a novel microservices approach. We investigate how cloud computing can be adopted within healthcare systems. The interoperability of existing technologies will improve the quality of life and the efficiency of healthcare systems by making them more personalized and centered on patients, together with reducing operational costs and medical errors. To have a socially acceptable health network service chain, the security and privacy issues need to be analyzed and addressed. We explore the the security and privacy requirements and implications, and also discuss existing methods, and in the end propose an architecture of a secure manager for cloud-based healthcare-related data management and exchange.}, 
keywords={cloud computing;data privacy;health care;cloud computing;cloud-based solutions;health data;healthcare systems;privacy requirements;security requirements;Cloud computing;Computer security;Data privacy;Electronic medical records;Medical services}, 
doi={10.1109/MCOM.2017.1700089}, 
ISSN={0163-6804}, 
month={},}
@INPROCEEDINGS{7745348, 
author={M. S. Das and A. Govardhan and D. V. Lakshmi}, 
booktitle={2016 International Conference on Engineering MIS (ICEMIS)}, 
title={An approach for improving performance of Web services and cloud based applications}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-7}, 
abstract={Web services provide functionalities to the users. Software products and services require high quality. Quality parameters of Web and cloud based applications includes scalability, balancing workload, high availability and other parameters. The objective of the paper to improve the performance of web in cloud based applications. Cloud based applications provide services to the users such as platform as service (PaaS), Infrastructure as Service(IaaS) and Software as Service(SaaS). For design and development of large scale computer model with high storage, demand processing, intensive application for tightly coupled infrastructure with distributed computing applications. One of the important services for Cloud applications is Infrastructure as Service (IaaS) and this provides storage, network computing, cloud files and virtual machines on demand. The problem is to access applications with scalability and distributed computing and interoperability grid of applications. We proposed a cloud service selection model, it find the services on demand and provides the cloud services with quality parameters. The programming model is Simple API for GRID application (SAGA) that will provide data on high performance grids connecting through various applications and it will use a map reduce algorithm is expected to improve the performance of Web services and cloud based applications.}, 
keywords={application program interfaces;cloud computing;data handling;distributed algorithms;grid computing;large-scale systems;open systems;IaaS;MapReduce;PaaS;SAGA;SaaS;Web quality parameters;Web services performance improvement;applications interoperability grid;cloud based applications;cloud service selection model;demand processing;distributed computing applications;high availability;high performance grids;high quality software services;high storage;infrastructure as service;large scale computer model;network computing;platform as service;scalability;services on demand;simple API for grid application;software as service;software products;tightly coupled infrastructure;virtual machines on demand;workload balancing;Cloud computing;Computational modeling;Data models;Quality of service;Service-oriented architecture;Cloud computing;IoT;QoS;Web services;classification;performance;security}, 
doi={10.1109/ICEMIS.2016.7745348}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{7849631, 
author={Muhammad Agus Triawan and H. Hindersah and D. Yolanda and F. Hadiatna}, 
booktitle={2016 6th International Conference on System Engineering and Technology (ICSET)}, 
title={Internet of things using publish and subscribe method cloud-based application to NFT-based hydroponic system}, 
year={2016}, 
volume={}, 
number={}, 
pages={98-104}, 
abstract={The integration Internet of Things (IoT) generally identical with Cloud computing. IoT aims to connect the heterogeneous objects/devices with each other, in order to communicate or exchange data/information. Development of the Cloud IoT system, have challenges to achieve these objectives, such as middleware, interoperability and scalability of system. In this paper, we will discuss the solution of the challenges, by applying the publish and subscriber method, using MQTT protocol. This paper, proposed of architecture model design, which is implemented in the form of system topology. This topology apply to monitor and control the provision of nutrition hydroponics, accessible as a Cloud SaaS. From the test results, average node response time needed to connect and communicate with IoT Cloud system (online) is 7.21 seconds. The time required to declare offline state of a node is 21.55 seconds. The test results of Cloud IoT (broker), obtained that number of nodes for each level QoS, affecting resource usage of CPU and throughput. The highest resource usage of CPU is 19% of 2.0GHz and throughput TX/RX is 34.68KBps/49.4KBps. This result obtained from 1000 nodes scheme testing with 1 messages/node, by using simulation application, on QoS level 2. The average of minimum bandwidth used is ± 0.90Kbps by 1 publisher, to send 1 message with 115 Bytes of payload size, on each 3 levels of QoS MQTT, and approximately ± 0.04Kbps on subscriber to receive that message.}, 
keywords={Internet of Things;cloud computing;message passing;middleware;open systems;quality of service;telecommunication network topology;transport protocols;Internet of Things;IoT cloud system;MQTT protocol;NFT-based hydroponic system;QoS level;average node response time;cloud SaaS;heterogeneous devices;heterogeneous objects;interoperability;middleware;publish-and-subscribe method cloud-based application;system scalability;system topology;Cloud;IoT;MQTT;broker;interoperability;middleware;publish;scalability;subscribe}, 
doi={10.1109/ICSEngT.2016.7849631}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6450972, 
author={R. Wu and G. J. Ahn and H. Hu}, 
booktitle={8th International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom)}, 
title={Secure sharing of electronic health records in clouds}, 
year={2012}, 
volume={}, 
number={}, 
pages={711-718}, 
abstract={In modern healthcare environments, healthcare providers are more willing to shift their electronic medical record systems to clouds. Instead of building and maintaining dedicated data centers, this paradigm enables to achieve lower operational cost and better interoperability with other healthcare providers. However, the adoption of cloud computing in healthcare systems may also raise many security challenges associated with authentication, identity management, access control, trust management, and so on. In this paper, we focus on access control issues in electronic medical record systems in clouds. We propose a systematic access control mechanism to support selective sharing of composite electronic health records (EHRs) aggregated from various healthcare providers in clouds. Our approach ensures that privacy concerns are accommodated for processing access requests to patients' healthcare information.We also demonstrate the feasibility and efficiency of our approach by implementing a proof-of-concept prototype along with evaluation results.}, 
keywords={authorisation;cloud computing;data privacy;health care;medical information systems;message authentication;open systems;trusted computing;EHR;access requests;authentication;cloud computing;clouds;composite electronic health records;dedicated data centers;electronic medical record systems;healthcare environments;healthcare providers;healthcare systems;identity management;interoperability;operational cost;patients healthcare information;privacy concerns;proof-of-concept prototype;secure sharing;security challenges;selective sharing;systematic access control mechanism;trust management;Authorization;Computational modeling;Access Control;Cloud Computing;Electronic Health Record;Security}, 
doi={}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6914006, 
author={R. Chu and I. K. W. Lai and D. C. F. Lai}, 
booktitle={2013 International Conference on Engineering, Management Science and Innovation (ICEMSI)}, 
title={Trust factors influencing the adoption of cloud-based interorganizational systems: A conceptual model}, 
year={2013}, 
volume={}, 
number={}, 
pages={1-3}, 
abstract={This study aims to develop a research model for the study of the trust factors that may influence the adoption of cloud-based interorganizational systems (CIOS). The proposed trust model consists of seven dimensions: security, usability, reliability, auditability, interoperability, accountability, and controllability. The proposed model also suggests that the scale of the company may moderate the effects of above trust factors on the trust in the adoption of CIOS. The proposed trust model aims to help the cloud computing service providers to understand the trust factors that will affect users' trust in the adoption of CIOS. So that cloud computing service providers can adjust their strategies for providing successful cloud computing services. It also provides a base for further research on the trust models for the adoption of other cloud systems.}, 
keywords={cloud computing;trusted computing;CIOS;Trust factors;accountability dimension;auditability dimension;cloud computing service providers;cloud-based interorganizational systems;controllability dimension;interoperability dimension;reliability dimension;security dimension;usability dimension;Cloud computing;Companies;Computational modeling;Interoperability;Security;Supply chains;Cloud Computing;Cloud-Based Interorganizational Systems;Information systems;Trust}, 
doi={10.1109/ICEMSI.2013.6914006}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{7005003, 
author={T. Y. Lin and B. H. Li and C. Yang}, 
booktitle={2013 8th EUROSIM Congress on Modelling and Simulation}, 
title={A Multi-centric Model of Resource and Capability Management in Cloud Simulation}, 
year={2013}, 
volume={}, 
number={}, 
pages={555-560}, 
abstract={The popularity of the modeling and simulation application increases the demand for acquiring the service of the simulation resource and capability (R/C) anytime, anywhere, on demand through the network. Cloud simulation draws the idea of cloud computing that integrates and shares the R/Cs to provide services which significantly depending on the R/Cs' management. Most existing work assumes that there is only one management center, and some existing work uses master-slave management architecture. Both of them cannot provide services reliably in the wide area network. The relevant work in cloud computing deploys data centers scatted and executes the distributed scheduling reliably. However, it does not take the limited R/C constraint and the parallel interoperability of the sub-tasks into account which are unique in simulation field. Our goal is to re-design an architecture of R/Cs' management with multi-centers in wide area. We also propose a mathematical model for the cross-centric global optimized allocation of R/C services. The model includes the factors of the availability of R/C service and the remote collaborative cost among sub-tasks. We show the model achieves desirable effect in the utilization balance of R/Cs and the reduction of the collaborative cost by experiment compared with an existing decentralized model.}, 
keywords={cloud computing;digital simulation;resource allocation;R/C management;R/C services;architecture redesign;capability management;cloud computing;cloud simulation;cross-centric global optimized allocation;distributed scheduling;management center;master-slave management architecture;mathematical model;modeling application;multicentric model;remote collaborative cost;resource management;simulation application;simulation resource and capability;Availability;Cloud computing;Collaboration;Computational modeling;Mathematical model;Resource management;cloud simulation;distributed scheduling;resource allocation;resource management;simulation capability;wide area reliability}, 
doi={10.1109/EUROSIM.2013.98}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6973738, 
author={J. D. Montes and M. Zou and R. Singh and S. Tao and M. Parashar}, 
booktitle={2014 IEEE 7th International Conference on Cloud Computing}, 
title={Data-Driven Workflows in Multi-cloud Marketplaces}, 
year={2014}, 
volume={}, 
number={}, 
pages={168-175}, 
abstract={Cloud computing is emerging as a viable platform for scientific exploration. The ideas of on-demand access to resources, "unlimited" resources as well as interesting pricing models are making scientist to move their workflows into cloud computing. However, the amount of services and different pricing models offered by the providers often overwhelm users when deciding which option is best for them. Moreover, interoperability across providers remains an open topic that forces users to develop specific solutions for each provider. In this paper, we present a service framework that enables the autonomic execution of dynamic workflows in multi-cloud environments. It also allows users to customize scheduling policies to use those resources that best fit their needs. To demonstrate the benefits of this framework, we study the execution of a real scientific workflow, with data dependencies across stages, in a multi-cloud federation using different policies and objective functions.}, 
keywords={cloud computing;open systems;scheduling;scientific information systems;autonomic execution;cloud computing;data dependency;data-driven workflow;dynamic workflow;interoperability;multicloud environment;multicloud federation;multicloud marketplaces;pricing model;real scientific workflow;scheduling policy;scientific exploration;Cloud computing;Computational modeling;Linear programming;Optimization;Pricing;Schedules;Scheduling;Autonomics;Cloud computing;Data-driven workflow;Software-defined infrastructure}, 
doi={10.1109/CLOUD.2014.32}, 
ISSN={2159-6182}, 
month={June},}
@INPROCEEDINGS{6616254, 
author={I. Karamitsos and C. Apostolopoulos}, 
booktitle={2013 Tenth International Conference on Wireless and Optical Communications Networks (WOCN)}, 
title={Convergence: Smart home into cloud}, 
year={2013}, 
volume={}, 
number={}, 
pages={1-4}, 
abstract={Taking into account the increase of the real estate development and the construction of smart cities, the control and interoperability between the devices in the smart home environment has become an interesting topic for further research. The aim of this paper is to present the convergence of smart home into the cloud computing using different network protocols. Moreover, the ways that smart homes can facilitate the development and integration with cloud computing is further discussed and analysed.}, 
keywords={cloud computing;home automation;open systems;protocols;cloud computing;convergence;interoperability;network protocols;real estate development;smart city construction;smart home environment;cloud computing;smart home;smart home protocols}, 
doi={10.1109/WOCN.2013.6616254}, 
ISSN={1811-3923}, 
month={July},}
@BOOK{6812708, 
author={Amit Sheth and Krishnaprasad Thirunarayan}, 
booktitle={Semantics Empowered Web 3.0:Managing Enterprise, Social, Sensor, and Cloud-based Data and Services for Advanced Applications}, 
title={Semantics Empowered Web 3.0:Managing Enterprise, Social, Sensor, and Cloud-based Data and Services for Advanced Applications}, 
year={2012}, 
volume={}, 
number={}, 
pages={175-}, 
abstract={After the traditional document-centric Web 1.0 and user-generated content focused Web 2.0, Web 3.0 has become a repository of an ever growing variety of Web resources that include data and services associated with enterprises, social networks, sensors, cloud, as well as mobile and other devices that constitute the Internet of Things. These pose unprecedented challenges in terms of heterogeneity (variety), scale (volume), and continuous changes (velocity), as well as present corresponding opportunities if they can be exploited. Just as semantics has played a critical role in dealing with data heterogeneity in the past to provide interoperability and integration, it is playing an even more critical role in dealing with the challenges and helping users and applications exploit all forms of Web 3.0 data. This book presents a unified approach to harness and exploit all forms of contemporary Web resources using the core principles of ability to associate meaning with data through conceptual or domain models and semantic descriptions including annotations, and through advanced semantic techniques for search, integration, and analysis. It discusses the use of Semantic Web standards and techniques when appropriate, but also advocates the use of lighter weight, easier to use, and more scalable options when they are more suitable. The authors' extensive experience spanning research and prototypes to development of operational applications and commercial technologies and products guide the treatment of the material. Table of Contents: Role of Semantics and Metadata / Types and Models of Semantics / Annotation -- Adding Semantics to Data / Semantics for Enterprise Data / Semantics for Services / Semantics for Sensor Data / Semantics for Social Data / Semantics for Cloud Computing / Semantics for Advanced Applications}, 
keywords={}, 
doi={10.2200/S00433ED1V01Y201207DTM031}, 
ISSN={}, 
publisher={Morgan & Claypool}, 
isbn={9781608457175}, 
url={http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6812708},}
@INPROCEEDINGS{7399087, 
author={P. Lopes and L. Bastião and J. L. Oliveira}, 
booktitle={2015 IEEE 8th International Conference on Service-Oriented Computing and Applications (SOCA)}, 
title={i2x: An Automated Real-Time Integration and Interoperability Platform (Short Paper)}, 
year={2015}, 
volume={}, 
number={}, 
pages={26-30}, 
abstract={In the age of cloud computing, the amount of data and services available for researchers continues to grow. As data are easier to generate and services simpler to deploy, researchers continue to face insurmountable integration and interoperability challenges. A major ongoing issue across many fields regards the automated and real-time integration of data and services. Besides aggregating and processing disparate sources, we need an always up-to-date view of our heterogeneous and distributed datasets. Enabling realistic insights over acquired information requires that data are as fresh as possible. This perspective appears in opposition to traditional warehousing strategies, where data are manipulated regularly over large intervals. Our proposal introduces a reactive and event-driven framework to simplify and automate real-time data integration and interoperability. This platform, entitled i2x, streamlines the creation of customizable integration tasks connecting heterogeneous data sources with any kind of services. Integration is poll-based, with intelligent agents monitoring data sources, or push-based, where the platform waits for data submission by external resources. I2X delivers data to services through a comprehensive template engine, where the platform maps data from the original data source to the destination resources. I2X is an open-source framework available online at https://bioinformatics.ua.pt/i2x/.}, 
keywords={data integration;open systems;public domain software;cloud computing;data integration;distributed dataset;heterogeneous data sources;heterogeneous dataset;i2x platform;realtime integration and interoperability platform;service integration;warehousing strategy;Data integration;Engines;Feature extraction;Interoperability;Monitoring;Real-time systems;Service-oriented architecture;Automation;cloud;data integration;event-driven;integration-as-a-service;intelligent ETL;interoperability;publish/subscribe;real-time;service-oriented architecture}, 
doi={10.1109/SOCA.2015.16}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6133187, 
author={R. Teckelmann and C. Reich and A. Sulistio}, 
booktitle={2011 IEEE Third International Conference on Cloud Computing Technology and Science}, 
title={Mapping of Cloud Standards to the Taxonomy of Interoperability in IaaS}, 
year={2011}, 
volume={}, 
number={}, 
pages={522-526}, 
abstract={The idea behind cloud computing is to deliver Infrastructure-, Platform- and Software-as-a-Service (IaaS, PaaS and SaaS) over the Internet on an easy pay-per-use business model. However, current offerings from cloud providers are based on proprietary technologies. As a consequence, consumers run into a risk of a vendor lock-in with little flexibility in moving their services to other providers. This can hinder the advancement of cloud computing to small- and medium-sized enterprises. To address these issues, standardization efforts have to take place in order to support further developments in the clouds. Standardized exchange mechanisms and interfaces are crucial in order to facilitate interoperability. In this paper, we look at several cloud standards, such as Open Virtualization Format, Open Cloud Computing Interface, and Cloud Data Management Interface, and analyze them against a taxonomy in order to point out their role for interoperability in IaaS. The taxonomy presents important IaaS topics, such as access mechanism, virtual appliance, security, and service-level agreement.}, 
keywords={cloud computing;open systems;Internet;cloud data management interface;cloud standards;infrastructure-as-a-service;interoperability;open cloud computing interface;open virtualization format;pay-per-use business model;platform-as-a-service;small- and medium-sized enterprises;software-as-a-service;standardization efforts;Cloud computing;Home appliances;Organizations;Security;Standards organizations;Taxonomy;CDMI;OCCI;OVF;cloud computing;interoperability}, 
doi={10.1109/CloudCom.2011.78}, 
ISSN={}, 
month={Nov},}
@ARTICLE{6924629, 
author={M. Yousif}, 
journal={IEEE Cloud Computing}, 
title={A Plethora of Challenges and Opportunities}, 
year={2014}, 
volume={1}, 
number={2}, 
pages={7-12}, 
abstract={This is an exciting time for cloud computing, as not only is the field expanding very fast, but also many organizations, communities, and people are involved. This issue of IEEE Cloud Computing includes a full roster of columns and departments, several of which touch on the use of open source software for cloud computing, a topic of a future special issue. The issue also features a roundtable of experts from academia discussing current cloud challenges, how the industry is addressing these challenges, and how cloud technologies are evolving. Other topics include interoperability in the cloud and cloud sensor data.}, 
keywords={IEEE Cloud Computing;cloud;editorial board;open source;standards}, 
doi={10.1109/MCC.2014.28}, 
ISSN={2325-6095}, 
month={July},}
@INPROCEEDINGS{6218402, 
author={W. Kampichler and D. Eier}, 
booktitle={2012 Integrated Communications, Navigation and Surveillance Conference}, 
title={Cloud based services in air traffic management}, 
year={2012}, 
volume={}, 
number={}, 
pages={G5-1-G5-9}, 
abstract={Air traffic management (ATM) services are migrating towards a global seamless concept. This requires new thinking not only on the necessary operational changes but also on the technological paradigms that determine our current service architectures. Driven by the availability of more and more bandwidth within wide area ground networks new technologies are emerging such as Cloud Computing. Beyond that, operational concepts of FAA's NEXTGEN and Europe's SESAR include dynamically moving the responsibility for airspace blocks from one facility to another, and ensuring continuity of operation by providing contingency operations. This contribution assesses the applicability of cloud computing in ATM, and the key differences to existing commercial applications. It presents the technical cloud computing elements necessary to achieve a truly global ATM system and addresses harmonization and interoperability aspects such as standardized working procedures and controller working positions equipment for air traffic controllers. Situational awareness is key for the decision making process of controllers and pilots in NEXTGEN. A key element different to commercial cloud applications is the necessity to communicate with aircraft and pilots as cloud participants via narrowband VHF radio communications, SATCOM, or other wireless communications technologies. Situational awareness of these participants is paramount which, in the current system, is automatically provided due to the broadcast nature of voice transmissions from controllers and pilots that can be received and heard by all listeners on a particular frequency nearly simultaneously (propagation delay of the radio signal not considered). To efficiently manage the access to this shared media and limit the access only to “relevant” participants, the concept of ATC sector within a geographical area, with boundaries (horizontal and vertical) aligned with traffic patterns exists today. This paper describes mecha- isms that demonstrate how SATCOM, VHF, and various data link technologies can be integrated into a service cloud by virtualizing the sector concept and relaxing or completely removing the dependence on the underlying communications media. The advantage of this concept is that sectors can be dynamically defined based on operational ATM service needs without having to adhere to the coverage limitations of the underlying telecommunications service. The current ATM system is severely limited by the underlying telecommunications service models, most often by programmatic and contractual issues rather than their technical nature. We introduce the concept of a multi-point service within a virtual sector taking into consideration operational NEXTGEN issues and demands related to capacity, performance, and global coverage. Finally we introduce a new communications service model where selected parts of the infrastructure can be selectively and partially outsourced to certified service providers. This concept allows for smoother transition between the existing and next generation technologies, and reduces cost for the taxpayer while maintaining the safety of the flights.}, 
keywords={aerospace safety;air traffic control;aircraft;aircraft communication;cloud computing;decision making;next generation networks;open systems;radiowave propagation;satellite communication;telecommunication control;telecommunication services;telecommunication traffic;voice communication;ATC sector;NEXTGEN;SATCOM;SESAR;air traffic controller;air traffic management;aircraft;airspace block;cloud based service;cloud computing;communications media;communications service model;contingency operation;data link technology;decision making process;flight safety;interoperability;multipoint service;narrowband VHF radio;operational ATM service;propagation delay;radio signal;service architecture;service cloud;situational awareness;telecommunications service;traffic pattern;virtual sector;voice transmission;wireless communication;Aircraft;Availability;Cloud computing;Computational modeling;Organizations;Standards organizations}, 
doi={10.1109/ICNSurv.2012.6218402}, 
ISSN={2155-4943}, 
month={April},}
@INPROCEEDINGS{6550566, 
author={C. Mîndruta and T. F. Fortis}, 
booktitle={2013 27th International Conference on Advanced Information Networking and Applications Workshops}, 
title={A Semantic Registry for Cloud Services}, 
year={2013}, 
volume={}, 
number={}, 
pages={1247-1252}, 
abstract={In the context of the efforts to organize the knowledge in the new and emerging area of Cloud Computing we performed an analysis of relevant existing developments and built on this basis a framework for a semantic registry of cloud services. The framework contains core ontological definitions and extension mechanisms used to define ontologies for cloud services, related to the aspects of semantic discovery and composition of cloud services. The relevance of the proposed registry can be assessed in relation with cloud interoperability, cloud service composition, as well as software services that offer support for finding and selecting cloud services and for marketing advantages of different cloud providers.}, 
keywords={cloud computing;data mining;open systems;software engineering;cloud computing;cloud interoperability;cloud service composition;cloud services;knowledge;semantic discovery;semantic registry;software services;Cloud computing;Computational modeling;Ontologies;Semantics;Standards;Taxonomy;Cloud ontology;Cloud taxonomy;Semantic characterization;Semantic registry;Semantic services}, 
doi={10.1109/WAINA.2013.100}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{7023596, 
author={H. P. Breivold and I. Crnkovic and I. Radosevic and I. Balatinac}, 
booktitle={2014 IEEE 17th International Conference on Computational Science and Engineering}, 
title={Architecting for the Cloud: A Systematic Review}, 
year={2014}, 
volume={}, 
number={}, 
pages={312-318}, 
abstract={Cloud Computing has emerged as a new paradigm in the field of network-based services within many industrial and application domains. The major benefits that it provides in terms of IT efficiency and business agility represent a huge competitive advantage for an organization. However, building new services in the cloud or designing cloud-based solutions into existing business context in general is a complex decision process involving many factors. In this paper, we undertake a systematic review to obtain an overview of the existing studies in designing cloud-based solutions. In particular, we investigate the main challenges and concerns when building cloud-based architectures and different architectural approaches and design considerations that are proposed in literatures to meet these specific concerns. The search strategy identified 72 studies that were catalogued as primary studies for this review after using multi-step selection process. The main challenges and concerns are classified into four main categories: security and trustworthiness, elasticity, portability and interoperability, and cloud resilience. We have also categorized studies that describe architectural approaches and design considerations when architecting for the cloud. Implications for research and practice are presented as well.}, 
keywords={business data processing;cloud computing;organisational aspects;security of data;trusted computing;IT efficiency;application domains;business agility;business context;cloud computing;cloud resilience;cloud-based architectures;cloud-based solutions;complex decision process;design considerations;industrial domains;multistep selection process;network-based services;organization;security;systematic review;trustworthiness;Architecture;Business;Cloud computing;Computer architecture;Data mining;Elasticity;Security;Cloud Computing;cloud-based architecture;concerns}, 
doi={10.1109/CSE.2014.85}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6133174, 
author={C. Doukas and I. Maglogiannis}, 
booktitle={2011 IEEE Third International Conference on Cloud Computing Technology and Science}, 
title={Managing Wearable Sensor Data through Cloud Computing}, 
year={2011}, 
volume={}, 
number={}, 
pages={440-445}, 
abstract={Mobile pervasive healthcare technologies can support a wide range of applications and services including patient monitoring and emergency response. At the same time they introduce several challenges, like data storage and management, interoperability and availability of heterogeneous resources, unified and ubiquitous access issues. One potential solution for addressing all aforementioned issues is the introduction of the Cloud Computing concept. Within this context, in this work we have developed and present a wearable -- textile platform based on open hardware and software that collects motion and heartbeat data and stores them wirelessly on an open Cloud infrastructure for monitoring and further processing. The proposed system may be used to promote the independent living of patient and elderly requiring constant surveillance.}, 
keywords={body sensor networks;cloud computing;geriatrics;health care;mobile computing;patient monitoring;wearable computers;cloud computing;data storage;elderly;emergency response;heartbeat data;heterogeneous resource availability;interoperability;mobile pervasive healthcare technologies;motion data;patient monitoring;ubiquitous access issues;wearable sensor data management;wearable-textile platform;Cloud computing;Clouds;Engines;Google;Mobile handsets;Sensors;cloud computing;sensors;wearable data management;wearable sensors}, 
doi={10.1109/CloudCom.2011.65}, 
ISSN={}, 
month={Nov},}
@ARTICLE{7108022, 
author={B. Di Martino and A. Esposito and G. Cretella}, 
journal={IEEE Transactions on Cloud Computing}, 
title={Semantic Representation of Cloud Patterns and Services with Automated Reasoning to support Cloud Application Portability}, 
year={2015}, 
volume={PP}, 
number={99}, 
pages={1-1}, 
abstract={During the past years the Cloud Computing offer has exponentially grown, with new Cloud providers, platforms and services being introduced in the IT market. The extreme variety of services, often providing non uniform and incompatible interfaces, makes it hard for customers to decide how to develop, or even worse to migrate, their own application into the Cloud. This situation can only get worse when customers want to exploit services from different providers, because of the portability and interoperability issues that often arise. In this paper we propose a uniform, integrated, machine-readable, semantic representation of cloud services, patterns, appliances and their compositions. Our approach aims at supporting the development of new applications for the Cloud environment, using semantic models and automatic reasoning to enhance potability and interoperability when multiple platforms are involved. In particular, the proposed reasoning procedure allows to: perform automatic discovery of Cloud services and Appliances; map between agnostic and vendor dependent Cloud Patterns and Services; automatically enrich the semantic knowledge base.}, 
keywords={Cloud computing;Cognition;Home appliances;Interoperability;Ontologies;Semantics;Cloud Computing;Cloud Interoperability;Cloud Patterns;Cloud Portability;Cloud Service Composition;Cloud Service Discovery}, 
doi={10.1109/TCC.2015.2433259}, 
ISSN={2168-7161}, 
month={},}
@ARTICLE{5481371, 
author={A. Sheth and A. Ranabahu}, 
journal={IEEE Internet Computing}, 
title={Semantic Modeling for Cloud Computing, Part 1}, 
year={2010}, 
volume={14}, 
number={3}, 
pages={81-83}, 
abstract={Cloud computing has lately become the attention grabber in both academia and industry. The promise of seemingly unlimited, readily available utility-type computing has opened many doors previously considered difficult, if not impossible, to open. The cloud computing landscape, however, is still evolving, and we must overcome many challenges to foster widespread adoption of clouds. The main challenge is interoperability.}, 
keywords={grid computing;open systems;programming language semantics;cloud computing;interoperability;semantic modeling;utility-type computing;Cloud computing;Computer industry;Internet;Semantic Web;cloud computing;infrastructure as a service;platform as a service;semantics;software as a service}, 
doi={10.1109/MIC.2010.77}, 
ISSN={1089-7801}, 
month={May},}
@INPROCEEDINGS{6580927, 
author={}, 
booktitle={Proceedings of the 2013 IEEE 17th International Conference on Computer Supported Cooperative Work in Design (CSCWD)}, 
title={Table of contents}, 
year={2013}, 
volume={}, 
number={}, 
pages={i-ix}, 
abstract={The following topics are dealt with: collaboration methods; collaboration techniques; multiagent systems; collaborative workflows; collaboration platforms; software tools; ontology; interoperability; collaborative computing; cloud computing; grid computing; Web services; collaborative virtual environments; collaborative manufacturing technology; healthcare applications; collaborative supply chains; collaborative enterprise networks; Internet of Things; and logistics.}, 
keywords={Internet of Things;Web services;business communication;cloud computing;entertainment;grid computing;groupware;health care;logistics;multi-agent systems;ontologies (artificial intelligence);open systems;social networking (online);software tools;supply chain management;virtual reality;Internet of Things;Web services;cloud computing;collaboration methods;collaboration platforms;collaboration techniques;collaborative computing;collaborative enterprise networks;collaborative manufacturing technology;collaborative supply chains;collaborative virtual environments;collaborative workflows;grid computing;healthcare applications;interoperability;logistics;multiagent systems;ontology;software tools}, 
doi={10.1109/CSCWD.2013.6580927}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{6903502, 
author={F. D. Sánchez and S. A. Zahr and M. Gagnaire and J. P. Laisné and I. J. Marshall}, 
booktitle={2014 IEEE International Conference on Cloud Engineering}, 
title={CompatibleOne: Bringing Cloud as a Commodity}, 
year={2014}, 
volume={}, 
number={}, 
pages={397-402}, 
abstract={Cloud Brokers enable interoperability and portability of applications across multiple Cloud Providers. On the other hand, incoming Cloud Providers start to support more and more unbundled Cloud Instances offerings. Thus, consumers may set up at their will the quantity of CPU, network bandwidth and memory or hard disk capacities their Cloud Instances will have. These facts enable the standardization of interoperable Cloud Instance configurations. In this paper, CompatibleOne is presented as an approach to bring Cloud Computing as a commodity. For this, the requirements to make of a product a commodity have been identified and have been mapped into the CompatibleOne architecture components. Our approach shows the practical feasibility of bringing Cloud Computing as a commodity.}, 
keywords={cloud computing;CPU quantity;CompatibleOne approach;application interoperability;application portability;cloud brokers;cloud computing;cloud instance offerings;cloud providers;hard disk capacity;memory capacity;network bandwidth;Benchmark testing;Business;Cloud computing;Clouds;Computer architecture;Monitoring;Standards}, 
doi={10.1109/IC2E.2014.62}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{6380048, 
author={Y. Jegou and P. Harsh and R. G. Cascella and F. Dudouet and C. Morin}, 
booktitle={2012 8th international conference on network and service management (cnsm) and 2012 workshop on systems virtualiztion management (svm)}, 
title={Managing OVF applications under SLA constraints on contrail virtual execution platform}, 
year={2012}, 
volume={}, 
number={}, 
pages={399-405}, 
abstract={The move of users and organizations to Cloud computing will become possible when they will be able to exploit their own applications, applications and services provided by cloud providers as well as applications from third party providers in a trustful way on different cloud infrastructures. To reach this goal, standard application formats must be enabled on the cloud to avoid vendor lock-in, and guarantees concerning protection, performance and security must be supported. This article describes the Contrail VEP component developed by the Contrail project. The VEP component is in charge of managing the whole life cycle of OVF distributed applications under Service Level Agreement rules on different infrastructure providers.}, 
keywords={cloud computing;contracts;trusted computing;Contrail VEP component;OVF distributed applications;SLA constraints;cloud computing;cloud infrastructures;contrail virtual execution platform;service level agreement;Cloud computing;Monitoring;Resource management;Security;Servers;Standards;Virtual machining}, 
doi={}, 
ISSN={2165-9605}, 
month={Oct},}
@INPROCEEDINGS{7951879, 
author={Quan Zou}, 
booktitle={2017 IEEE 2nd International Conference on Cloud Computing and Big Data Analysis (ICCCBDA)}, 
title={Research on cloud computing for disaster monitoring using massive remote sensing data}, 
year={2017}, 
volume={}, 
number={}, 
pages={29-33}, 
abstract={Satellite remote sensing technology can extract disaster information rapidly and accurately for disaster monitoring on a regional or national basis. However, various sensors are generating huge volumes of remote sensing data for disaster management. It is urgent to handle such massive remote sensing images. In this paper, it provides the solutions for massive remote sensing data analysis and rapid information extraction. A detailed description of the web platform offers an interoperable framework to integrate distributed data and model resources for disaster monitoring using cloud computing. A high throughput cloud computing interfaces and the design of integrated disaster rapid cloud platform are proposed in this paper. In addition, this system provides well interoperability for users. With three typical disaster applications as use case, the experiment proves that the framework is quite efficient for rapid extraction of disaster information based on massive remote sensing data.}, 
keywords={cloud computing;data analysis;distributed databases;emergency management;open systems;remote sensing;Web platform;data analysis;disaster management;disaster monitoring;distributed data;high throughput cloud computing interfaces;integrated disaster rapid cloud platform;interoperability;massive remote sensing images;national basis;rapid information extraction;regional basis;satellite remote sensing technology;Merging;Metadata;Monitoring;Portals;Processor scheduling;Remote sensing;Scheduling;big remote sensing data;cloud computing;rapid extraction of disaster information}, 
doi={10.1109/ICCCBDA.2017.7951879}, 
ISSN={}, 
month={April},}
@ARTICLE{6924634, 
author={A. Sill}, 
journal={IEEE Cloud Computing}, 
title={The Role of Communities in Developing Cloud Standards}, 
year={2014}, 
volume={1}, 
number={2}, 
pages={16-19}, 
abstract={Organizations of varying shapes, types, and sizes play a variety of roles in motivating and developing cloud standards. Establishing community-driven, consensus-based international mutually agreed-upon standards in rapidly developing fields like cloud computing requires many such intermediate organizations to bridge communication gaps that would otherwise exist between theory and implementation when characteristics such as interoperability, portability between architectures, privacy, or other cross-cutting issues are required.}, 
keywords={cloud computing;organisational aspects;standards;architecture portability;cloud computing;cloud standard development;community role;community-driven standard;consensus-based international mutually agreed-upon standards;cross-cutting issues;intermediate organizations;interoperability;privacy;Cloud computing;Communities;Social network services;Standards organizations;Strategic planning;cloud computing;software development;standardization;standards organizations}, 
doi={10.1109/MCC.2014.43}, 
ISSN={2325-6095}, 
month={July},}
@INPROCEEDINGS{7250222, 
author={M. Allison and S. Turner and A. A. Allen}, 
booktitle={2015 10th International Conference on Computer Science Education (ICCSE)}, 
title={Towards interpreting models to orchestrate IaaS multi-cloud infrastructures}, 
year={2015}, 
volume={}, 
number={}, 
pages={80-85}, 
abstract={One challenge to the cloud computing paradigm is the task complexity associated with designing and managing multi-cloud solutions based on operational objectives. Heterogeneous vendor interfaces and a lack of standardization compounds this complexity and may eventually lead to vendor lock-in. In this article we present a model driven approach to allowing network administrators to intuitively describe and rapidly realize non-trivial IaaS behavior in realtime. We have developed iCloudML, an interpreted domain-specific modeling language and its interpreter as tooling support for the domain.}, 
keywords={cloud computing;specification languages;IaaS multicloud infrastructures;cloud computing;iCloudML;infrastructure as a service;interpreted domain-specific modeling language;model driven approach;task complexity;Biological system modeling;Cloud computing;Data models;Object oriented modeling;Quality of service;Runtime;Syntactics}, 
doi={10.1109/ICCSE.2015.7250222}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{7509526, 
author={M. Belaazi and H. B. Rahmouni and A. Bouhoula}, 
booktitle={2014 11th International Conference on Security and Cryptography (SECRYPT)}, 
title={Towards a legislation driven framework for access control and privacy protection in public cloud}, 
year={2014}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Cloud computing is an emerging IT paradigm proving cost reduction and flexibility benefits. However security and privacy are serious issues challenging its adoption and sustainability in both social and commercial areas. Public clouds, in particular, present a controversial which is brought up by the need to exchange critical and protected data (even sensitive) between heterogeneous domains that are governed by multiple legislation. Access control is one of the essential and traditional security arms of data protection. However, in the context of open and dynamic environments such as clouds, access control becomes more complicated. This is because the security policies, models and related mechanisms have to be defined across various security domains and enforced in an integrated manner as required. Thus, improving the current access control paradigms is crucial in order to ensure privacy compliance in open and heterogeneous environments. In this paper, we propose a framework that is driven by legislation and which aims to assure an access control that preserves privacy while dealing with personal data hosted in public clouds. In addition, the proposed framework deals with the problem of interoperability between heterogeneous policies governing the processing of personal data on a cloud environment. In this regards, the need for access control delegation is also presented and tackled.}, 
keywords={authorisation;cloud computing;cost reduction;data protection;electronic data interchange;legislation;sustainable development;IT paradigm;access control delegation;cloud environment;cost reduction;critical data exchange;data protection;dynamic environments;flexibility benefits;heterogeneous domains;heterogeneous environments;legislation driven framework;multiple legislation;open environments;personal data processing;privacy compliance;privacy protection;protected data exchange;public cloud computing;security;security domains;security policies;sustainability;Access control;Cloud computing;Data privacy;Legislation;Privacy;Standards;Cloud Computing;Federated access control;Legislation;Ontology;Privacy;Security;Semantic Web}, 
doi={}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{6934607, 
author={B. Genge and A. Beres and P. Haller}, 
booktitle={2014 49th International Universities Power Engineering Conference (UPEC)}, 
title={A survey on cloud-based software platforms to implement secure smart grids}, 
year={2014}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Smart Grid has been characterized as the next generation power grid in which modern Information and Communication Technologies (ICT) will improve control, reliability and safety. Although the adoption of generic off-the-shelf ICT in Smart Grid provisions indisputable advantages and benefits, it raises several issues concerning the reliability and security of communications - the core infrastructure of Smart Grid. Cloud computing has developed and evolved over the past years becoming a real choice for Smart Grids infrastructure because of the availability, scalability, performance and interoperability that it offers. In this paper we present a survey of the existing cloud-based software platforms for implementing secure Smart Grids. Security issues like authentication and authorization of users, data encryption, availability, attacker impact, detection and trust management have received significant attention in previous work. Nevertheless, as shown in this paper, their integration and adaptation to emerging fields such as Smart Grid is still in an embryonic state. As such, we report recent advancements and software platforms specifically for Smart Grid and we outline several issues as well as suggestions for designing security-aware platforms for Smart Grid.}, 
keywords={cloud computing;open systems;power engineering computing;power system security;smart power grids;Information and Communication Technologies;cloud based software platform;cloud computing;generic off-the-shelf ICT;interoperability;next generation power grid safety control;secure smart grid infrastructure reliability;Availability;Cloud computing;Educational institutions;Encryption;Smart grids;Smart Grid;cloud computing;privacy;security}, 
doi={10.1109/UPEC.2014.6934607}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{5617071, 
author={T. Rings and J. Grabowski and S. Schulz}, 
booktitle={2010 Second International Conference on Advances in System Testing and Validation Lifecycle}, 
title={On the Standardization of a Testing Framework for Application Deployment on Grid and Cloud Infrastructures}, 
year={2010}, 
volume={}, 
number={}, 
pages={99-107}, 
abstract={An important requirement in the successful deployment of grid and cloud computing technology in industry or governmental institutions is the ability to compose their infrastructures using equipment from different vendors. These equipments have to be engineered for and assessed to assure a problem-free interoperation. Focusing on software interoperability, we present a testing framework for the assessment of interoperability of grid and cloud computing infrastructures. This testing framework is part of an initiative for standardizing the use of grid and cloud technology in the context of telecommunication at the European Telecommunications Standards Institute. Following the test development process developed and used at the European Telecommunications Standards Institute, its application is exemplified by the assessment of for resource reservation and application deployment onto grid and cloud infrastructures based on standardized Grid Component Model descriptors. The presented testing framework has been applied successfully in an interoperability event.}, 
keywords={grid computing;object-oriented programming;open systems;program testing;European Telecommunications Standards Institute;Grid Component Model descriptor;application deployment;cloud computing;cloud infrastructure;grid computing;grid infrastructure;problem-free interoperation;resource reservation;software interoperability;testing framework standardization;Bridges;Cloud computing;Clouds;Computer architecture;Telecommunication standards;Testing;GCM;cloud;grid;interoperability;standardization;testing}, 
doi={10.1109/VALID.2010.9}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{6427542, 
author={T. Nguyen and Q. H. Vu and R. Asal}, 
booktitle={4th IEEE International Conference on Cloud Computing Technology and Science Proceedings}, 
title={Harnessing the power of P2P technology to build PC2 #x2014; An open and free cloud computing platform}, 
year={2012}, 
volume={}, 
number={}, 
pages={646-651}, 
abstract={Peer-to-Peer (P2P) systems are generally known as open and free systems since resources are often contributed from voluntary participants. Their limitation, however, is that they only support simple resource sharing such as file (storage) sharing and bandwidth sharing. On the other hand, based on virtualization techniques, cloud computing provides a more flexible mechanism to share all types of resources with no limitations. Nevertheless, the use of cloud computing usually requires a fee and is often locked-in to services of cloud computing providers (i.e., vendor lock-in). In this paper, we aim to combine P2P and cloud computing technologies to design and develop PC2, an open and free cloud computing platform that allows users to participate in any time to contribute as well as to consume sharing resources. While this combination inherits good advantages of these two technologies, it also avoid their disadvantages. As a proof-of-concept, we have developed a prototype for PC2 based on Eucalyptus, the most popular open source for building cloud computing platforms.}, 
keywords={cloud computing;peer-to-peer computing;public domain software;virtualisation;Eucalyptus;P2P technology;PC2;bandwidth sharing;file sharing;free cloud computing platform;open cloud computing platform;peer-to-peer systems;resource sharing;virtualization techniques;Cloud computing;Computer architecture;Conferences;Peer to peer computing;Prototypes;Servers;Cloud Computing;Eucalyptus;P2P;Platform}, 
doi={10.1109/CloudCom.2012.6427542}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{7454539, 
author={M. Bahrami and M. Singhal}, 
booktitle={2015 17th International Conference on E-health Networking, Application Services (HealthCom)}, 
title={A dynamic cloud computing platform for eHealth systems}, 
year={2015}, 
volume={}, 
number={}, 
pages={435-438}, 
abstract={Cloud Computing technology offers new opportunities for outsourcing data, and outsourcing computation to individuals, start-up businesses, and corporations in health care. Although cloud computing paradigm provides interesting, and cost effective opportunities to the users, it is not mature, and using the cloud introduces new obstacles to users. For instance, vendor lock-in issue that causes a healthcare system rely on a cloud vendor infrastructure, and it does not allow the system to easily transit from one vendor to another. Cloud data privacy is another issue and data privacy could be violated due to outsourcing data to a cloud computing system, in particular for a healthcare system that archives and processes sensitive data. In this paper, we present a novel cloud computing platform based on a Service-Oriented cloud architecture. The proposed platform can be ran on the top of heterogeneous cloud computing systems that provides standard, dynamic and customizable services for eHealth systems. The proposed platform allows heterogeneous clouds provide a uniform service interface for eHealth systems that enable users to freely transfer their data and application from one vendor to another with minimal modifications. We implement the proposed platform for an eHealth system that maintains patients' data privacy in the cloud. We consider a data accessibility scenario with implementing two methods, AES and a light-weight data privacy method to protect patients' data privacy on the proposed platform. We assess the performance and the scalability of the implemented platform for a massive electronic medical record. The experimental results show that the proposed platform have not introduce additional overheads when we run data privacy protection methods on the proposed platform.}, 
keywords={cloud computing;data privacy;electronic health records;health care;medical computing;cloud computing paradigm;cloud computing system;cloud data privacy;cloud vendor infrastructure;data accessibility scenario;data privacy protection methods;dynamic cloud computing platform;eHealth systems;electronic medical record;health care;healthcare system;heterogeneous cloud computing systems;outsourcing computation;patient data privacy;service-oriented cloud architecture;uniform service interface;vendor lock-in issue;Cloud computing;Computer architecture;Data privacy;Databases;Encryption;Medical services;Cloud Computing;Data Privacy;Data Security;Dynamic Cloud Computing Architecture;eHealth Platform}, 
doi={10.1109/HealthCom.2015.7454539}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{7830714, 
author={K. Kritikos and K. Magoutis and D. Plexousakis}, 
booktitle={2016 IEEE International Conference on Cloud Computing Technology and Science (CloudCom)}, 
title={Towards Knowledge-Based Assisted IaaS Selection}, 
year={2016}, 
volume={}, 
number={}, 
pages={431-439}, 
abstract={Current PaaS platforms enable single or hybrid cloud deployments. However, such deployment types cannot best cover the user application requirements as they do not consider the great variety of services offered by different cloud providers and the effects of vendor lock-in. On the other hand, multi-cloud deployment enables selecting the best possible service among equivalent ones providing the best trade-off between performance and cost. In addition, it avoids cases of service level deterioration due to service under-performance as main effects of vendor lock-in. While many multi-cloud application deployment research prototypes have been proposed, such prototypes do not examine the effect that deployment decisions have on application performance. As such, they blindly attempt to satisfy low-level hardware requirements by neglecting the impact of allocation decisions on higher-level requirements at the component or application level. To this end, this paper proposes a new IaaS selection algorithm which, apart from being able to satisfy both low and high level requirements of different types, it also exploits deployment knowledge offered via reasoning over previous application execution histories to take the best possible allocation decisions. The experimental evaluation clearly shows that by considering this extra knowledge, more optimal deployment solutions are derived, able to maintain the service levels requested by users, in less solving time.}, 
keywords={cloud computing;decision making;inference mechanisms;resource allocation;IaaS selection;allocation decisions;cloud providers;higher-level requirements;hybrid cloud deployments;knowledge-based assisted IaaS selection;low-level hardware requirements;multicloud application deployment research prototypes;multicloud deployment;service level deterioration;vendor lock-in;Cloud computing;Hardware;History;Prototypes;Resource management;Scalability;Security;IaaS;deployment;evaluation;knowledge base;location;performance;placement;quality of service;requirements;rules;security;selection}, 
doi={10.1109/CloudCom.2016.0073}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6842224, 
author={A. V. A. Ferreira and C. J. A. B. Filho}, 
booktitle={2nd IEEE Latin American Conference on Cloud Computing and Communications}, 
title={Cloud services}, 
year={2013}, 
volume={}, 
number={}, 
pages={59-64}, 
abstract={Cloud computing has been widely referred as a promising technology by the Information Technology community. The market of Cloud services expects an increase of hundreds of billions of dollars in the next years. Currently, most services are being offered by centralized datacenters over the Internet, which imposes limitations such as non-guaranteed end-to-end quality of service and relative low security. The network control owned by telecommunications providers may be considered as a major competitive differential for companies that plan to join the cloud services market. Among the different cloud service models, the Infrastructure as a Service model can be considered as the most appropriate model for telecom providers in the cloud market since it is the less complex option and it can be used as a basis for deploying the other models. In order to take advantage of their network reachability, telecom providers should consider a distributed architecture and other architectural decisions to support multi-tenancy, migration of virtual machines and prevent vendor lock-in. Another important aspect when designing cloud services is the choice of tools for deploying these services. The tools should meet as many requirements as needed in order to provide services in a proper and successful manner. This paper aims to discuss some important aspects as to serve as a reference guide for telecom providers and service providers that wish to enter the cloud services market.}, 
keywords={cloud computing;computer centres;decision support systems;quality of service;virtual machines;Brazilian telecommunication providers;Internet;architectural decisions support;centralized datacenters;cloud computing;cloud services;distributed architecture;infrastructure as a service model;quality of service;virtual machines;Cloud computing;Companies;Computational modeling;Quality of service;Telecommunications;Virtualization;cloud computing;cloud services;infrastructure as a service;telecommunication providers}, 
doi={10.1109/LatinCloud.2013.6842224}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6360129, 
author={R. d. C. C. Castro and H. Carvalho e Silva and A. S. Gracia and M. J. N. Gomes}, 
booktitle={Seventh International Conference on Digital Information Management (ICDIM 2012)}, 
title={Mapping of vulnerabilities in the public cloud with the use of foundational ontology: A perspective for service IaaS}, 
year={2012}, 
volume={}, 
number={}, 
pages={245-252}, 
abstract={In the present days, business applications are still designed for human consumption, which does not allow machines to understand the information contained in them, particularly preventing the correlation between concepts from different fields, in the generation and submission of new information for the handling of large data sets. The increasing complexity of applications, increases the attention in the construction of knowledgeable systems that can be understood and shared by all (application / machines / people). Using the concept of Ontology as a tool for knowledge representation has been effective, in order to develop applications with these said characteristics, since the semantic models have the ability to map and integrate different concepts from the same domain or different domains of knowledge, related to each other, therefore providing conditions for understanding the information contained herewith. Presently, there are different proposals for the aforesaid mapping, considering the semantics and ontological integrations, as well as interoperability of the information systems. This study presents a conceptual modeling in domain knowledge, about the potential vulnerabilities in environments, IaaS, in the public cloud, as a scenario using ontology reasoning. The purpose this modeling, is to provide an effective mechanism, capable of handling two major security issues, such as: providing a common vocabulary to describe vulnerabilities unambiguously and resolving the issue of semantic interoperability between the databases of vulnerabilities maintained by various entities1.}, 
keywords={cloud computing;ontologies (artificial intelligence);open systems;domain knowledge;foundational ontology;human consumption;information systems;knowledge representation;ontological integrations;ontology reasoning;public cloud;security issues;semantic interoperability;semantic models;service IaaS;Cloud computing;Computational modeling;Ontologies;Security;Semantics;Unified modeling language;Cloud Computing;Conceptual Models;OntoUML;Ontologies;Public Cloud;Vulnerabilities}, 
doi={10.1109/ICDIM.2012.6360129}, 
ISSN={pending}, 
month={Aug},}
@INPROCEEDINGS{6846458, 
author={D. Trihinas and G. Pallis and M. D. Dikaiakos}, 
booktitle={2014 14th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing}, 
title={JCatascopia: Monitoring Elastically Adaptive Applications in the Cloud}, 
year={2014}, 
volume={}, 
number={}, 
pages={226-235}, 
abstract={Over the past decade, Cloud Computing has rapidly become a widely accepted paradigm with core concepts such as elasticity, scalability and on demand automatic resource provisioning emerging as next generation Cloud service-must have-properties. Automatic resource provisioning for Cloud applications is not a trivial task, requiring for both the applications and platform, to be constantly monitored, capturing information at various levels and time granularity. In this paper we describe the challenges that occur when monitoring elastically adaptive Cloud applications and to address these issues we present JCatascopia, a fully automated, multi-layer, interoperable Cloud Monitoring System. Experiments on different production Cloud platforms show that JCatascopia is a Monitoring System capable of supporting a fully automated Cloud resource provisioning system with proven interoperability, scalability and low runtime footprint. Most importantly, JCatascopia is able to adapt in a fully automatic manner when elasticity actions are enforced to an application deployment.}, 
keywords={cloud computing;monitoring;resource allocation;JCatascopia;automatic resource provisioning;cloud computing;cloud monitoring system;cloud resource provisioning system;elastically adaptive cloud applications;next generation cloud service;Cloud computing;Elasticity;Measurement;Monitoring;Probes;Servers;Subscriptions;Application Monitoring;Cloud Computing;Cloud Monitoring;Elasticity}, 
doi={10.1109/CCGrid.2014.41}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{7226707, 
author={J. M. Schleicher and M. Vögler and C. Inzinger and S. Dustdar}, 
booktitle={2015 IEEE International Conference on Mobile Services}, 
title={Smart Fabric - An Infrastructure-Agnostic Artifact Topology Deployment Framework}, 
year={2015}, 
volume={}, 
number={}, 
pages={320-327}, 
abstract={The cloud computing paradigm enables the development of applications that can elastically react to changes in their environment by autonomously provisioning and releasing infrastructure resources. However, current applications need to be specifically tailored to a concrete cloud provider infrastructure, leading to vendor lock-in. Migrating applications to the cloud or between cloud providers is challenging due to differences in deployment directives, available services, and programming interfaces. Existing infrastructure as code approaches closely tie application artifacts to their deployment directives and do not allow for a clear separation of application artifacts from deployment infrastructure. In this paper, we present Smart Fabric, a methodology and accompanying toolset for infrastructure-agnostic deployment of application artifact topologies based on a constraint-based, declarative specification of the required deployment infrastructure. Our framework allows for seamless migration of application topologies between deployment targets and enables independent, parallel evolution of both, applications and underlying infrastructure. We discuss the feasibility of the proposed methodology and prototype implementation using representative applications from the Internet of Things and smart city domains.}, 
keywords={Internet of Things;cloud computing;formal specification;smart cities;Internet of Things;application artifact topology;cloud computing paradigm;concrete cloud provider infrastructure;constraint-based specification;declarative specification;deployment directive;deployment infrastructure;infrastructure resource;infrastructure-agnostic artifact topology deployment framework;infrastructure-agnostic deployment;parallel evolution;programming interface;prototype implementation;representative application;seamless migration;smart city domain;smart fabric;vendor lock-in;Fabrics;Hardware;Program processors;Rails;Runtime;Topology}, 
doi={10.1109/MobServ.2015.52}, 
ISSN={2329-6429}, 
month={June},}
@INPROCEEDINGS{6245782, 
author={G. Di Modica and O. Tomarchio}, 
booktitle={2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems}, 
title={A Semantic Model for Utility Driven Discovery of Cloud Resources}, 
year={2012}, 
volume={}, 
number={}, 
pages={822-827}, 
abstract={Cloud computing has reached a high level of acceptance, both in academia and in industry. The maturity of the technology, along with the considerable business opportunity that has been promised, is the main responsible for its success. Nevertheless, today only few, very big players dominate the commercial panorama and take over market shares. From that position, they impose rigid pricing policies and quite inflexible negotiation schemes. When the ongoing cloud standardization process will complete, and thus full interoperability among clouds will be accomplished, new players will come into play. A real competition among cloud providers will then start based on key factors like the capability of providing flexible services tailored to specific, fine-grained customers' requirements. In this market scenario a mechanism must be devised to support the matchmaking between what providers offer and what customers demand. In this work we define a semantic model to help customers and providers to characterize their demands/offers, and propose the use of semantic tools to perform the matchmaking in such a way to maximize both the provider's and the customer's satisfaction.}, 
keywords={cloud computing;customer satisfaction;knowledge representation languages;ontologies (artificial intelligence);pricing;business opportunity;cloud computing;cloud interoperability;cloud providers;cloud resources;cloud standardization process;customer demand;customer satisfaction;demand characterization;extensible OWL-based ontology;flexible service;inflexible negotiation scheme;market scenario;market share;offer characterization;rigid pricing policy;semantic model;semantic tools;specific fine-grained customer requirement;utility driven discovery;Computational modeling;Concrete;Ontologies;Pricing;Prototypes;Semantics;cloud computing;cloud market;matchmaking;negotiation;ontology;price model}, 
doi={10.1109/CISIS.2012.78}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{7516379, 
author={F. Vega and J. Pantoja and S. Morales and O. Urbano and A. Arevalo and E. Muskus and C. Pedraza and M. Patino and M. Suarez and N. Hernandez}, 
booktitle={2016 IEEE Colombian Conference on Communications and Computing (COLCOM)}, 
title={An IoT-based open platform for monitoring non-ionizing radiation levels in Colombia}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-4}, 
abstract={We present in this paper the design, test and validation of a prototype IoT platform for the remote measurement, storage, processing and georeferenced visualization of non-ionizing radiation (NIR) data. The system was designed having into account requirements of interoperability with different NIR probes, backward compatibility, auto scalability, cloud-based operation and security. The development included the design and implementation of communication interfaces for different measuring equipment, the standardization of a communication protocol, the development of a cloud computing platform for processing large volume of data and the integration of two NIR sensors.}, 
keywords={Internet of Things;biological effects of radiation;cloud computing;computerised monitoring;data visualisation;open systems;protocols;radiation monitoring;sensors;Colombia;IoT-based open platform;NIR data;NIR sensor;auto scalability;backward compatibility;cloud computing platform;cloud-based operation;cloud-based security;communication protocol standardization;georeferenced visualization;nonionizing radiation level monitoring;remote measurement;Internet of things;Logic gates;Monitoring;Probes;Sensor systems;Software;Cloud Computing;Internet of Things;IoT;NIR;NIR monitoring system;Non-ionizing Radiation Measurement}, 
doi={10.1109/ColComCon.2016.7516379}, 
ISSN={}, 
month={April},}
@ARTICLE{7057558, 
author={L. Garber}, 
journal={IEEE Cloud Computing}, 
title={In Brief}, 
year={2014}, 
volume={1}, 
number={4}, 
pages={4-6}, 
abstract={As more organizations adopt the cloud, new issues will continue to emerge. Each issue, IEEE Cloud Computing news briefs looks at recent happenings and trends in the cloud world. In this issue, IEEE Cloud Computing reports on cloud interoperability, attacks on Apple, desktop as a service, and a new cloud-based traffic app.}, 
keywords={cloud;interoperability;mobile apps;security}, 
doi={10.1109/MCC.2014.82}, 
ISSN={2325-6095}, 
month={Nov},}
@INPROCEEDINGS{5674744, 
author={M. Kretzschmar and S. Hanigk}, 
booktitle={2010 4th International DMTF Academic Alliance Workshop on Systems and Virtualization Management}, 
title={Security management interoperability challenges for Collaborative Clouds}, 
year={2010}, 
volume={}, 
number={}, 
pages={43-49}, 
abstract={The re-perimeterization and the erosion of trust boundaries already happening in organizations is amplified and accelerated by Cloud Computing. Cloud service models employed, operational models, and technologies used to enable Cloud services may present additional risks and requirements to an organization compared to traditional IT solutions. This paper focuses on Cloud security management issues and interoperability challenges for Collaborative Clouds. Based on a comprehensive requirements analysis, we intendified Cloud security management domains, integrating various Cloud security services of an organization and providing interoperability to identified stakeholders, in order to guideline Cloud activities within an organization. Furthermore we present the status quo of current approaches, systems and standards, with a special focus to objects within the Cloud Security Management Infrastructure (CSMI) that have to be managed and integrated by a Cloud security management system.}, 
keywords={business data processing;cloud computing;formal specification;groupware;open systems;security of data;cloud activity;cloud computing;cloud security management infrastructure;cloud security service;cloud service model;collaborative clouds;comprehensive requirements analysis;interoperability;organization;stakeholder;trust boundary;Cloud computing;Clouds;Collaboration;Cryptography;Organizations;Standards organizations;Cloud Security Management Infrastructure;Cloud security management;Collaborative Clouds;Security Management Infrastructure}, 
doi={10.1109/SVM.2010.5674744}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{7746120, 
author={J. Zouari and M. Hamdi}, 
booktitle={2016 International Symposium on Networks, Computers and Communications (ISNCC)}, 
title={AIDF: An identity as a service framework for the cloud}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={The cloud computing paradigm has changed the way of managing identity. Domain based identity management systems are no more suitable. The alternative of a universal identifier globally handled by an all knowing identity provider proved its failure. The best opproach is to follow the cloud paradigm by offering an Identity as a Service layer. Many projects and standards were proposed to reach this goal but the lack of interoperability and the increasing number of digital identities have hampered the task. We propose in this work an Identity as a Service framework based on the Automated IDentity Finder (AIDF) system which associates one service provider or more with the suitable identity provider after user consent, thus enabling Single Sign On. Additional functionalities are claims transform between different standards and semantic mapping among heterogenous attributes in the same identity context.}, 
keywords={authorisation;cloud computing;open systems;system recovery;AIDF system;Single Sign On;automated identity finder system;cloud computing;digital identities;domain based identity management systems;identity as a service layer;identity management;identity provider;interoperability;semantic mapping;universal identifier;Authentication;Cloud computing;Interoperability;Privacy;Protocols;Standards;claims;cloud;identity management;identity provider;semantic mapping;single sign on}, 
doi={10.1109/ISNCC.2016.7746120}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{5708493, 
author={Z. Hill and M. Humphrey}, 
booktitle={2010 IEEE Second International Conference on Cloud Computing Technology and Science}, 
title={CSAL: A Cloud Storage Abstraction Layer to Enable Portable Cloud Applications}, 
year={2010}, 
volume={}, 
number={}, 
pages={504-511}, 
abstract={One of the large impediments for adoption of cloud computing is perceived vendor lock-in with respect to both low-level resource management and application-level storage services. Application portability is essential to both avoid lock-in as well as leverage the ever-changing landscape of cloud offerings. We present a storage abstraction layer to enable applications to both utilize the highly-available and scalable storage services provided by cloud vendors and be portable across platforms. The abstraction layer, called CSAL, provides Blob, Table, and Queue abstractions across multiple providers and presents applications with an integrated namespace thereby relieving applications of having to manage storage entity location information and access credentials. Overall, we have observed minimal overhead of CSAL on both EC2 and Windows Azure.}, 
keywords={abstract data types;cloud computing;resource allocation;storage management;Blob abstraction;CSAL;application portability;application-level storage service;cloud computing;cloud storage abstraction layer;low-level resource management;portable cloud application;queue abstraction;storage entity location information management;table abstraction;Cloud computing;Connectors;Containers;Java;Peer to peer computing;Semantics;API;cloud computing;cloud storage;portable applications;storage abstraction}, 
doi={10.1109/CloudCom.2010.88}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{7060176, 
author={S. Dam and G. Mandal and K. Dasgupta and P. Dutta}, 
booktitle={Proceedings of the 2015 Third International Conference on Computer, Communication, Control and Information Technology (C3IT)}, 
title={Genetic algorithm and gravitational emulation based hybrid load balancing strategy in cloud computing}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-7}, 
abstract={Cloud computing enables a new supplement of consumption and delivery model for internet based services and protocol. It helps to provide software, hardware and data in form of collaborative services on the demand of the end user. To meet the QoS and ensure high interoperability and scalability is one of the most challenging tasks for cloud service provider. However, there are also several technical challenges that need to be tackled before the benefits can be fully realized. Among them reliability, resource provisioning, and efficient resources consuming etc are major concern. Load balancing also one of them. It includes selecting a proper node that must be full filled end user demand and also distribution of dynamic workload evenly into the multiple nodes. So load balancing can be described as an optimization problem and should be adapting nature due to the changing needs. In this paper we suggest a novel load balancing strategy to search under loaded node to balance load from overwhelmed node. CloudAnalyst used as a simulation tool for the proposed load balancing strategy. Experimental results of the sample application are really very encouraging. Significantly the results of the proposed algorithm are compared and outperformed the traditional strategy like First Come First Serve(FCFS), local search algorithm like Stochastic Hill Climbing(SHC) and soft computing approaches like Genetic Algorithm (GA) and Ant Colony Optimization(ACO).}, 
keywords={cloud computing;genetic algorithms;open systems;quality of service;resource allocation;virtual machines;CloudAnalyst simulation tool;Internet based services;QoS;cloud computing;collaborative services;dynamic workload distribution;genetic algorithm;gravitational emulation based hybrid load balancing strategy;interoperability;optimization problem;scalability;Algorithm design and analysis;Biological cells;Cloud computing;Computational modeling;Genetic algorithms;Gravity;Load management;Cloud Computing;CloudAnalyst;Genetic Algorithm;Load balancing}, 
doi={10.1109/C3IT.2015.7060176}, 
ISSN={}, 
month={Feb},}
@INPROCEEDINGS{6978136, 
author={}, 
booktitle={2014 International Workshop on Advanced Information Systems for Enterprises}, 
title={Table of contents}, 
year={2014}, 
volume={}, 
number={}, 
pages={v-vi}, 
abstract={The following topics are dealt with: information systems; cloud computing; data mining; information retrieval; semantic interoperability; software engineering; and software model.}, 
keywords={cloud computing;data mining;information retrieval;information systems;open systems;software engineering;cloud computing;data mining;information retrieval;information systems;semantic interoperability;software engineering;software model}, 
doi={10.1109/IWAISE.2014.6}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{7436945, 
author={B. M. R. Wilson and B. Khazaei and L. Hirsch}, 
booktitle={2015 IEEE International Conference on Cloud Computing in Emerging Markets (CCEM)}, 
title={Enablers and Barriers of Cloud Adoption among Small and Medium Enterprises in Tamil Nadu}, 
year={2015}, 
volume={}, 
number={}, 
pages={140-145}, 
abstract={Cloud computing has the potential to speed up IT adoption among SMEs in developing economies. Though the benefits of cloud computing is very appealing, the level of cloud adoption is still low among SMEs. This research aims to identify the key enablers, barriers and other factors that influence cloud adoption among SMEs in Tamil Nadu by conducting empirical investigations. We have used TOE framework to identify and capture the factors that affect technology adoption. We highlight cost benefits of using cloud infrastructure, scalability and agility of cloud services as the key enablers of cloud adoption. Broadband availability, high bandwidth cost and vendor lock-in are the main barrier for cloud adoption. Compatibility to existing system, complexity of the migration process, top management support, government policies and competitor pressure are the major organizational factors affecting cloud adoption among SMEs in Tamil Nadu. This study is part of a larger study which aims to develop a cloud migration decision support system (CMDSS) for SMEs in Tamil Nadu.}, 
keywords={cloud computing;decision support systems;small-to-medium enterprises;CMDSS;IT adoption;Nadu;SME;TOE framework;Tamil;bandwidth cost;broadband availability;cloud adoption barrier;cloud adoption enabler;cloud computing;cloud infrastructure;cloud migration decision support system;cloud service agility;competitor pressure;government policies;migration process complexity;small and medium enterprises;technology adoption;top management support;vendor lock-in;Business;Cloud computing;Computational modeling;Context;Law;Technological innovation;SMEs;TOE framework;cloud adoption;cloud adoption in developing countries;cloud computing;empirical study}, 
doi={10.1109/CCEM.2015.21}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{6003845, 
author={B. Yinglei and W. Lei}, 
booktitle={2011 International Conference on Business Computing and Global Informatization}, 
title={Leveraging Cloud Computing to Enhance Supply Chain Management in Automobile Industry}, 
year={2011}, 
volume={}, 
number={}, 
pages={150-153}, 
abstract={To enhance interoperability between stakeholders and improve efficiency of Supply Chain Management (SCM) is one of the key issues that need to be addressed in automobile industry. On the other hand, Cloud Computing has developed from being a gifted commerce idea to one of the top geared sector of the Information Technology. This paper analyzes the state-of-art of the IT condition in supply chain management of automobile industry and proposes a cloud computing based IT reference architecture for enterprises to build the integrated SCM solutions.}, 
keywords={automobile industry;cloud computing;manufacturing data processing;middleware;supply chain management;automobile industry;cloud computing;information technology;supply chain management;Automobiles;Cloud computing;Industries;Software;Supply chain management;cloud computing;saas;supply chain management}, 
doi={10.1109/BCGIn.2011.45}, 
ISSN={2378-8941}, 
month={July},}
@INPROCEEDINGS{5708471, 
author={B. Song and M. M. Hassan and E. n. Huh}, 
booktitle={2010 IEEE Second International Conference on Cloud Computing Technology and Science}, 
title={A Novel Heuristic-Based Task Selection and Allocation Framework in Dynamic Collaborative Cloud Service Platform}, 
year={2010}, 
volume={}, 
number={}, 
pages={360-367}, 
abstract={To address interoperability and scalability issues for cloud computing, in our previous paper, we presented a novel cloud market model called CACM that enables a dynamic collaboration (DC) platform among different Cloud providers. As the initiator of dynamic collaboration, primary Cloud provider (pCP) needs an efficient local task selection and allocation algorithm to partition the whole tasks and allocate those tasks to be executed locally. Existing task allocation algorithms cannot be directly applicable in a DC environment since they may cause low resource utilization of local resources. So in this paper we propose a general task selection and allocation framework to improve resource utilization for pCP. The framework utilizes an adaptive filter to select tasks and a modified heuristic algorithm to allocate tasks. Moreover, a trade-off metric is developed as the optimization goal of heuristic algorithm, so that it is able to manage and optimize the trade-off between QoS of tasks and utilization of resources.}, 
keywords={cloud computing;groupware;information filters;open systems;optimisation;resource allocation;cloud computing;cloud market;dynamic collaborative cloud service;heuristic based task selection;interoperability;optimization;primary cloud provider;resource utilization;scalability;task allocation;Bandwidth;Collaboration;Heuristic algorithms;Measurement;Optimization;Quality of service;Resource management;allocation;cloud market;resource utilization;task selection}, 
doi={10.1109/CloudCom.2010.53}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{7424617, 
author={G. Zangara and D. Terrana and P. P. Corso and M. Ughetti and G. Montalbano}, 
booktitle={2015 10th International Conference on P2P, Parallel, Grid, Cloud and Internet Computing (3PGCIC)}, 
title={A Cloud Federation Architecture}, 
year={2015}, 
volume={}, 
number={}, 
pages={498-503}, 
abstract={Cloud Computing is the state of the art computation paradigm enabling providers to offer computing resources to customers in a pay-per-use fashion. Nowadays public Cloud providers offer similar services within few service models, mainly IaaS and PaaS. Cloud providers give to the user the feeling to dispose of infinite resources, thus having to predict the user requirements in order to provide services with minimal costs, maintaining at the same time high levels of SLAs. In order to achieve this goal, Cloud providers can cooperate together to bring new business opportunities, such as expanding available resources, achieving cost effective asset optimization and adopting power saving policies. Cloud Federation allows different Cloud providers the opportunity to work collaboratively to offer best services to customers and contemporary to improve their productivity. Customers can advantage from Cloud Federation for a larger offer of available services, the capability of price comparison and the removal of vendor lock-in. In this paper we describe a platform that enables the federation of several heterogeneous Cloud Providers to allow the customers choosing and activating Cloud services from a central platform, bringing more attractive price policy to customers. The authors introduce a prototype of Cloud Federation platform based on a central infrastructure tested to manage OpenStack, CloudStack and Amazon EC2 providers, thus allowing the user to select the best services in terms of either technical requirements or price policy and activate them without having to explicitly register to each of the federated providers. The prototype is designed to accept different types of Cloud service models by means of transparent interfaces developed around a billing and a metering module, respectively to bill the service to the customer and to collect information about the health status of the federated platforms.}, 
keywords={cloud computing;contracts;pricing;user interfaces;Amazon EC2 providers;CloudStack;IaaS;OpenStack;PaaS;SLA;central infrastructure;cloud computing;cloud federation architecture;cloud service model;metering module;open technologies;price comparison capability;public cloud providers;transparent interfaces;vendor lock-in removal;Cloud computing;Companies;Computational modeling;Computers;Prototypes;Virtualization;Cloud computing; Cloud federation; OpenStack; CloudStack}, 
doi={10.1109/3PGCIC.2015.183}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{6816579, 
author={S. Yangui and M. B. Nasrallah and S. Tata}, 
booktitle={2013 Ninth International Conference on Semantics, Knowledge and Grids}, 
title={PaaS-Independent Approach to Provision Appropriate Cloud Resources for SCA-based Applications Deployment}, 
year={2013}, 
volume={}, 
number={}, 
pages={14-21}, 
abstract={The adoption of Cloud Computing as a new business model has induced the proliferation of platform providers. However, the platform as-a-service (PaaS) concept still has several drawbacks to address before it can become widely used. In fact, PaaS involves some risks of vendor lock-in and compatibility restrictions if applications to deploy require proprietary or specific hosting frameworks such as applications based on Service Component Architecture (SCA) specifications. In this paper, we introduce a new approach to provision appropriate platform resources in order to host and deploy SCA-based applications on Cloud platforms. Our approach consists of slicing SCA-based applications to different services and then deploying them on our already developed service micro-containers. Our approach is a PaaS-independent approach that allows developers to deploy SCA-based applications on the target PaaS regardless of the platform capabilities. We motivate our solution with real use case scenario to show its feasibility.}, 
keywords={cloud computing;resource allocation;software architecture;PaaS-independent approach;SCA-based applications deployment;appropriate cloud resource provisioning;cloud computing;platform as-a-service;service component architecture specifications;Containers;Java;Packaging;Semantics;Servers;Service-oriented architecture;COAPS;Resource provisioning;SCA;Service binding;Service micro-container}, 
doi={10.1109/SKG.2013.34}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6221788, 
author={}, 
booktitle={Proceedings of the 2012 IEEE 16th International Conference on Computer Supported Cooperative Work in Design (CSCWD)}, 
title={Table of contents}, 
year={2012}, 
volume={}, 
number={}, 
pages={1-12}, 
abstract={The following topics are dealt with: multiagent systems; collaboration methods; collaboration platforms; software tools; collaborative workflows; ontology; interoperability; cloud computing; service-oriented computing; collaborative virtual environments; collaborative wireless sensor networks; social aspects; human factors; manufacturing collaboration technology applications; green products; collaborative networks productions; service collaborative network; Internet of things and logistics.}, 
keywords={Internet;cloud computing;environmental factors;groupware;human factors;logistics;manufacturing data processing;multi-agent systems;ontologies (artificial intelligence);open systems;service-oriented architecture;social aspects of automation;software tools;virtual reality;wireless sensor networks;workflow management software;Internet of things;cloud computing;collaboration methods;collaboration platforms;collaborative networks productions;collaborative virtual environments;collaborative wireless sensor networks;collaborative workflows;green products;human factors;interoperability;logistics;manufacturing collaboration technology applications;multiagent systems;ontology;service collaborative network;service-oriented computing;social aspects;software tools}, 
doi={10.1109/CSCWD.2012.6221788}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{7195634, 
author={Y. Elshater and K. Elgazzar and P. Martin}, 
booktitle={2015 IEEE International Conference on Web Services}, 
title={goDiscovery: Web Service Discovery Made Efficient}, 
year={2015}, 
volume={}, 
number={}, 
pages={711-716}, 
abstract={The growing popularity of cloud computing has magnified the rise of software reuse by facilitating service provisioning over the Internet. At the same time, a new generation of mobile apps has emerged relying on backend services that expand the app functionally, while reducing the overhead on limited mobile resources. The Web service approach promises great flexibility in offering software functionality over the network, while maintaining interoperability between heterogeneous platforms. In addition, recent years have witnessed the rise of user-facing service developments that can be consumed on-the-go with a standard interface, such as Restful Web services. However, the discovery of such services does not match their growing popularity and remain challenging. Users cannot tolerate long latency in finding relevant services to their requests. In this paper, we propose a robust and efficient Web service discovery approach that uses statistical methods and indexing techniques to improve the precision and response time of the discovery process. Experimental results demonstrate that the proposed approach outperforms the state-of-the-art discovery mechanisms and significantly reduces the query response time by at least 77%, while maintaining comparable accuracy.}, 
keywords={Web services;database indexing;statistical analysis;Internet;Web service discovery;app functionally;backend services;cloud computing;discovery process precision;discovery process response time;goDiscovery;heterogeneous platforms;indexing techniques;interoperability;mobile apps;mobile resources;restful Web services;service provisioning;services discovery;software functionality;software reuse;statistical methods;user-facing service developments;Accuracy;Data mining;Force;Runtime;Search engines;Time factors;Web services;K-D tree;TF-IDF;Web service;feature extraction;service discovery}, 
doi={10.1109/ICWS.2015.99}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{5684381, 
author={B. Wu and X. Wu and J. Huang}, 
booktitle={2010 International Conference on Audio, Language and Image Processing}, 
title={Geospatial data services within Cloud computing environment}, 
year={2010}, 
volume={}, 
number={}, 
pages={1577-1584}, 
abstract={The last decade has been a substantial increase in commodity desktop and distributed Geographic Information System applications with client-server or browser-server architectures, mainly as a result of faster hardware and network performance. Nevertheless, there are still problems, in the field of GIS applications, which can not be effectively cooperative used due to the complicated geospatial data formats and geographically distributed resources. The new approach of Utilities computing known by several names, such as Cloud computing, Grid computing or cluster computing is a new trend. As a data intensive application, GIS can benefit from Cloud computing to solve the application interoperability bottleneck. Hence, in this paper, we analyze the weakness and problems of traditional GIS, and then give the approach to solve those problems by Cloud computing and web services. This paper presents the architecture of Geospatial Data Service within Cloud computing environment and its relative technology. In conclusion, this paper provides a solution of execution model based on GML and Web Services. At last, we discuss its implementation process based on Intranet.}, 
keywords={Web services;cloud computing;geographic information systems;grid computing;GIS;Intranet;Web services;application interoperability bottleneck;browser-server architecture;client-server;cloud computing environment;cluster computing;commodity desktop;complicated geospatial data format;data intensive application;distributed geographic information system;geospatial data service;grid computing;network performance;utilities computing;Cloud computing;Clouds;Containers;Geospatial analysis;Peer to peer computing}, 
doi={10.1109/ICALIP.2010.5684381}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{7515760, 
author={C. O. Díaz and C. E. Gómez and H. E. Castro and C. J. Barrios and H. D. Bolívar}, 
booktitle={2016 16th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid)}, 
title={Federated Campus Cloud Colombian Initiative}, 
year={2016}, 
volume={}, 
number={}, 
pages={712-717}, 
abstract={Desktop cloud paradigm arises from combining cloud computing with volunteer computing systems in order to harvest the idle computational resources of volunteers' computers Students usually underuse university computer rooms. As a result, a desktop cloud can be seen as a form of high performance computing (HPC) at a low cost. When the capacity of a desktop cloud is insufficient to execute a HPC project, a new opportunity for collaborative work among universities appears, resulting in a federation of desktop cloud systems to create a significant amount of virtual resources from multiple providers on non-dedicated infrastructure. Even though cloud federation generates research activity today, neither interoperability among several implementations of cloud computing nor the federation of desktop clouds are resolved issues. Therefore, our initiative is related to gathering the existing and idle computer resources provided by the universities that take part to form a cloud federation on non-dedicated infrastructure.}, 
keywords={cloud computing;groupware;parallel processing;volunteer computing;HPC project;cloud computing;collaborative work;desktop cloud systems;federated campus cloud Colombian initiative;high performance computing;university computer rooms;virtual resources;volunteer computing systems;Cloud computing;Computational modeling;Computers;High performance computing;Interoperability;Proposals;Security;Desktop cloud computing;cloud computing;volunteer cloud computing}, 
doi={10.1109/CCGrid.2016.48}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{7794334, 
author={C. Cheng and Z. Deng and Z. Gu and D. Xu}, 
booktitle={2016 IEEE 35th Symposium on Reliable Distributed Systems (SRDS)}, 
title={vMocity: Traveling VMs Across Heterogeneous Clouds}, 
year={2016}, 
volume={}, 
number={}, 
pages={101-110}, 
abstract={Current IaaS cloud providers typically adopt different underlying cloud infrastructures and are reluctant to provide consistent interfaces to facilitate cross-cloud interoperability. Such status quo significantly complicates inter-cloud virtual machine relocation and impedes the adoption of cloud services for more enterprises and individual users. In this paper, we propose vMocity, a middleware framework enabling VM relocation across heterogeneous IaaS clouds. vMocity extends the principles of cold migration and decouples VM's storage stack from their underlying virtualization platforms, which presents a homogeneous view of storage to cloud users. We deploy our prototype system across three representative commercial cloud platforms - Amazon EC2, Google Compute Engine, and VMware vSphere-based private cloud. Compared to existing approaches on both synthetic and real-world work-loads, vMocity can significantly reduce the disruption time, up to 27 times shorter, of relocated services and boost the recovery time, up to 1.8 times faster, to pre-relocation performance level. Our results demonstrate that vMocity is efficient and convenient for relocating VMs across clouds, offering freedom of choice to customers when facing a market of IaaS clouds to align with business objectives (cost, performance, service availability, etc.).}, 
keywords={cloud computing;commerce;middleware;open systems;virtual machines;virtualisation;Amazon EC2;Google Compute Engine;IaaS cloud providers;VM relocation;VM storage stack decoupling;VMware vSphere-based private cloud;business objectives;cloud infrastructures;cloud services;cold migration;cross-cloud interoperability;heterogeneous IaaS clouds;inter-cloud virtual machine relocation;middleware framework;traveling VM;vMocity;virtualization platforms;Booting;Cloud computing;Engines;Google;Peer-to-peer computing;Switches;Virtualization}, 
doi={10.1109/SRDS.2016.022}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6655696, 
author={M. Montenegro and A. Maña}, 
booktitle={2013 IEEE Ninth World Congress on Services}, 
title={Improving Interoperability of Digital Certificates for Software amp; Services}, 
year={2013}, 
volume={}, 
number={}, 
pages={185-192}, 
abstract={Software certification has been successfully used with traditional "static" software. With the introduction of new computing paradigms such as service-oriented computing and cloud computing, the existing way to represent software certifications based in verbose human-oriented documents, exhibits many limitations, to the point of making the approach not useful in practice. The ASSERT4SOA project is currently addressing this problem and has developed a computer-oriented representation for software certifications based on a new type of digital certificates called ASSERT. However, in order to be able to represent the huge heterogeneity of certification schemes and standards, the ASSERT specification has to be extremely flexible and rather complex. This in turn, makes the production of ASSERTs difficult, and moreover, limits their interoperability, as to be interoperable, ASSERTS need to follow certain rules. This paper presents the solution adopted in the project in order to improve the interoperability of independently produced ASSERTS. The solution has been evaluated and has received very positive feedback.}, 
keywords={Web services;certification;cloud computing;formal specification;open systems;service-oriented architecture;ASSERT specification;ASSERT4SOA project;certification scheme;certification standards;cloud computing;computer-oriented representation;computing paradigm;digital certificate;interoperability improvement;service-oriented computing;software certification;static software;verbose human-oriented documents;Certification;Security;Semantics;Software;Software reliability;XML;ASSERT; ASSERT Profile; Web service; CA}, 
doi={10.1109/SERVICES.2013.51}, 
ISSN={2378-3818}, 
month={June},}
@INPROCEEDINGS{7299350, 
author={N. Constant and O. Douglas-Prawl and S. Johnson and K. Mankodiya}, 
booktitle={2015 IEEE 12th International Conference on Wearable and Implantable Body Sensor Networks (BSN)}, 
title={Pulse-Glasses: An unobtrusive, wearable HR monitor with Internet-of-Things functionality}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={The concurrent popularity of wearable sensors and Internet-of-Things (IoT) brings significant benefits to body sensor networks (BSN) that could communicate with the cloud computing platforms for bringing interoperability in health and wellness monitoring. We designed Pulse-Glasses that are cloud-connected, wearable, smart eyeglasses for unobtrusive and continuous heart rate (HR) monitoring. We 3D-printed the first prototype of Pulse-Glasses that use a photoplethysmography (PPG) sensor on one of the nose-pads to collect HR data. We integrated other circuits including an embedded board with Bluetooth low energy (BLE) and a rechargeable battery inside the two temples of Pulse-Glasses. We implemented IoT functionalities such that HR data are recorded from Pulse-Glasses, visualized on an Android smartphone, and stored seamlessly on the cloud. In this paper, we present the developments of Pulse-Glasses hardware including IoT services and the preliminary results from validation experiments. We compared Pulse-Glasses with a laboratory ECG system to cross-validate HR data collected during various activities-sitting, talking, and walking-performed by a participant. We used Pulse-Glasses to record HR data of a driver to test IoT functionalities of location services and BLE and cloud connectivity. The first set of results is promising and demonstrates the prospect of Pulse-Glasses in the field of cloud-connected BSN.}, 
keywords={Bluetooth;Internet of Things;bioelectric potentials;body sensor networks;cloud computing;electrocardiography;gait analysis;medical computing;patient monitoring;photoplethysmography;smart phones;telemedicine;three-dimensional printing;3D-printing;Android smartphone;Bluetooth low energy;body sensor networks;cloud computing platforms;continuous heart rate monitoring;embedded board;internet-of-Things functionality;laboratory ECG system;photoplethysmography sensor;pulse-glass hardware;rechargeable battery;sitting activities;smart eyeglasses;talking activities;unobtrusive heart rate monitoring;walking activities;wearable heart rate monitoring;wearable sensors;Biomedical monitoring;Bluetooth;Electrocardiography;Glass;Heart rate;Monitoring;Smart phones;Body Sensor Networks;Internet-of-things;Wearable Health Monitors;Wearable Photoplethysmography}, 
doi={10.1109/BSN.2015.7299350}, 
ISSN={2376-8886}, 
month={June},}
@INPROCEEDINGS{6021635, 
author={Tinton Dwi Atmaja and Fitriana}, 
booktitle={Proceedings of the 2011 International Conference on Electrical Engineering and Informatics}, 
title={Cyber security strategy for future distributed energy delivery system}, 
year={2011}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Energy delivery systems in future manner will be referred to a modernization of delivery system so it monitors, protects and automatically optimize the operation of its interconnected elements. Its contain power generations, transmission network and user automation. It characterized by two way flow of electricity and information to create an automated distributed energy delivery system. From the viewing side of information flow, there are management and protection of the system that must be strategized to ensure the effective operation of the energy delivery system. This cyber security strategy will examine both domain-specific and common requirement to ensure interoperability of solution across different part of infrastructure. This strategy will require risk management framework developed by both private and public sector. This framework will establish the processes for combining impact, vulnerability, and threat information to produce an assessment of risk to the distributed energy delivery system. The approach of this risk management will consider an organizational perspective, cyber security requirement, standard security system, and electricity security guideline and protection plan. This risk management will be applied on an asset, system, and network basis, as applicable. Some security architecture such as key management, virtualization security within cloud computing, and smart privacy will be linked to the energy delivery system. The final strategy of this effort will be a set of recommended cyber security requirements that will be allocated to interfaces of the Smart Grid. The goal is to ensure that a comprehensive assessment of the systems and component of the distributed energy delivery system is completed.}, 
keywords={cloud computing;data privacy;distributed power generation;open systems;power distribution planning;power distribution protection;power engineering computing;power system security;risk management;smart power grids;virtualisation;cloud computing;cyber security strategy;distributed energy delivery system;electricity security guideline-and-protection plan;information flow;interoperability;key management;organizational perspective;power generations;risk assessment;risk management framework;smart grid;smart privacy;transmission network;user automation;virtualization security;Computer security;Electricity;Power system reliability;Privacy;Risk management;Smart grids;cyber security;delivery system;distributed energy;risk management;strategy}, 
doi={10.1109/ICEEI.2011.6021635}, 
ISSN={2155-6822}, 
month={July},}
@INPROCEEDINGS{7275391, 
author={Y. Ahn and Y. Kim}, 
booktitle={2015 17th Asia-Pacific Network Operations and Management Symposium (APNOMS)}, 
title={Semantic resource classification using statistical analysis for application characteristics in intercloud environment}, 
year={2015}, 
volume={}, 
number={}, 
pages={558-561}, 
abstract={Scientists gain benefits from scalable resource provisioning on-demand, and various computing environments by using cloud computing resources for their applications. However, many cloud computing providers offer their cloud resources according to their own rules. The descriptions of various cloud resources also differ for each vendor. Subsequently, it becomes difficult to find suitable cloud resources given the characteristics of an application. Scientists therefore, select resources used in previous experiments or best performance resources without considering the characteristics of their applications. There is the need to standardize notations to support simple selection of cloud resources without the constraints of providers. Intercloud can use cloud resources without considering cloud providers in hybrid cloud environments. Intercloud project has been studied for interoperability and creates mOSAIC ontology to conceptualize various resources. However, the mOSAIC ontology attributes are limited when considering characteristics of an application. We propose a semantic engine to provide semantic cloud resource services in intercloud environment. We define a rule of categorized resource description with reference to mOSAIC ontology attributes which includes added factors needed to represent application characteristics. We also develop a semantic engine which can choose semantically similar cloud resources using statistical analysis while considering the characteristics of an application. The semantic engine can also classify resources dynamically according to application specifications.}, 
keywords={cloud computing;ontologies (artificial intelligence);open systems;pattern classification;resource allocation;search engines;semantic Web;statistical analysis;application characteristics;cloud computing resource;hybrid cloud environment;intercloud;intercloud environment;interoperability;mOSAIC ontology attribute;scalable resource provisioning on-demand;semantic cloud resource service classification;semantic engine;statistical analysis;Cloud computing;Computer science;Engines;Interoperability;Ontologies;Semantics;Standards;application characteristics;hybrid clouds;resoruce classification;semantic cloud}, 
doi={10.1109/APNOMS.2015.7275391}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{6903709, 
author={E. Pinho and L. B. Silva and C. Costa}, 
booktitle={2014 International Conference on High Performance Computing Simulation (HPCS)}, 
title={A cloud service integration platform for web applications}, 
year={2014}, 
volume={}, 
number={}, 
pages={366-373}, 
abstract={Due to the latest trends on cloud and multi-cloud computing, the lack of interoperability raised a few issues that have been tackled with open standards and integration frameworks. However, the development of web applications adds a few more issues when accessing, managing, combining and orchestrating cloud resources in the application's logic. This paper proposes an extensible platform architecture for portable cloud service integration. It was designed to satisfy requirements and usage patterns of web applications. Moreover, it implements access control policies and mechanisms for sharing and delegation of resources. The article also explains how the platform can be implemented over existent interoperability frameworks, concretely the mOSAIC platform. Finally, some use-cases and implications of the proposed platform are presented.}, 
keywords={cloud computing;open systems;Web applications;access control policies;application logic;cloud resources;cloud service integration platform;extensible platform architecture;interoperability frameworks;mOSAIC platform;multicloud computing;portable cloud service integration;Access control;Cloud computing;Databases;Interoperability;Servers;Standards;cloud computing;cloud interoperability;cloud resources;cloud storage;web applications}, 
doi={10.1109/HPCSim.2014.6903709}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{6644536, 
author={B. Faqihi and N. Daoudi and R. Ajhoun}, 
booktitle={2013 International Conference on Interactive Collaborative Learning (ICL)}, 
title={Semantic Interoperability in the d-learning in the era of cloud computing: Simplicity or complexity}, 
year={2013}, 
volume={}, 
number={}, 
pages={56-60}, 
abstract={Since traditional computing of the 60s, to the innovations of the 80s, passing by emergence of internet, the virtualization advances, the concept of cloud computing have a promising future. Certainly much remains to be done especially for interoperability but also the establishment of norms and standards that will allow to build a set of heterogeneous systems.}, 
keywords={cloud computing;distance learning;open systems;Internet;cloud computing;d-learning;distance learning;heterogeneous systems;semantic interoperability;Cloud computing;Complexity theory;Educational institutions;Information systems;Interoperability;Ontologies;Semantics}, 
doi={10.1109/ICL.2013.6644536}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{5493416, 
author={V. D. Cunsolo and S. Distefano and A. Puliafito and M. Scarpa}, 
booktitle={2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing}, 
title={Applying Software Engineering Principles for Designing Cloud@Home}, 
year={2010}, 
volume={}, 
number={}, 
pages={618-624}, 
abstract={Cloud computing is the ``new hot'' topic in IT. It combines the maturity of Web technologies (networking, APIs, semantic Web 2.0, languages, protocols and standards such as WSDL, SOAP, REST, WS-BPEL, WS-CDL, IPSEC, etc.), the robustness of geographically distributed computing paradigm (emph{Network, Internet} and emph{Grid computing}) and self-management capabilities (emph{Autonomic computing}), with the capacity to manage quality of services by monitoring, metering, quantifying and billing computing resources and costs (emph{Utility computing}). Those have made possible and cost-effective for businesses, small and large, to completely host data- and application-centers virtually... in the Cloud. Our idea of Cloud proposes a new dimension of computing, in which everyone, from single users to communities and enterprises, can, on one hand, share resources and services in a transparent way and, on the other hand, have access to and use such resources and services adaptively to their requirements. Such an enhanced concept of Cloud, enriching the original one with Volunteer computing and interoperability challenges, has been proposed and synthesized in Cloud@Home. The complex infrastructure implementing Cloud@Home has to be supported by an adequate distributed middleware able to manage it.}, 
keywords={Cloud computing;Computer network management;Computer networks;Distributed computing;IP networks;Robustness;Semantic Web;Simple object access protocol;Software engineering;Web and internet services;Cloud computing;HW/SW co-design;Separation of Concerns;Volunteer computing;cross-platform interoperability}, 
doi={10.1109/CCGRID.2010.76}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{5305993, 
author={M. M. Hassan and B. Song and C. Yoon and H. W. Lee and E. N. Huh}, 
booktitle={2009 World Conference on Services - II}, 
title={A Novel Market Oriented Dynamic Collaborative Cloud Service Infrastructure}, 
year={2009}, 
volume={}, 
number={}, 
pages={9-16}, 
abstract={In this paper, we present a novel combinatorial auction (CA) based cloud market model that facilitates dynamic collaboration (DC) among cloud providers (CPs) for providing composite/collaborative cloud services to consumers and hence can address the interoperability and scalability issues for cloud computing. Also to minimize the conflicts that may happen when negotiating among providers in a DC platform, we propose a new auction policy in CA that allows a CP to dynamically collaborate with suitable partner CPs to form a group before joining the auction and to publish their group bids as a single bid to fulfill the service requirements completely. But to find a good combination of CP partners is a NP-hard problem. So we propose a promising multi-objective (MO) optimization model for CP partner selection that not only uses their individual information (INI) but also their past collaborative relationship information (PRI) which is seldom considered in existing approaches. A multi-objective genetic algorithm (MOGA) called MOGA-IC is also developed to solve the model. We implemented our proposed CACM model and the MOGA-IC in a simulated environment and study their economic efficiency and performance with existing model and algorithm. The experimental results show that the proposed MOGA-IC can support satisfactory and high quality partner selection in CACM model.}, 
keywords={commerce;genetic algorithms;open systems;NP-hard problem;cloud computing;cloud market model;collaborative cloud services;combinatorial auction;dynamic collaboration;market oriented dynamic collaborative cloud service infrastructure;multiobjective genetic algorithm;past collaborative relationship information;Cloud computing;Computational modeling;Consumer electronics;Electronic mail;Genetic algorithms;International collaboration;NP-hard problem;Power generation economics;Scalability;Telecommunication computing;Cloud market;MOGA.;combinatorial auction;dynamic collaboration;partner selection}, 
doi={10.1109/SERVICES-2.2009.20}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6350660, 
author={D. Mandl and S. Frye and R. Sohlberg and P. Cappelaere and M. Handy and R. Grossman}, 
booktitle={2012 IEEE International Geoscience and Remote Sensing Symposium}, 
title={The Namibia Early Flood Warning System, a CEOS pilot project}, 
year={2012}, 
volume={}, 
number={}, 
pages={3521-3524}, 
abstract={This paper describes a pilot project effort under the auspices of the Namibian Ministry of Agriculture Water and Forestry (MAWF)/Department of Water Affairs, the Committee on Earth Observing Satellites (CEOS) /Working Group on Information Systems and Services (WGISS) and originally moderated by the United Nations Platform for Space-based Information for Disaster Management and Emergency Response (UN-SPIDER). The effort began by identifying and prototyping technologies which enabled the rapid gathering and dissemination of both space-based and ground sensor data and data products for the purpose of flood disaster management. This was followed by an international collaboration to build small portions of the identified system which was prototyped during the past few years during the flood seasons which occurred in the February through May timeframe of 2010 and 2011 with further prototyping to ongoing in 2012. The pilot effort has been fostered by CEOS to facilitate international efforts to promote satellite sensor data interoperability. In particular, the group has been making use of a technology effort call SensorWeb being developed at NASA which leverages Open Geospatial Consortium (OGC) Sensor Web Enablement (SWE) standards to facilitate various satellite and ground sensor interoperability. The group has made use of such satellites such as Earth Observing 1, Terra/Aqua MODIS and the Canadian Space Agency (CSA) Radarsat together with various ground sensors such as river gauges in Namibia and models such as Global Disaster Alert and Coordination System (GDACS) from Joint Research Center (JRC) from the European Commission. Finally, the group has been experimenting with integrating a large Cloud Computing service provided by the Open Cloud Consortium (OCC) with the SensorWeb to provide management and distribution of the large data sets for emergency workers.},
keywords={cloud computing;disasters;floods;geophysical techniques;geophysics computing;rivers;sensors;AD 2010 to 2011;CEOS pilot project;Canadian Space Agency;Department of Water Affairs;European Commission;Global Disaster Alert and Coordination System;Joint Research Center;NASA;Namibian Ministry of Agriculture Water and Forestry;Open Geospatial Consortium;Radarsat;Sensor Web Enablement standards;SensorWeb;Space-based Information for Disaster Management and Emergency Response;Terra/Aqua MODIS;United Nations Platform;Working Group on Information Systems and Services;early flood warning system;flood disaster management;ground sensor data;ground sensor interoperability;large cloud computing service;prototyping technologies;river gauges;satellite sensor data;satellite sensor interoperability;space-based data;Alarm systems;Cloud computing;Computer architecture;Earth;Floods;Satellites;Architecture;CEOS;Disaster Management;Earth Observations;GEO;GEOSS;Interoperability;OGC}, 
doi={10.1109/IGARSS.2012.6350660}, 
ISSN={2153-6996}, 
month={July},}
@INPROCEEDINGS{6651222, 
author={G. Suciu and S. Halunga and A. Vulpe and V. Suciu}, 
booktitle={International Symposium on Signals, Circuits and Systems ISSCS2013}, 
title={Generic platform for IoT and cloud computing interoperability study}, 
year={2013}, 
volume={}, 
number={}, 
pages={1-4}, 
abstract={Data and Internet services have become ubiquitous, and the recent trend of building massive cloud datacenters is part of the current network evolution. The success of Internet of Things (IoT) will not so much depend on the development of new technologies, but rather on connecting and integrating existing resources. The paper proposes a novel architecture that enables objects to exchange information through the Internet to achieve nonintrusive behavior and customized services based on an open source cloud platform. To achieve this goal, the information driven interactions are done not only in a peer to peer method, but also via advanced cloud services. The result is a generic platform where devices, systems and services will take part in a heterogeneous and decentralized architecture. We demonstrate that IoT is all about interoperability, from connected cloud computing using RFID, NFC, M2M and sensor technology to digital content and context-aware services. We conclude our cloud of things vision by expanding on the need for interoperability of cloud and IoT.}, 
keywords={Internet of Things;Web services;cloud computing;computer centres;open systems;peer-to-peer computing;Internet of Things;Internet services;IoT;M2M technology;NFC technology;RFID technology;advanced cloud services;cloud computing interoperability study;context-aware services;customized services;data services;decentralized architecture;digital content;generic platform;heterogeneous architecture;information driven interactions;massive cloud datacenters;network evolution;nonintrusive behavior;open source cloud platform;peer to peer method;sensor technology;Cloud computing;Clouds;Google;Radiofrequency identification;Standards;Zigbee}, 
doi={10.1109/ISSCS.2013.6651222}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{7923802, 
author={R. R. d. Oliveira and R. M. Martins and A. d. S. Simao}, 
booktitle={2017 IEEE International Conference on Cloud Engineering (IC2E)}, 
title={Impact of the Vendor Lock-in Problem on Testing as a Service (TaaS)}, 
year={2017}, 
volume={}, 
number={}, 
pages={190-196}, 
abstract={Testing as a Service (TaaS) is a new business and service model that provides efficient and effective software quality assurance and enables the use of a cloud for the meeting of quality standards, requirements and consumer's needs. However, problems that limit the effective use of TaaS involve lack of standardization in writing, execution, configuration and management of tests and lack of portability and interoperability among TaaS platforms - the so-called lock-in problem. The lock-in problem is a serious threat to software testing in the cloud and may become critical when a provider decides to suddenly increase prices, or shows serious technical availability problems. This paper proposes a novel approach for solving the lock-in problem in TaaS with the use of design patterns. The aim to assist software engineers and quality control managers in building testing solutions that are both portable and interoperable and promote a more widespread adoption of the TaaS model in cloud computing.}, 
keywords={cloud computing;object-oriented programming;open systems;program testing;quality assurance;software quality;TaaS;cloud computing;design patterns;interoperability;quality standards;software quality assurance;software testing;testing as a service;vendor lock-in problem;Browsers;Cloud computing;Computational modeling;Context;Interoperability;Testing;Cloud Computing;Design Patterns;Testing Service;Testing as a Service (TaaS);Vendor Lock-in}, 
doi={10.1109/IC2E.2017.30}, 
ISSN={}, 
month={April},}
@ARTICLE{6497443, 
author={A. Bahga and V. K. Madisetti}, 
journal={IEEE Journal of Biomedical and Health Informatics}, 
title={A Cloud-based Approach for Interoperable Electronic Health Records (EHRs)}, 
year={2013}, 
volume={17}, 
number={5}, 
pages={894-906}, 
abstract={We present a cloud-based approach for the design of interoperable electronic health record (EHR) systems. Cloud computing environments provide several benefits to all the stakeholders in the healthcare ecosystem (patients, providers, payers, etc.). Lack of data interoperability standards and solutions has been a major obstacle in the exchange of healthcare data between different stakeholders. We propose an EHR system - cloud health information systems technology architecture (CHISTAR) that achieves semantic interoperability through the use of a generic design methodology which uses a reference model that defines a general purpose set of data structures and an archetype model that defines the clinical data attributes. CHISTAR application components are designed using the cloud component model approach that comprises of loosely coupled components that communicate asynchronously. In this paper, we describe the high-level design of CHISTAR and the approaches for semantic interoperability, data integration, and security.}, 
keywords={cloud computing;data integration;data structures;electronic data interchange;health care;medical computing;medical information systems;open systems;security of data;CHISTAR;EHR systems;archetype model;cloud component model;cloud computing environment;cloud health information system technology architecture;cloud-based approach;data integration;data interoperability standard;data security;data structures;generic design methodology;healthcare data exchange;healthcare ecosystem;high-level design;interoperable electronic health record systems;semantic interoperability;stakeholders;Cloud computing;Electronic medical records;Medical information systems;Cloud EHR;data integration;electronic health records;healthcare;1}, 
doi={10.1109/JBHI.2013.2257818}, 
ISSN={2168-2194}, 
month={Sept},}
@ARTICLE{7368833, 
author={J. A. Guerrero-ibanez and S. Zeadally and J. Contreras-Castillo}, 
journal={IEEE Wireless Communications}, 
title={Integration challenges of intelligent transportation systems with connected vehicle, cloud computing, and internet of things technologies}, 
year={2015}, 
volume={22}, 
number={6}, 
pages={122-128}, 
abstract={Transportation is a necessary infrastructure for our modern society. The performance of transportation systems is of crucial importance for individual mobility, commerce, and for the economic growth of all nations. In recent years modern society has been facing more traffic jams, higher fuel prices, and an increase in CO2 emissions. It is imperative to improve the safety and efficiency of transportation. Developing a sustainable intelligent transportation system requires the seamless integration and interoperability with emerging technologies such as connected vehicles, cloud computing, and the Internet of Things. In this article we present and discuss some of the integration challenges that must be addressed to enable an intelligent transportation system to address issues facing the transportation sector such as high fuel prices, high levels of CO2 emissions, increasing traffic congestion, and improved road safety.}, 
keywords={Cloud computing;Connected vehicles;Intelligent vehicles;Internet of things;Vehicular ad hoc networks}, 
doi={10.1109/MWC.2015.7368833}, 
ISSN={1536-1284}, 
month={December},}
@INPROCEEDINGS{8000055, 
author={}, 
booktitle={2017 IEEE 14th International Conference on Networking, Sensing and Control (ICNSC)}, 
title={Table of contents}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={The following topics are dealt with: community-oriented smart grid user engagement; data network planning; photovoltaic system; binary descriptor; 3D object recognition; 3D object registration; autonomous vehicles; smart buildings; IoT; automatic cataract detection; deep convolutional neural network; timed discrete event system; logic programming; API interoperability; open source system; intelligent control; robots; environment monitoring; wireless sensor; observer; Petri net; video surveillance; smart energy systems; anomaly detection; virtualized data center; document detection; cloud data centers; vehicle collision avoidance; trajectory tracking control; multi-agent system; vehicular ad hoc networks; linear systems; MEMS resonating sensors; wastewater management; RFID system; soft sensors; recommender systems; flight departure scheduling; smart city; supply and demand matching; feature selection; smart healthcare; SAR images; remote sensing; health monitoring; image retrieval; adaptive control; sliding model control; and wireless edge cloud computing.}, 
keywords={Internet of Things;adaptive control;application program interfaces;cloud computing;collision avoidance;computer centres;control systems;data visualisation;discrete event systems;feature selection;image processing;logic programming;micromechanical devices;neural nets;open systems;public domain software;robots;scheduling;smart cities;supply and demand;trajectory control;vehicular ad hoc networks;wireless sensor networks;3D object recognition;3D object registration;API interoperability;IoT;MEMS resonating sensors;Petri net;RFID system;SAR images;adaptive control;anomaly detection;automatic cataract detection;autonomous vehicles;binary descriptor;cloud data centers;community-oriented smart grid user engagement;data network planning;deep convolutional neural network;document detection;environment monitoring;feature selection;flight departure scheduling;health monitoring;image retrieval;intelligent control;linear systems;logic programming;multi-agent system;observer;open source system;photovoltaic system;recommender systems;remote sensing;robots;sliding model control;smart buildings;smart city;smart energy systems;smart healthcare;soft sensors;supply and demand matching;timed discrete event system;trajectory tracking control;vehicle collision avoidance;vehicular ad hoc networks;video surveillance;virtualized data center;wastewater management;wireless edge cloud computing;wireless sensor}, 
doi={10.1109/ICNSC.2017.8000055}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{5714464, 
author={J. Villasante}, 
booktitle={2010 14th European Conference on Software Maintenance and Reengineering}, 
title={Keynote: Jes #x0FA;s Villasante}, 
year={2010}, 
volume={}, 
number={}, 
pages={xvii-xvii}, 
abstract={There is growing momentum around Cloud Computing among technology providers, end users, and academia. It is considered as a key theme for both the research constituency itself and for policy makers. Even though Cloud computing is a commercial reality and the adoption rate of cloud computing services is growing, there are major issues that need to be smoothed out before big businesses will truly consider moving mission-critical applications out of their firewalls. More research is needed to tackle challenges such as scalability, security, interoperability of clouds, etc. Aspects of these challenges have been addressed to a certain degree by the Grid and SO A research communities in the past years in the European Community's Framework Programmes for RTD. The expertise gained and the lessons learned should be a basis for further research and policy making in the next generation cloud computing infrastructures. Last year, the European Commission DG Information Society created a Group of Experts in Cloud Computing with the objective to develop a Cloud Computing strategic vision and research directions beyond 2010, capitalising on past expertise and research activities in the area of Grids, SoA and Virtualisation technologies. This group of experts has worked on a report that outlines the future directions of Cloud Computing research. The findings of the final report of the group of experts and the orientations for future research in cloud computing will be presented in this talk.}, 
keywords={cloud computing;European cloud computing service;cloud computing strategic vision;industry expert report;interoperability;technology provider;virtualisation technology;European research;cloud computing}, 
doi={10.1109/CSMR.2010.51}, 
ISSN={1534-5351}, 
month={March},}
@INPROCEEDINGS{5708456, 
author={A. Ranabahu and A. Sheth}, 
booktitle={2010 IEEE Second International Conference on Cloud Computing Technology and Science}, 
title={Semantics Centric Solutions for Application and Data Portability in Cloud Computing}, 
year={2010}, 
volume={}, 
number={}, 
pages={234-241}, 
abstract={Cloud computing has become one of the key considerations both in academia and industry. Cheap, seemingly unlimited computing resources that can be allocated almost instantaneously and pay-as-you-go pricing schemes are some of the reasons for the success of Cloud computing. The Cloud computing landscape, however, is plagued by many issues hindering adoption. One such issue is vendor lock-in, forcing the Cloud users to adhere to one service provider in terms of data and application logic. Semantic Web has been an important research area that has seen significant attention from both academic and industrial researchers. One key property of Semantic Web is the notion of interoperability and portability through high level models. Significant work has been done in the areas of data modeling, matching, and transformations. The issues the Cloud computing community is facing now with respect to portability of data and application logic are exactly the same issue the Semantic Web community has been trying to address for some time. In this paper we present an outline of the use of well established semantic technologies to overcome the vendor lock-in issues in Cloud computing. We present a semantics-centric programming paradigm to create portable Cloud applications and discuss MobiCloud, our early attempt to implement the proposed approach.}, 
keywords={cloud computing;data models;electronic data interchange;open systems;pricing;resource allocation;semantic Web;MobiCloud;cloud computing;computing resource allocation;data modeling;data portability;interoperability;pay-as-you-go pricing scheme;semantic Web;semantics-centric programming paradigm;Business;Cloud computing;DSL;Programming;Quality of service;Semantics;Software;cloud computing;semantic modeling;semantics}, 
doi={10.1109/CloudCom.2010.48}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{6345134, 
author={N. Hargreaves and G. Taylor and A. Carter}, 
booktitle={2012 IEEE Power and Energy Society General Meeting}, 
title={Information standards to support application and enterprise interoperability for the smart grid}, 
year={2012}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Current changes in the European electricity industry are driven by regulatory directives to reduce greenhouse gas emissions, at the same time as replacing aged infrastructure and maintaining energy security. There is a wide acceptance of the requirement for smarter grids to support such changes and accommodate variable injections from renewable energy sources. However the design templates are still emerging to manage the level of information required to meet challenges such as balancing, planning and market dynamics under this new paradigm. While secure and scalable cloud computing architectures may contribute to supporting the informatics challenges of the smart grid, this paper focuses on the essential need for business alignment with standardised information models such as the IEC Common Information Model (CIM), to leverage data value and control system interoperability. In this paper we present details of use cases being considered by National Grid, the GB transmission system operator for information interoperability in pan-network system management and planning.}, 
keywords={air pollution control;cloud computing;open systems;power engineering computing;power markets;power system management;power transmission planning;renewable energy sources;smart power grids;European electricity industry;GB transmission system operator;IEC CIM;IEC common information model;National Grid;energy security;enterprise interoperability;greenhouse gas emission reduction;information standards;market dynamics;pan-network system management;pan-network system planning;regulatory directives;renewable energy sources;scalable cloud computing architecture;smart grid;standardised information model;Business;Computer integrated manufacturing;Data models;Electricity;IEC standards;Smart grids;Common Information Model;Interoperability;Power system management;Smart grid}, 
doi={10.1109/PESGM.2012.6345134}, 
ISSN={1932-5517}, 
month={July},}
@INPROCEEDINGS{6830909, 
author={S. Kolb and G. Wirtz}, 
booktitle={2014 IEEE 8th International Symposium on Service Oriented System Engineering}, 
title={Towards Application Portability in Platform as a Service}, 
year={2014}, 
volume={}, 
number={}, 
pages={218-229}, 
abstract={Cloud Computing has been one of the most vibrant topics in the last years. Especially Platform as a Service (PaaS) is said to be a game changer for future application development. Taking away most of the configuration work, it pledges to foster rapid application development which seems even more important in a world of complex scalable distributed systems. Whereas Infrastructure as a Service (IaaS) is in the process of consolidation and standardization, the PaaS market is largely fragmented offering varying ecosystem capabilities. In this situation, application portability is a major concern for companies utilizing PaaS to avoid vendor lock-in and to retain the ability for future strategical decisions. To categorize portability problems of PaaS, we define a model of current PaaS offerings and identify different portability perspectives. Starting from the model, we derive a standardized profile with a common set of capabilities that can be found among PaaS providers and matched with one another to check application portability based on ecosystem capabilities. We validate our findings with a comprehensive data set of 68 PaaS offerings together with a web-based application for portability matching. We also identify further portability problems by porting the application to different PaaS vendors, validating ecosystem portability and giving hints for future research directions.}, 
keywords={Web services;cloud computing;software portability;IaaS;PaaS;application portability;cloud computing;ecosystem portability validation;infrastructure as a service;platform as a service;portability matching;Abstracts;Companies;Ecosystems;Middleware;Runtime;Standardization;Cloud Computing;Comparison;Ecosystem;PaaS;Platform as a Service;Portability}, 
doi={10.1109/SOSE.2014.26}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{7776611, 
author={D. Kimovski and N. Saurabh and S. Gec and P. Štefanič and G. Kecskemeti and V. Stankovski and R. Prodan and T. Fahringer}, 
booktitle={2016 5th IEEE International Conference on Cloud Networking (Cloudnet)}, 
title={Towards an Environment for Efficient and Transparent Virtual Machine Operations: The ENTICE Approach}, 
year={2016}, 
volume={}, 
number={}, 
pages={242-247}, 
abstract={Cloud computing is based on Virtual Machines (VM) or containers, which provide their own software execution environment that can be deployed by facilitating technologies on top of various physical hardware. The use of VMs or containers represents an efficient way to automatize the overall software engineering and operation life-cycle. Some of the benefits include elasticity and high scalability, which increases the utilization efficiency and decreases the operational costs. VMs or containers as software artifacts are created using provider-specific templates and are stored in proprietary or public repositories for further use. However, technology specific choices may reduce their portability, lead to a vendor lock-in, particularly when applications need to run in federated Clouds. In this paper we present the current state of development of the novel concept of a VM repository and operational environment for federated Clouds named ENTICE. The ENTICE environment has been designed to receive unmodified and functionally complete VM images from its users, and transparently tailor and optimise them for specific Cloud infrastructures with respect to their size, configuration, and geographical distribution, such that they are loaded, delivered, and executed faster and with improved QoS compared to their current behaviour. Furthermore, in this work a specific use case scenario for the ENTICE environment has been provided and the underlying novel technologies have been presented.}, 
keywords={cloud computing;software engineering;virtual machines;ENTICE;ENTICE environment;VM images;cloud computing;cloud infrastructures;operation life-cvcle;software artifacts;software engineering;software execution environment;transparent virtual machine operations;Conferences}, 
doi={10.1109/CloudNet.2016.30}, 
ISSN={}, 
month={Oct},}
@ARTICLE{7091774, 
author={M. Yousif}, 
journal={IEEE Cloud Computing}, 
title={The Road Ahead}, 
year={2015}, 
volume={2}, 
number={1}, 
pages={8-9}, 
abstract={The first issue of 2015 includes four peer-reviewed articles covering topics ranging from energy efficiencies in cloud deployments to interoperability between personal and infrastructure clouds to support the Internet of Things (IoT) as well as an invited article discussing software engineering requirements in cloud-scale computing. The departments explore interesting and thought-provoking topics such as Amazon as a software provider and the competitiveness of cloud pricing. IEEE Cloud Computing also welcomes two new editorial board members: Lutz Schubert and Yongwei Wu.}, 
keywords={Internet of Things;cloud;interoperability;software engineering}, 
doi={10.1109/MCC.2015.21}, 
ISSN={2325-6095}, 
month={Jan},}
@INPROCEEDINGS{7820380, 
author={J. Carrasco and J. Cubo and F. Durán and E. Pimentel}, 
booktitle={2016 IEEE 9th International Conference on Cloud Computing (CLOUD)}, 
title={Bidimensional Cross-Cloud Management with TOSCA and Brooklyn}, 
year={2016}, 
volume={}, 
number={}, 
pages={951-955}, 
abstract={The diversity in the way different cloud providers offer their services, give their SLAs, present their QoS, support different technologies, etc., complicates the portability and interoperability of cloud applications, and favors vendor lockin. Standards like TOSCA, and tools supporting them, have come to help in the provider-independent description of cloud applications. After the variety of proposed cross-cloud application management tools, we propose going one step further in the unification of cloud services with a deployment tool in which IaaS and PaaS services are integrated into a unified interface. We provide support for applications whose components are to be deployed on different providers, indistinctly using IaaS and PaaS services. The TOSCA standard is used to define a portable model describing the topology of the cloud applications and the required resources in an agnostic, and providers- and resources-independent way. We include in this paper some highlights on our implementation on Apache Brooklyn and present a non-trivial example that illustrates our approach.}, 
keywords={cloud computing;contracts;quality of service;resource allocation;topology;Apache Brooklyn;IaaS services;PaaS services;QoS;SLA;TOSCA standard;bidimensional cross-cloud application management;cloud providers;deployment tool;portable model;provider-independent description;unified interface;Cloud computing;Databases;Monitoring;Proposals;Quality of service;Standards;Topology;CAMP;Cloud applications;TOSCA;multi-deployment;standards}, 
doi={10.1109/CLOUD.2016.0143}, 
ISSN={}, 
month={June},}
@INPROCEEDINGS{7471301, 
author={C. Prazeres and M. Serrano}, 
booktitle={2016 30th International Conference on Advanced Information Networking and Applications Workshops (WAINA)}, 
title={SOFT-IoT: Self-Organizing FOG of Things}, 
year={2016}, 
volume={}, 
number={}, 
pages={803-808}, 
abstract={The Internet of Things (IoT) has advanced in different directions, including the development of new architectures, platforms and applications. This multidirectional progress has resulted in the creation of several parallel IoT ecosystems called verticals. Therefore, several approaches have proposed solutions for interoperability of these ecosystems through the delivery of services over virtual infrastructure (Cloud Computing). We introduce the paradigm of Fog of Things (FoT) and propose the design and development of a self-organizing platform called SOFT-IoT: Self-Organizing Fog of Things. SOFT-IoT implements the "Fog Computing" concept introduced by CISCO for the Internet of Things, where part of data processing capacity and service delivery operations are processed locally in "small servers", i.e., close to where data is collected. SOFT-IoT deals with protocols to facilitate the local computing processing and rely in more complex operations running in virtual entities avoiding the traditional approach of centralized cloud computing solutions. In this way, SOFT-IoT enables interoperability of local ecosystems in the fog and also at the cloud level, where other data is stored, processed and complex operations are resolved. In other words, in SOFT-IoT the data processing and delivery of services occurs locally in order to overcome with current infrastructure limitations and data processing alleviating those demands for heavy computational resources that can occur in remote servers, i.e., geographically away from where data is generated.}, 
keywords={Internet of Things;cloud computing;open systems;CISCO;Internet of Things;SOFT-IoT;centralized cloud computing solutions;data processing capacity;fog computing;local ecosystems interoperability;remote servers;self-organizing Fog of Things;service delivery operations;Cloud computing;Computer architecture;Data processing;Internet of things;Logic gates;Performance evaluation;Servers}, 
doi={10.1109/WAINA.2016.153}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{6316481, 
author={S. Abolfazli and Z. Sanaei and M. Shiraz and A. Gani}, 
booktitle={2012 1st IEEE International Conference on Communications in China Workshops (ICCC)}, 
title={MOMCC: Market-oriented architecture for Mobile Cloud Computing based on Service Oriented Architecture}, 
year={2012}, 
volume={}, 
number={}, 
pages={8-13}, 
abstract={The vision of augmenting computing capabilities of mobile devices, especially smartphones with least cost is likely transforming to reality leveraging cloud computing. Cloud exploitation by mobile devices breeds a new research domain called Mobile Cloud Computing (MCC). However, issues like portability and interoperability should be addressed for mobile augmentation which is a non-trivial task using component-based approaches. Service Oriented Architecture (SOA) is a promising design philosophy embraced by mobile computing and cloud computing communities to stimulate portable, complex application using prefabricated building blocks called Services. Utilizing distant cloud resources to host and run Services is hampered by long WAN latency. Exploiting mobile devices in vicinity alleviates long WAN latency, while creates new set of issues like Service publishing and discovery as well as clientserver security, reliability, and Service availability. In this paper, we propose a market-oriented architecture based on SOA to stimulate publishing, discovering, and hosting Services on nearby mobiles, which reduces long WAN latency and creates a business opportunity that encourages mobile owners to embrace Service hosting. Group of mobile phones simulate a nearby cloud computing platform. We create new role of Service host by enabling unskilled mobile owners/users to host Services developed by skilled developers. Evidently, Service availability, reliability, and Service-oriented mobile application portability will increase towards green ubiquitous computing in our mobile cloud infrastructure.}, 
keywords={cloud computing;computer network reliability;computer network security;mobile computing;open systems;service-oriented architecture;smart phones;telecommunication services;wide area networks;MOMCC;SOA;client-server security;component-based approach;green ubiquitous computing;interoperability;long WAN latency;market-oriented architecture;mobile cloud computing;mobile device;reliability;service availability;service discovery;service host;service oriented architecture;service publishing;smartphone;Cloud computing;Computer architecture;Mobile communication;Security;Service oriented architecture;Smart phones}, 
doi={10.1109/ICCCW.2012.6316481}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{6153249, 
author={S. Kotecha and M. Bhise and S. Chaudhary}, 
booktitle={2011 Nirma University International Conference on Engineering}, 
title={Query translation for cloud databases}, 
year={2011}, 
volume={}, 
number={}, 
pages={1-4}, 
abstract={Due to features like on demand services, scalability and usage based pricing, today cloud computing has attracted many customers to move their applications to cloud. But cloud service providers are using different standards and frameworks which customer has to follow. There may be a case where customer wants to migrate data and application to another cloud service provider. In that case, code of application and structure of database must be modified according to the standard provided by new service provider which is very costly. This issue is regarded as cloud vendor lock-in. Work has already been done for providing techniques which can facilitate migration of data. But that technique is not providing support for transformation of query from one cloud to other. By taking Google App engine as one cloud service provider, algorithm can be developed to transform query supported by relational databases, SQL, to query supported by Google app engine datastore, Google Query Language (GQL). After that same algorithm can be generalized for any cloud datastore.}, 
keywords={SQL;cloud computing;query processing;relational databases;Google App engine;Google Query Language;SQL;cloud computing;cloud databases;cloud datastore;cloud service provider;cloud vendor lock-in;data migration;on demand service;query translation;relational database;usage based pricing;Database languages;Engines;Google;Image color analysis;Indexes;Resource description framework;Cloud Database;Google Query Language (GQL);Query Translation;SQL}, 
doi={10.1109/NUiConE.2011.6153249}, 
ISSN={2375-1282}, 
month={Dec},}
@INPROCEEDINGS{6890665, 
author={P. Pouladzadeh and P. Kuhad and S. V. B. Peddi and A. Yassine and S. Shirmohammadi}, 
booktitle={2014 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)}, 
title={Mobile cloud based food calorie measurement}, 
year={2014}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Mobile-based applications have become ubiquitous in many aspects of people's lives over the past few years. Harnessing the potential of this trend for healthcare purposes has become a focal point for researchers and industry, in particular designing applications that can be used by patients as part of their wellness, prevention, or treatment process. Along the way, mobile cloud computing (MCC) has been introduced to be a potential paradigm for mobile health services to overcome the interoperability issues across different information formats. In this paper, we propose a mobile cloud-based food calorie measurement system. Our system provides users with convenient and intelligent mechanisms that allow them to track their food intake and monitor their calorie count. The food recognition technique in our system uses cloud Support Vector Machine (SVM) training mechanism in a cloud computing environment with Map Reduce technique for distributed machine learning. The details of the system and its implementation results are recorded in this paper.}, 
keywords={cloud computing;food safety;health care;learning (artificial intelligence);medical information systems;mobile computing;support vector machines;SVM training mechanism;cloud support vector machine;distributed machine learning;food calorie measurement;food recognition technique;healthcare;map reduce technique;mobile cloud computing;mobile health services;Accuracy;Cloud computing;Databases;Mobile communication;Servers;Support vector machines;Training;Classification;Food recognition;Graph cut;Segmentation}, 
doi={10.1109/ICMEW.2014.6890665}, 
ISSN={1945-7871}, 
month={July},}
@INPROCEEDINGS{7273390, 
author={F. Hajjej and Y. B. Hlaoui and L. J. B. Ayed}, 
booktitle={2015 IEEE 39th Annual Computer Software and Applications Conference}, 
title={Personalized and Generic E-assessment Process Based on Cloud Computing}, 
year={2015}, 
volume={3}, 
number={}, 
pages={387-392}, 
abstract={Currently, there are many problems of the application development of E-Assessment such as the difficulty to use the assessment object from a platform to another one. In addition, the domain model reuse rate is very low in various application systems, and hardness to guarantee the consistency between designs and codes. Therefore, to resolve these problems, we need an approach aiming to automate the modeling and coding processes in e-assessment system. The present study describes an approach, based on service cloud computing, for integrating e-assessment functionalities of candidate LMS systems into a generalized e-assessment process. The proposed approach is based on three steps. The first step consists on development of generic e-assessment process based on reverse engineering. The second step describes a set mapping rules to adapt this generic e-assessment process on the learning profiles. To ensure more flexibility in the generated e-assessment process, we create a composite cloud service that's defining the mapping rules. The third step consists of defining the resulting e-assessment process as a composite cloud service allowing flexibility and interoperability between any LMS e-assessment.}, 
keywords={cloud computing;learning management systems;open systems;reverse engineering;candidate LMS systems;cloud computing;coding processes;composite cloud service;domain model reuse rate;generic e-assessment process;interoperability;personalized e-assessment process;reverse engineering;set mapping rules;Adaptation models;Cloud computing;Electronic learning;Interoperability;Least squares approximations;Reverse engineering;Unified modeling language;LTSA;cloud computing;e-assessment;flexibility}, 
doi={10.1109/COMPSAC.2015.250}, 
ISSN={}, 
month={July},}
@INPROCEEDINGS{6514201, 
author={M. Bist and M. Wariya and A. Agarwal}, 
booktitle={2013 3rd IEEE International Advance Computing Conference (IACC)}, 
title={Comparing delta, open stack and Xen Cloud Platforms: A survey on open source IaaS}, 
year={2013}, 
volume={}, 
number={}, 
pages={96-100}, 
abstract={In the next five years to come people around the globe would choose open source deployment not just because they cut down cost but also helps avoid vendor lock-in. Our research paper gives you an insight to use open source IaaS to set your own public, private or hybrid cloud. The reason behind it is that it delivers value to your enterprise. Comparing these three open clouds will help researcher and other users to decide which one would be a better option for their enterprise.}, 
keywords={cloud computing;organisational aspects;public domain software;Deltacloud platform;OpenStack platform;Xen Cloud Platform;hybrid cloud;open clouds;open source IaaS;private cloud;public cloud;Cloud computing;Computer architecture;Hardware;Security;Servers;Virtual machine monitors;Virtualization;DeltaCloud;IaaS;OCCI;OpenStack;XCP}, 
doi={10.1109/IAdCC.2013.6514201}, 
ISSN={}, 
month={Feb},}
@INPROCEEDINGS{7529566, 
author={H. Ali and R. Moawad and A. A. F. Hosni}, 
booktitle={2016 IEEE International Conference on Cloud Computing and Big Data Analysis (ICCCBDA)}, 
title={A cloud interoperability broker (CIB) for data migration in SaaS}, 
year={2016}, 
volume={}, 
number={}, 
pages={250-256}, 
abstract={Cloud computing is becoming increasingly popular. Information technology market leaders, e.g., Microsoft, Google, and Amazon, are extensively shifting toward cloud-based solutions. However, there is isolation in the cloud implementations provided by the cloud vendors. Limited interoperability can cause one user to adhere to a single cloud provider; thus, a required migration of an application or data from one cloud provider to another may necessitate a significant effort and/or full-cycle redevelopment to fit the new provider's standards and implementation. The ability to move from one cloud vendor to another would be a step toward advancing cloud computing interoperability and increasing customer trust. This study proposes a cloud broker solution to fill the interoperability gap between different software-as-a-service providers. The proposed cloud broker was implemented and tested on a real enterprise application dataset. The migration process was completed and it worked correctly, according to a specified mapping model.}, 
keywords={business data processing;cloud computing;open systems;SaaS;cloud computing;cloud interoperability broker;cloud provider;cloud vendors;cloud-based solutions;customer trust;data migration;enterprise application dataset;full-cycle redevelopment;software-as-a-service providers;Computational modeling;Europe;Facsimile;Interoperability;Mediation;Sugar;Wide area networks;SaaS broker;cloud computing;interoperability}, 
doi={10.1109/ICCCBDA.2016.7529566}, 
ISSN={}, 
month={July},}
@INBOOK{7493827, 
author={San Murugesan and Irena Bojanova}, 
booktitle={Encyclopedia of Cloud Computing}, 
title={Cloud Portability and Interoperability}, 
year={2016}, 
volume={}, 
number={}, 
pages={744-}, 
abstract={Despite the spread of cloud computing and the huge amount of cloud computing solutions a number of issues and challenges related to the cloud still exist. For this reason many research groups have focused on different aspects of cloud computing in order to propose solutions to open cloud issues. The two main issues in cloud computing are portability and interoperability among different cloud platforms. This chapter approaches the problem of cloud interoperability and portability offering an overview of different methodologies, solutions, and initiatives. This chapter presents the most relevant methodologies, research projects, standards proposals, and initiatives to resolve interoperability and portability problems by addressing them from different points of view.}, 
keywords={}, 
doi={10.1002/9781118821930.ch14}, 
ISSN={}, 
publisher={Wiley-IEEE Press}, 
isbn={9781118821930}, 
url={http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7493827},}
@INPROCEEDINGS{7456728, 
author={D. N. Jha and D. P. Vidyarthi}, 
booktitle={2015 IEEE UP Section Conference on Electrical Computer and Electronics (UPCON)}, 
title={A heuristic for security prioritized resource provisioning in cloud computing}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Cloud computing is the hottest buzzword today having enormous benefits, but there remains a number of critical problems (Security, Privacy, Interoperability, Costing, etc.) preventing their wider adoption. For each job/application, Cloud resource provisioning is a cumbersome task as a number of objectives needs to be satisfied with certain constraints. This work proposes security prioritized resource provisioning based on Lp metric and Analytical Hierarchical Process (AHP) which considers both qualitative and quantitative properties in an efficient manner.}, 
keywords={analytic hierarchy process;cloud computing;resource allocation;security of data;AHP;analytical hierarchical process;cloud computing;cloud resource provisioning;costing problems;interoperability problems;privacy problems;security prioritized resource provisioning;security problems;Cloud computing;Complexity theory;Measurement;Quality of service;Resource management;Security;Virtualization;AHP;Cloud computing;Lp metric;resource provisioning;security}, 
doi={10.1109/UPCON.2015.7456728}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{7546227, 
author={P. Thakur and D. K. Shrivastava}, 
booktitle={2015 International Conference on Computational Intelligence and Communication Networks (CICN)}, 
title={Interoperability Issues and Standard Architecture for Service Delivery in Federated Cloud: A Review}, 
year={2015}, 
volume={}, 
number={}, 
pages={908-912}, 
abstract={Cloud computing can be defined as accessing third party software and services on web and paying as per usage. It facilitates scalability and virtualized resources over internet as a service providing cost effective and scalable solution to customers. As the customer needs are growing for the solutions of the complex problem, there is the need for the services from different cloud service providers so that resources will be properly utilized. To execute and handle the complex business application over clouds as demands by the users, interoperable solution is provided. Federated cloud computation gives the advantage of cost reduction and energy saving. Cloud architecture uses virtualization technique for having the provision of more than one virtual machine on the same physical host. Interoperable cloud architecture solves the problem of vendor lock-in and portability, saves energy reduce power consumption and promote green cloud computing. This paper describes Interoperability issues and standard architecture of cloud computing suitable for the use of services from multiple service providers to provide portability.}, 
keywords={cloud computing;cost reduction;energy conservation;energy consumption;green computing;open systems;power aware computing;resource allocation;virtual machines;virtualisation;Internet;cloud architecture;cloud computing;cloud service providers;complex business application execution;complex business application handling;cost reduction;customer needs;energy saving;federated cloud computation;green cloud computing;interoperability issues;portability problem;power consumption reduction;resource utilization;scalability;service delivery;standard architecture;third party software;third services;vendor lock-in problem;virtual machine;virtualization technique;virtualized resources;Cloud computing;Computational modeling;Computer architecture;Interoperability;Ontologies;Semantics;Software as a service;Federated cloud;Interoperability;Standardization}, 
doi={10.1109/CICN.2015.179}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{7224871, 
author={Y. W. Ma and J. L. Chen and C. C. Chang and C. M. Chiang and Y. L. Xie and S. J. Chen and H. Y. Pan and W. C. Hung and J. C. Chiou and P. S. Yu}, 
booktitle={2015 17th International Conference on Advanced Communication Technology (ICACT)}, 
title={SDN test cases development and implementation}, 
year={2015}, 
volume={}, 
number={}, 
pages={618-621}, 
abstract={The evolution of information technology and the explosive growth in Internet data have rendered traditional ways of providing information services and their infrastructure no longer appropriates. Data storage, computing and Internet services are moving toward virtualization and cloud computing. However, the performance of this network architecture needs to be examined to improve network bandwidth utilization. Google's success in using the Software-Defined Networking (SDN) to achieve a system utilization rate as high as 90% stimulated widespread development of SDN. This work conducts SDN research and develops a test platform for conformance and interoperability analysis.}, 
keywords={computer network performance evaluation;software defined networking;Internet data;Internet services;SDN test cases development;cloud computing;conformance analysis;interoperability analysis;software-defined networking;Computer architecture;Generators;Interoperability;Monitoring;Switches;Testing;Device Under Test (DUT);Open Networking Foundation (ONE);RYU;Software-Defined Networking (SDN);Test Cases},
doi={10.1109/ICACT.2015.7224871}, 
ISSN={1738-9445}, 
month={July},}
@INPROCEEDINGS{7820320, 
author={K. Yongsiriwit and M. Sellami and W. Gaaloul}, 
booktitle={2016 IEEE 9th International Conference on Cloud Computing (CLOUD)}, 
title={A Semantic Framework Supporting Cloud Resource Descriptions Interoperability}, 
year={2016}, 
volume={}, 
number={}, 
pages={585-592}, 
abstract={With the advent of Cloud Computing, organizations are increasingly migrating their information and communication technology (ICT) resources to the cloud. This has recently gained a great attention because of cloud pay-as-you-go model which drastically reduces actual IT infrastructure with high performance and continuous availability. In order to effectively utilize existing cloud resources, organizations may look for available cloud resources from different cloud providers. However, cloud resources are heterogeneous and described by different standards which prevents an easy and dynamic interoperability between organizations. In this paper, we propose a semantic framework tackling this heterogeneity issue. We develop a set of ontologies to semantically represent cloud resources by looking at three cloud resource description standards: Topology and Orchestration Specification for Cloud Applications (TOSCA), Open Cloud Computing Interface (OCCI), and Cloud Infrastructure Management Interface (CIMI). Hence, our framework promotes the creation of a common semantic knowledge base of cloud resources described using these different standards. This knowledge base allows a seamless translation of cloud providers' resource descriptions. We developed an application to validate our approach as a proof of concept. We also evaluated the feasibility and completeness of our semantic framework on use cases obtained from standard specifications.}, 
keywords={cloud computing;knowledge based systems;open systems;resource allocation;CIMI;Cloud Infrastructure Management Interface;ICT resources;IT infrastructure;OCCI;Open Cloud Computing Interface;TOSCA;Topology and Orchestration Specification for Cloud Applications;cloud pay-as-you-go model;cloud provider resource descriptions;cloud providers;cloud resource description interoperability;cloud resource description standards;dynamic interoperability;information and communication technology;semantic framework;semantic knowledge base;Cloud computing;Interoperability;Ontologies;Organizations;Semantics;Standards organizations;Cloud computing;cloud resource description standard;ontology;semantic web technologies}, 
doi={10.1109/CLOUD.2016.0083}, 
ISSN={}, 
month={June},}
@ARTICLE{7116435, 
author={B. Di Martino and G. Cretella and A. Esposito}, 
journal={IEEE Cloud Computing}, 
title={Advances in Applications Portability and Services Interoperability among Multiple Clouds}, 
year={2015}, 
volume={2}, 
number={2}, 
pages={22-28}, 
abstract={Despite the exponential growth in available services and their broad adoption, cloud computing solutions are still heavily affected by the lack of a shared and worldwide accepted standard for their description and exposition to customers. This is reflected in the portability and interoperability issues often arising when customers try to exploit multicloud solutions. In this article the solutions proposed by the most prominent European research projects are presented, together with a set of emerging de jure and de facto standards and affirmed cloud platforms.}, 
keywords={cloud computing;open systems;applications portability issue;cloud computing solutions;cloud platforms;multicloud solutions;services interoperability issue;Cloud computing;Computational modeling;Computer applications;Europe;Interoperability;Semantics;APIs;cloud;cloud platforms;cloud services;interoperability;portability;standards}, 
doi={10.1109/MCC.2015.38}, 
ISSN={2325-6095}, 
month={Mar},}
@INPROCEEDINGS{7182659, 
author={Young-Rok Shin and Eui-Nam Huh}, 
booktitle={2015 Seventh International Conference on Ubiquitous and Future Networks}, 
title={QoE metrics aggregation for hierarchical Service Level Agreement in Cross-Layered SLA architecture}, 
year={2015}, 
volume={}, 
number={}, 
pages={831-836}, 
abstract={Numerous services are developed using cloud computing technology. It is possible to use service from remote location, not in place of local computer. Accordingly, the research groups predict that the scale of cloud service also will be grown. One of cloud computing's advantage is scalability. It can extend its service scale and range using collaboration between cloud service providers. To make it possible, however, interoperability is required in that environment. Cross-Layered SLA architecture is the cloud service environment that supports interoperability. In this paper, we propose aggregation functions and quality model for QoE metrics and newly generating Service Level Agreement in cross-layered SLA architecture. We expect that this aggregation function and quality model will solve the possible problems in the cloud service area.}, 
keywords={cloud computing;contracts;QoE metrics aggregation;cloud computing technology;cloud service;cross-layered SLA architecture;hierarchical service level agreement;interoperability;Business;Cloud computing;Computational modeling;Computer architecture;Mathematical model;Measurement;Quality of service;Cloud service;Cross-layered SLA architecture;Intercloud;Metric aggregation;Quality of Experience (QoE);Quality of Service (QoS);Service Level Agreement (SLA)}, 
doi={10.1109/ICUFN.2015.7182659}, 
ISSN={2165-8528}, 
month={July},}
@INPROCEEDINGS{7962516, 
author={B. Alessandro and R. Barbara and P. Alberto}, 
booktitle={2017 Fourth International Conference on eDemocracy eGovernment (ICEDEG)}, 
title={E-government and cloud: Security implementation for services}, 
year={2017}, 
volume={}, 
number={}, 
pages={79-85}, 
abstract={Public Administration sector in modern society is characterized by the need to simplify and streamline how to provide services to citizens and business. The enactment of e-government services has been a valuable solution that, thanks to cloud computing, has also ensured greater efficiency, effectiveness, transparency and interoperability. However, such approach creates new challenges for security and trust. In this scenario the paper describes a security framework that implements a centralized access control, providing authentication and authorization to a wide range of Web applications and services delivered by Public Administration and deployed in the cloud. Authentication occurs according to the SSO federated pattern that assumes the use of remote Identity Providers for login. To this end we decided to leverage the Public Digital Identity System (SPID), a security infrastructure that ensures to citizens and enterprises to be uniquely recognized. Federation is realized according to SPID specifications which rely on the SAML standard, while the interaction between the security framework and the applications/services to be protected is mainly enforced via the OAuth2/OpenID Connect protocol, but, to ensure a smooth transition of existing applications to the cloud, additional proprietary methods have been taken into account.}, 
keywords={Internet;authorisation;cloud computing;government data processing;message authentication;public administration;OAuth2-OpenID Connect protocol;SAML standard;SPID specifications;SSO federated pattern;Web applications;authentication;authorization;centralized access control;cloud computing;e-government services;interoperability;proprietary methods;public administration sector;public digital identity system;remote identity providers;security implementation;Authentication;Authorization;Cloud computing;Servers;Standards organizations;E-government cloud;authentication;cloud infrastructure;cloud services;security framework;single sign-on}, 
doi={10.1109/ICEDEG.2017.7962516}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{7390868, 
author={A. Corradi and L. Foschini and A. Pernafini and F. Bosi and V. Laudizio and M. Seralessandri}, 
booktitle={2015 IEEE 82nd Vehicular Technology Conference (VTC2015-Fall)}, 
title={Cloud PaaS Brokering in Action: The Cloud4SOA Management Infrastructure}, 
year={2015}, 
volume={}, 
number={}, 
pages={1-7}, 
abstract={In the last few years, we witnessed a growing interest in interoperability and portability topics within the Cloud Computing area. In fact, most heterogeneous PaaS solutions have been developed with no standard APIs, and with different models and levels of service; in this scenario, vendor lock-in becomes an issue. Cloud4SOA project aims to design and develop a Reference Architecture that could solve interoperability and portability problems within the Cloud domain. This paper describes our work on Cloud4SOA Semantic and SOA layer presenting a common knowledge base framework and a standardized set of harmonized APIs to overcome diversities among PaaS solution and report interesting experimental results collected for two real-world PaaS deployments.}, 
keywords={cloud computing;open systems;service-oriented architecture;Cloud4SOA management infrastructure;cloud PaaS brokering;cloud computing;interoperability problem;platform as a service;portability problem;Cloud computing;Computational modeling;Computer architecture;Interoperability;Ontologies;Semantics;Service-oriented architecture}, 
doi={10.1109/VTCFall.2015.7390868}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{7027518, 
author={B. Parák and Z. Ŝustr}, 
booktitle={2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing}, 
title={Challenges in Achieving IaaS Cloud Interoperability across Multiple Cloud Management Frameworks}, 
year={2014}, 
volume={}, 
number={}, 
pages={404-411}, 
abstract={In academia, many institutes have deployed IaaS cloud services in isolation, based on cloud management frameworks of their choice, making the cloudscape quite heterogeneous. Now, with the effort to federate cloud resources well underway, the challenge is not to make everyone switch to a common solution, but rather to allow everyone to keep their setup but still provide uniform access to essential services. This seems to be best achieved by implementing common standards. This paper discusses the different areas such standardization effort must address, ranging from the choice of the actual standardization approach (i.e., Choosing a recognized open standard or possibly a non-standard solution with a strong community backing) through authentication and virtual machine life-cycle management to monitoring or accounting (billing) services. The discussion is based on the authors' own practical experience with implementing standard compliance in multiple cloud management frameworks, producing a real-world interoperability solution -- the rOCCI Framework - which is also introduced in the paper.}, 
keywords={cloud computing;open systems;resource allocation;virtual machines;IaaS cloud interoperability;cloud management framework;cloud resource federation;infrastructure as a service;virtual machine life-cycle management;Authentication;Home appliances;Interoperability;Monitoring;Standards;Virtual machining;IaaS;OCCI;cloud;framework;interoperability;rOCCI;standards}, 
doi={10.1109/UCC.2014.51}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{6110925, 
author={P. Kalagiakos and P. Karampelas}, 
booktitle={2011 5th International Conference on Application of Information and Communication Technologies (AICT)}, 
title={Cloud Computing learning}, 
year={2011}, 
volume={}, 
number={}, 
pages={1-4}, 
abstract={Cloud Computing is evolving as a key technology for sharing resources. Grid Computing, distributed computing, parallel computing and virtualization technologies define the shape of a new era. Traditional distance learning systems lack reusability, portability and interoperability. This paper sees cloud computing ecosystem as a new opportunity in designing cloud computing educational platforms where learning actors can reuse learning resources handled by cloud educational operating systems. To enhance learning objects portability and interoperability not only cloud computing API standards should be advocated by the key cloud providers but also learning resources standards should be defined by the Open Cloud Computing Education Federation as proposed by this paper.}, 
keywords={application program interfaces;cloud computing;computer aided instruction;grid computing;open systems;parallel processing;cloud computing API standards;cloud computing ecosystem;cloud computing educational platforms;cloud computing learning;cloud educational operating systems;distance learning systems;distributed computing;grid computing;learning objects interoperability;learning objects portability;learning resource sharing;open cloud computing education federation;parallel computing;virtualization technologies;Computational modeling;Context;Hafnium compounds;Reliability;Semiconductor optical amplifiers;Standards;cloud computing;cloud educational operating system;learning actors;open cloud computing education federation}, 
doi={10.1109/ICAICT.2011.6110925}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{6914202, 
author={S. Khan and E. Ahmad and M. Shiraz and A. Gani and A. W. A. Wahab and M. A. Bagiwa}, 
booktitle={2014 International Conference on Computer, Communications, and Control Technology (I4CT)}, 
title={Forensic challenges in mobile cloud computing}, 
year={2014}, 
volume={}, 
number={}, 
pages={343-347}, 
abstract={Mobile cloud computing (MCC) is fast becoming one of the most essential research topics for distributed resource networks. Users can easily access cloud while offloading their mobile applications from anywhere anytime. Being easy to access, intruder attacks mobile networks to acquire credential from mobile applications inside and outside the cloud computing. To investigate intruder's attacks, digital investigator has to identify the root cause of the attack. However, investigating MCC infrastructure is difficult due to its characteristics of virtualization, dispersion of data, multi tenancy, interoperability, and mobility. In this paper, we present an overview of MCC and digital forensics, focusing on its key aspects and significant forensic challenges faced by digital investigators in MCC. The purpose of this paper is to provide a comprehensive understanding about forensic research challenges and re-direct researchers towards new research areas.}, 
keywords={cloud computing;digital forensics;mobile computing;MCC;distributed resource networks;forensic challenges;intruder attacks;mobile applications;mobile cloud computing;mobile networks;Cloud computing;Companies;Digital forensics;Mobile communication;Mobile computing;Mobile handsets;Forensic;Investigation;Mobile cloud computing}, 
doi={10.1109/I4CT.2014.6914202}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6012766, 
author={G. D. Modica and O. Tomarchio}, 
booktitle={2011 IEEE World Congress on Services}, 
title={Semantic Security Policy Matching in Service Oriented Architectures}, 
year={2011}, 
volume={}, 
number={}, 
pages={399-405}, 
abstract={Cloud computing poses several new security and privacy challenges, mainly related to resource sharing, interoperability and dinamicity among different providers. Although policy specification languages address some of these challenges,many issues still have to be faced with. Policy matching is today performed by way of syntactical approaches, which may limit the selection of suitable services on the one hand, and the flexibility and the dinamicity of the matching process on the other one. In this work we propose a semantic approach that,by means of semantic annotations to WS-Policy documents,allows for an improved matching of security requirements and capabilities based on their actual meaning. The proposed approach has been validated through a case study that shows how a pure syntactic-based mechanism of WS-Policy would have failed in matching two actually compatible policies.}, 
keywords={cloud computing;security of data;service-oriented architecture;specification languages;WS-Policy;cloud computing;policy specification language;semantic annotation;semantic security policy matching;service oriented architecture;syntactic-based mechanism;Authentication;OWL;Ontologies;Protocols;Semantics;Web services;Security policy;Semantic matching;WS-Policy}, 
doi={10.1109/SERVICES.2011.110}, 
ISSN={2378-3818}, 
month={July},}
@INPROCEEDINGS{5559829, 
author={W. Li and L. Ping and X. Pan}, 
booktitle={2010 International Conference on Electronics and Information Engineering}, 
title={Use trust management module to achieve effective security mechanisms in cloud environment}, 
year={2010}, 
volume={1}, 
number={}, 
pages={V1-14-V1-19}, 
abstract={Security and interoperability is the biggest challenge to promote cloud computing currently. Trust has proved to be one of the most important and effective alternative means to construct security in distributed systems. In order to efficiently and safely construct entities' trust relationship in cloud and cross-clouds environment, this paper proposed a novel cloud trust model and a new cloud security framework. The propose trust model is domain-based. It divides one cloud provider's resource nodes into the same trust domain. It designs different trust strategies for different roles. Trust recommendation is treated as one type of cloud services just like computation or storage. Based on the proposed trust model, it introduced a novel cloud security framework with an independent trust management module. Using the proposed security model, it introduced some trust-based security mechanisms. Results of simulation experiments show that the proposed security model can achieve high transaction success rate with high trust accuracy.}, 
keywords={Internet;open systems;security of data;cloud computing;cloud provider resource node;cloud security framework;cloud service;cross clouds environment;distributed system;domain based trust model;high transaction success rate;security mechanism;trust management module;trust recommendation;Accuracy;Authorization;Cloud computing;Clouds;Computational modeling;Conferences;cloud computing;security framework;security mechanisms;trust model}, 
doi={10.1109/ICEIE.2010.5559829}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{5577272, 
author={D. Bernstein and D. Vij}, 
booktitle={2010 6th World Congress on Services}, 
title={Intercloud Directory and Exchange Protocol Detail Using XMPP and RDF}, 
year={2010}, 
volume={}, 
number={}, 
pages={431-438}, 
abstract={Working groups have proposed building a layered set of protocols to solve the Cloud Computing interoperability challenge called “Intercloud Protocols”. Instead of each cloud provider establishing connectivity with another cloud provider in a Point-to-Point manner resulting in the n2 complexity problem, Intercloud Directories and Exchanges will act as mediators for enabling connectivity and collaboration among disparate cloud providers. Point to Point protocols such as HTTP are not suitable beyond 1-to-1 models, therefore the discussions around many-to-many mechanisms have been proposed, including XMPP. This paper details the use of an XMPP mechanism for such mediation. On top of that, for the federation of the resources themselves, we define a resources catalog approach, using the Semantic Web Resource Definition Framework (RDF) along with a common Ontology of Cloud Computing Resources to work across a variety of heterogeneous cloud providers.}, 
keywords={Internet;ontologies (artificial intelligence);open systems;semantic Web;transport protocols;RDF;Semantic Web resource definition framework;XMPP;cloud computing interoperability;exchange protocol;intercloud directory;intercloud protocols;ontology;point to point protocols;Authentication;Catalogs;Cloud computing;Clouds;Logic gates;Protocols;Resource description framework}, 
doi={10.1109/SERVICES.2010.131}, 
ISSN={2378-3818}, 
month={July},}
@ARTICLE{7226829, 
author={M. Aazam and E. N. Huh and M. St-Hilaire and C. H. Lung and I. Lambadaris}, 
journal={IEEE Transactions on Parallel and Distributed Systems}, 
title={Cloud Customer #x0027;s Historical Record Based Resource Pricing}, 
year={2016}, 
volume={27}, 
number={7}, 
pages={1929-1940}, 
abstract={Media content in its digital form has been rapidly scaling up, resulting in popularity gain of cloud computing. Cloud computing makes it easy to manage the vastly increasing digital content. Moreover, additional features like, omnipresent access, further service creation, discovery of services, and resource management also play an important role in this regard. The forthcoming era is interoperability of multiple clouds, known as cloud federation or inter-cloud computing. With cloud federation, services would be provided through two or more clouds. Once matured and standardized, inter-cloud computing is supposed to provide services which would be more scalable, better managed, and efficient. Such tasks are provided through a middleware entity called cloud broker. A broker is responsible for reserving resources, managing them, discovering services according to customer's demands, Service Level Agreement (SLA) negotiation, and match-making between the involved service provider and the customer. So far existing studies discuss brokerage in a narrow focused way. In the research outcome presented in this paper, we provide a holistic brokerage model to manage on-demand and advance service reservation, pricing, and reimbursement. A unique feature of this study is that we have considered dynamic management of customer's characteristics and historical record in evaluating the economics related factors. Additionally, a mechanism of incentive and penalties is provided, which helps in trust build-up for the customers and service providers, prevention of resource underutilization, and profit gain for the involved entities. For practical implications, the framework is modeled on Amazon Elastic Compute Cloud (EC2) On-Demand and Reserved Instances service pricing. For certain features required in the model, data was gathered from Google Cluster trace.}, 
keywords={cloud computing;contracts;middleware;open systems;pricing;profitability;resource allocation;Amazon Elastic Compute Cloud;EC2;Google Cluster trace;SLA negotiation;cloud broker;cloud computing;cloud customer historical record based resource pricing;cloud federation;cloud interoperability;customer demands;digital content;discovery of services;dynamic customer characteristics management;incentive mechanism;intercloud computing;media content;middleware;omnipresent access;on-demand service pricing;penalty mechanism;profit gain;reserved instance service pricing;resource management;resource underutilization;service creation;service level agreement negotiation;service reservation;Cloud computing;Economics;Electronic mail;Mathematical model;Pricing;Quality of service;Resource management;Cloud broker;Inter-cloud computing;cloud broker;cloud federation;inter-cloud computing;pricing;resource management}, 
doi={10.1109/TPDS.2015.2473850}, 
ISSN={1045-9219}, 
month={July},}
@INPROCEEDINGS{7819665, 
author={D. Kumar and H. V. Samalia}, 
booktitle={2016 IEEE International Conference on Cloud Computing in Emerging Markets (CCEM)}, 
title={Investigating Factors Affecting Cloud Computing Adoption by SMEs in Himachal Pradesh}, 
year={2016}, 
volume={}, 
number={}, 
pages={9-16}, 
abstract={Due to low level of penetration of ICT in SME sector, Indian SMEs are deprived of benefits like improved efficiency, better market linkages and enhanced customer services. Cloud computing has the potential to accelerate ICT adoption among SMEs, by making ICT accessible to the small businesses without incurring much costs and efforts. Cloud computing can prove to be very beneficial to SMEs. Flexible cost structure and delivery of computing services through internet can make cloud computing a unique proposition for SMEs. Other features such as scalability, flexibility and easy deployment process provide an opportunity for small businesses to get access to the most advanced & latest technologies at affordable cost. However, issues like lack of knowledge/awareness about cloud computing, poor internet connectivity, security & privacy concerns, lack of trust, and vendor lock-in prevent small businesses from adopting cloud computing. In spite of these concerns, cloud computing can still prove to be commercially viable option to SMEs. The primary purpose of this paper is to investigate key factors influencing SME's intention to adopt cloud computing in Himachal Pradesh, India. Findings of this work are intended to provide valuable insights for practitioners and researchers who are interested in spreading the usage & adoption of cloud computing among SMEs.}, 
keywords={cloud computing;small-to-medium enterprises;Himachal Pradesh;Indian SME;Internet;cloud computing adoption;Cloud computing;Computational modeling;Investment;Organizations;Security;Software as a service;Cloud computing;Cloud computing adoption;Information and Communication Technologies (ICT);Small and Medium sized Enterprise (SME)}, 
doi={10.1109/CCEM.2016.012}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{7019735, 
author={C. Saravanakumar and C. Arun}, 
booktitle={2014 International Conference on Contemporary Computing and Informatics (IC3I)}, 
title={Survey on interoperability, security, trust, privacy standardization of cloud computing}, 
year={2014}, 
volume={}, 
number={}, 
pages={977-982}, 
abstract={Cloud computing is a service oriented concept which offers everything as a service. These services are deployed at the server with necessary credentials in order to provide reliable services to the customer. The customer always wants to process and store the data in the cloud with an efficient access over different location. The security is the key parameter to secure the customer's data. The cloud computing security issues are addressed in various standards and techniques which lacks in providing a complete solution. The privacy issues in the cloud access are handled and assessed by using privacy protocols and assessment techniques which are also addressed. The trust issues in cloud computing has been addressed with different models. An inter-cloud and intra-cloud standard of cloud interoperability has been identified in order to highlight the challenges exist during the cloud interaction. The cloud resources are deployed over cloud environment with different models also faces a problem. This paper focuses on a recent survey related to the cloud interoperability, security, privacy and trust based on standards and guidelines have been analyzed. The overall focus on this paper is to establish an interoperability among different cloud service providers for effective interaction by maximizing the QoS of cloud computing.}, 
keywords={cloud computing;data privacy;open systems;security of data;trusted computing;QoS;assessment techniques;cloud access;cloud computing security issues;cloud environment;cloud interaction;cloud interoperability;cloud privacy;intercloud standard;intracloud standard;privacy issues;privacy protocols;service oriented concept;Cloud computing;Computational modeling;Interoperability;Privacy;Security;Standards;Cloud Interoperability;Privacy;Security;Standardization;Trust Management}, 
doi={10.1109/IC3I.2014.7019735}, 
ISSN={}, 
month={Nov},}
@INBOOK{7493857, 
author={San Murugesan and Irena Bojanova}, 
booktitle={Encyclopedia of Cloud Computing}, 
title={Open-Source Cloud Software Solutions}, 
year={2016}, 
volume={}, 
number={}, 
pages={744-}, 
abstract={Today various commercial, free, and open-source cloud software solutions are available for building clouds. Open-source cloud software solutions, promoted by the open-source community, give enterprises the ability to build their own private clouds with lower costs and without vendor lock-in issues. In this chapter we compare leading open-source cloud software solutions available in the community, under the umbrella of the following three main cloud service delivery models - infrastructure as a service (IaaS), platform as a service (PaaS), and software as a service (SaaS). We use a different set of criteria for comparing software solutions under each model. At the end of the chapter, we discuss the features of open-source cloud infrastructure automation tools.}, 
keywords={}, 
doi={10.1002/9781118821930.ch12}, 
ISSN={}, 
publisher={Wiley-IEEE Press}, 
isbn={9781118821930}, 
url={http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7493857},}
@INPROCEEDINGS{7057164, 
author={B. D. Martino and G. Cretella and A. Esposito and R. G. Sperandeo}, 
booktitle={2014 International Conference on Intelligent Networking and Collaborative Systems}, 
title={Semantic Representation of Cloud Services: A Case Study for Microsoft Windows Azure}, 
year={2014}, 
volume={}, 
number={}, 
pages={647-652}, 
abstract={Starting with the provision of ready-to-use infrastructures, such as storage and compute resources, cloud computing quickly became a flexible, cost-effective and complete environment for a wide range of IT services offered over the Internet. A growing number of cloud providers started to expose their own services to the market, to answer consumer's need, engaging a competition in the attempt to offer the easiest access to resources and the wider catalogue of services. Being integrated with proprietary services and infrastructures, these offerings makes difficult to switch between different underlying technologies, so that the customer is tied to the service provider's strategy. This lack in standards interfaces, service requirements and technologies brings into the cloud the vendor lock-in problem. Due to this complex scenery, a categorization of services to support the choice of the right solution, as well as a semantic and computable description of services that enables the comparison and the mapping between different providers' services, proves to be extremely appealing. In an attempt to take a first important step in this context we propose the semantic description of some cloud services, exposing them in terms of functionalities, parameters exchanged, and collaboration between services. In particular in this paper we present the semantic representation of Microsoft Windows Azure APIs, describing functional and non-functional properties of the services.}, 
keywords={application program interfaces;cloud computing;ontologies (artificial intelligence);open systems;semantic Web;Microsoft Windows Azure API;application programming interfaces;cloud computing;cloud interoperability;cloud services semantic representation;compute resources;functional properties;nonfunctional properties;ontology;proprietary infrastructures;proprietary services;ready-to-use infrastructures;semantic Web;service categorization;storage resources;vendor lock-in problem;Cloud computing;Grounding;Interoperability;Ontologies;Semantics;Subscriptions;Virtual machining;cloud computing;cloud interoperability;ontology;semantic representation;semantic web}, 
doi={10.1109/INCoS.2014.76}, 
ISSN={}, 
month={Sept},}
@INPROCEEDINGS{6249994, 
author={M. Vida and O. Lupse and L. Stoicu-Tivadar}, 
booktitle={2012 7th IEEE International Symposium on Applied Computational Intelligence and Informatics (SACI)}, 
title={Improving the interoperability of healthcare information systems through HL7 CDA and CCD standards}, 
year={2012}, 
volume={}, 
number={}, 
pages={157-161}, 
abstract={The interoperability of healthcare information system is an important issue in medical informatics field. It is important to increase the life expectancy, reduce medical errors and provide more medical information for medical personal. For achieving the interoperability of healthcare information systems is important to have a standardized communication. This paper presents a control for Visual Studio .NET 2010 toolbox; it can be used for ASP. NET pages and in the final it will be used to improve interoperability issues. It has the possibility to show the tables and fields from different database and it can be integrated with a cloud application. Further is reveled the use of this control in a Pediatrics application on Azure platform. CC (cloud computing) is a technology that supports flexibility, seamless care, and can reduced costs of the medical act.}, 
keywords={cloud computing;cost reduction;health care;medical information systems;network operating systems;nonprofit organisations;open systems;paediatrics;ASP. NET pages;Azure platform;HL7 CCD standard;HL7 CDA standard;HL7 clinical document architecture standard;HL7 continuity of care document standard;Visual Studio .NET 2010 toolbox;cloud application;cloud computing;cost reduction;database tables;healthcare information system interoperability improvement;life expectancy;medical act;medical error reduction;medical informatics;medical information system;medical personal;pediatrics application;seamless care;standardized communication;Charge coupled devices;Databases;Immune system;Informatics;Standards;Tiles}, 
doi={10.1109/SACI.2012.6249994}, 
ISSN={}, 
month={May},}
@INPROCEEDINGS{6496382, 
author={B. M. Nguyen and V. Tran and L. Hluchy}, 
booktitle={The International Conference on Information Networking 2013 (ICOIN)}, 
title={A novel approach for developing interoperable services in cloud environment}, 
year={2013}, 
volume={}, 
number={}, 
pages={232-237}, 
abstract={Cloud computing has seen a tremendous growth in the last five years. Along with the growth, many cloud models have been marketed. They deliver hardware and software as virtualization enabled services to users. Although cloud computing offers considerable advantages such as unlimited resources, manageability and lower investment costs but there are still barriers to exploit it. One of the barriers is the difficulties, which users are being faced when developing and deploying their own services into clouds. In this paper, we present a novel approach for developing interoperable services that can be deployed in different cloud infrastructures at the same time. The approach provides an instrument with emphasis on abstraction, inheritance and code reuse. Using the approach, cloud-based services are developed easily by extending existing abstractions classes provided by the instrument or other developers. The interoperability between different clouds is solved via the basic abstraction class of the instrument and all services are inherited and benefited from this advantage.}, 
keywords={cloud computing;investment;cloud computing;cloud environment;cloud infrastructures;cloud models;cloud-based services;code reuse;interoperability;interoperable services;investment costs;virtualization enabled services;Cloud computing;Clouds;Databases;Image restoration;Servers;asbtraction;cloud computing;inheritance;interoperahility;service development}, 
doi={10.1109/ICOIN.2013.6496382}, 
ISSN={1550-445X}, 
month={Jan},}
@INPROCEEDINGS{6090863, 
author={C. Cheng and T. H. Stokes and M. D. Wang}, 
booktitle={2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society}, 
title={caREMOTE: The design of a cancer reporting and monitoring telemedicine system for domestic care}, 
year={2011}, 
volume={}, 
number={}, 
pages={3168-3171}, 
abstract={After receiving cancer treatment, patients often experience a decline of HRQoL (health-related quality of life). Physicians typically evaluate HRQoL during periodic clinical visits. However, out-patient reporting of vital signals between two visits could be used to interpret the decline of HRQoL. Considering that the vast majority of patients recovering from cancer are not in hospitals, it is often impractical for the care providers to collect these data. In this paper, we design and prototype caREMOTE, a cancer reporting and monitoring telemedicine system, which can be used in domestic cancer care. By extending a standard clinical trial informatics model, we build a prototype on cloud computing services that can be accessed by a mobile application. We aim to maximize the potential of caREMOTE to help medical practitioners efficiently monitor discharged patients' HRQoL and vital signals, and facilitate data reusability and system interoperability in future collaborative cancer research.}, 
keywords={cancer;cloud computing;health care;patient monitoring;telemedicine;caREMOTE;cancer monitoring design;cancer reporting design;cancer treatment;cloud computing services;domestic cancer care;health-related quality-of-life;mobile application;physicians;standard clinical trial informatics;telemedicine system;Biomedical monitoring;Cancer;Clinical trials;Google;Mobile communication;Monitoring;Unified modeling language;Home Care Services;Humans;Monitoring, Physiologic;Neoplasms;Quality of Life;Questionnaires;Telemedicine}, 
doi={10.1109/IEMBS.2011.6090863}, 
ISSN={1094-687X}, 
month={Aug},}
@INPROCEEDINGS{7527790, 
author={}, 
booktitle={2016 IEEE International Conference on Cloud Engineering Workshop (IC2EW)}, 
title={[Front cover]}, 
year={2016}, 
volume={}, 
number={}, 
pages={C4-C4}, 
abstract={The following topics are dealt with: software defined system; cloud-supported Internet of things; cloud computing; technoeconomic engineering workshop; interoperability; data quality.}, 
keywords={Internet of Things;cloud computing;data handling;open systems;cloud computing technoeconomic engineering workshop;cloud-supported Internet of things;data quality;interoperability;software defined system}, 
doi={10.1109/IC2EW.2016.67}, 
ISSN={}, 
month={April},}
